{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Noting:\n",
    "## Camera Depth\n",
    "Closer Person and Farther Person from the camera lead to different skeletons coordinate making the action detection model prone to changes in 3D environment. Since joint locations are detected in pixel coordinates, a person who is far away will have joint coordinates that appear compressed, while those who are closer will appear expanded.  \n",
    "-> Solution: Normalize Person Coordinate and calculate joint distances.\n",
    "+ Joint locations are Normalized using equation (1) where $(x_i, y_i)$ and $(x'_i, y'_i)$ are the original joint coordinate and normalized joint coordinate in i-th position. Thus the normalized joints reprepresent n features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading a Video and Saving Frames in Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes: 3 subfolders within 'Single_person_violent' => Kicking, Punching, Non-violent\n",
    "CLASSES = [\"Kicking\", \"Punching\", \"Standing\", \"Walking\"]\n",
    "\n",
    "# We will define a fixed sequence length to handle variable-length videos\n",
    "MAX_SEQ_LEN = 5  \n",
    "\n",
    "# Set how many frames to skip when reading a video (to reduce computational load)\n",
    "SKIP_RATE = 1  # example: capture 1 frame out of every 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract Pose Sequence from a Single Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function opens a video file with OpenCV (cv.VideoCapture).\n",
    "\n",
    "It skips frames by advancing the capture index so we only process 1 out of every SKIP_RATE frames.\n",
    "\n",
    "For each processed frame, it uses MediaPipe Pose to detect 33 landmarks.\n",
    "\n",
    "Each landmark has 4 values: (x, y, z, visibility), so for 33 landmarks, we get 132 values in one frame.\n",
    "\n",
    "If no pose is detected, we append a zero vector (132 zeros).\n",
    "\n",
    "Finally, it returns a NumPy array of shape (T, 132), where T is the number of frames we processed in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def get_pose_sequence_from_video(video_path, skip_rate=5):\n",
    "    \"\"\"\n",
    "    Opens a video, reads frames at a specified skip_rate,\n",
    "    and returns a NumPy array of shape (num_frames, 132)\n",
    "    containing (x, y, z, visibility) for 33 pose landmarks.\n",
    "    \"\"\"\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    \n",
    "    # List to store the per-frame keypoints\n",
    "    sequence = []\n",
    "    \n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, \n",
    "                      min_tracking_confidence=0.5) as pose_model:\n",
    "        \n",
    "        frame_index = 0  # keep track of frame index\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # no more frames\n",
    "            \n",
    "            # Process only 1 out of every 'skip_rate' frames\n",
    "            if frame_index % skip_rate == 0:\n",
    "                # Convert BGR to RGB\n",
    "                rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "                results = pose_model.process(rgb_frame)\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    # Flatten 33 landmarks × 4 = 132 values\n",
    "                    keypoints = []\n",
    "                    for lm in results.pose_landmarks.landmark:\n",
    "                        keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "                    sequence.append(keypoints)\n",
    "                else:\n",
    "                    # If no pose was detected, append a zero vector of length 132\n",
    "                    sequence.append([0]*132)\n",
    "            \n",
    "            frame_index += 1  # increment frame counter\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(sequence)  # shape (num_frames, 132)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Full Dataset by Loop through all videos (X_sequences, y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over each subfolder (Kick, Punching, Non-violent) under Single_person_violent.\n",
    "\n",
    "For each video, we call get_pose_sequence_from_video with our chosen SKIP_RATE.\n",
    "\n",
    "We store the resulting array (T, 132) in a list, and store the string label (e.g. \"Kick\") in another list.\n",
    "\n",
    "We will end up with X_sequences[i] as the 2D array of skeleton data, and y_labels[i] as the corresponding string label.\n",
    "\n",
    "Note: At this point, X_sequences[i] might have different lengths because each video can have a different number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob # for file path matching\n",
    "\n",
    "BASE_DIR = \"Single_person_violent\"  # your main dataset folder\n",
    "X_sequences = []\n",
    "y_labels = []\n",
    "\n",
    "for cls in CLASSES:  # e.g. \"Kick\", \"Punching\", \"Non-violent\"\n",
    "    class_dir = os.path.join(BASE_DIR, cls)\n",
    "    # Use glob to list all .mp4 or .avi files\n",
    "    video_paths = glob.glob(os.path.join(class_dir, \"*.mp4\")) + glob.glob(os.path.join(class_dir, \"*.avi\"))\n",
    "    \n",
    "    for vid_path in video_paths:\n",
    "        seq = get_pose_sequence_from_video(vid_path, skip_rate=SKIP_RATE)\n",
    "        \n",
    "        # If the video has at least 1 frame successfully processed, append\n",
    "        if seq.shape[0] > 0:\n",
    "            X_sequences.append(seq)\n",
    "            y_labels.append(cls)\n",
    "        else:\n",
    "            print(f\"No frames extracted from {vid_path} (possibly empty or skip too high).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Preprocessed Data (`X_sequences` and `y_labels`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder if it doesn't exist\n",
    "SAVE_DIR = \"extracted_data\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Convert to NumPy arrays and save\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"pose_dataset.npz\"),\n",
    "    X=np.array(X_sequences, dtype=object),\n",
    "    y=np.array(y_labels)\n",
    ")\n",
    "\n",
    "print(f\"✅ Saved {len(X_sequences)} sequences to {SAVE_DIR}/pose_dataset.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load(\"extracted_data/pose_dataset.npz\", allow_pickle=True)\n",
    "# X_sequences = list(data[\"X\"])\n",
    "# y_labels = list(data[\"y\"])\n",
    "\n",
    "# print(f\"✅ Loaded {len(X_sequences)} sequences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pad or Truncate Sequences\n",
    "LSTM/GRU networks expect uniform sequence lengths in a batch.\n",
    "\n",
    "We define a function pad_or_truncate_sequence that ensures each sequence has exactly MAX_SEQ_LEN frames.\n",
    "\n",
    "+ If a sequence is longer than MAX_SEQ_LEN, we take the first MAX_SEQ_LEN frames.\n",
    "\n",
    "+ If it’s shorter, we pad with zeros at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate_sequence(seq, max_len=30):\n",
    "    \"\"\"\n",
    "    seq: (T, 132) array for T frames\n",
    "    Returns an array of shape (max_len, 132).\n",
    "    \"\"\"\n",
    "    length = seq.shape[0]\n",
    "    num_features = seq.shape[1]\n",
    "    \n",
    "    if length > max_len:\n",
    "        # Truncate\n",
    "        return seq[:max_len, :]\n",
    "    else:\n",
    "        # Pad with zeros\n",
    "        padded = np.zeros((max_len, num_features))\n",
    "        padded[:length, :] = seq\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of data: (210, 5, 132)\n"
     ]
    }
   ],
   "source": [
    "X_seq_padded = []\n",
    "\n",
    "for seq in X_sequences:\n",
    "    seq_padded = pad_or_truncate_sequence(seq, max_len=MAX_SEQ_LEN)\n",
    "    X_seq_padded.append(seq_padded)\n",
    "\n",
    "X_seq_padded = np.array(X_seq_padded)  # shape => (num_videos, MAX_SEQ_LEN, 132)\n",
    "\n",
    "print(\"Final shape of data:\", X_seq_padded.shape)\n",
    "# Should be (N, 20, 132) if MAX_SEQ_LEN=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to CSV file for visualization and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode Labels and Split Data\n",
    "\n",
    "We use LabelEncoder to convert \"Kicking\", \"Punching\", \"Non-violent\" into numeric IDs: e.g. 0, 1, 2.\n",
    "\n",
    "Then we split into train/test sets (e.g., 80/20) for fair evaluation.\n",
    "\n",
    "We store them as X_train, X_test, y_train, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (168, 5, 132) Test shape: (42, 5, 132)\n",
      "Train labels shape: (168,) Test labels shape: (42,)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_int = label_encoder.fit_transform(y_labels)  \n",
    "# e.g. \"Kick\"->0, \"Punching\"->2, \"Non-violent\"->1 (the mapping depends on alphabetical order)\n",
    "\n",
    "# Convert to NumPy\n",
    "y_int = np.array(y_int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq_padded, \n",
    "    y_int, \n",
    "    test_size=0.2, \n",
    "    stratify=y_int,  # keep classes balanced\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", y_train.shape, \"Test labels shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and Evaluate Machine Learning Classification Model \n",
    "\n",
    "We create a sequential Keras model with an LSTM layer (64 units) returning sequences, followed by another LSTM (32 units), then a Dense layer for classification.\n",
    "\n",
    "Use sparse_categorical_crossentropy since we have integer labels (0, 1, 2).\n",
    "\n",
    "num_classes is the length of label_encoder.classes_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 210 \n",
      "MAX_SEQ_LEN: 5 \n",
      "NUM_FEATURES: 132 \n",
      "num_classes: 4\n"
     ]
    }
   ],
   "source": [
    "PATIENCE = 10\n",
    "N, MAX_SEQ_LEN, NUM_FEATURES = X_seq_padded.shape\n",
    "NUM_CLASSES = len(np.unique(y_int))\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "print(\"N:\", N, \"\\nMAX_SEQ_LEN:\", MAX_SEQ_LEN, \"\\nNUM_FEATURES:\", NUM_FEATURES, \"\\nnum_classes:\", NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Build and Train LSTM Model\n",
    "\n",
    "**Dropout:** Applied to the non-recurrent connections within a layer. This means it randomly drops neurons (and their connections) during the forward pass in the current time step.\n",
    "+ Applies to the input connections going into the LSTM/GRU cell.\n",
    "+ At each time step t, some input features are randomly \"dropped\" (set to zero) with probability dropout.\n",
    "+ Helps prevent overfitting from relying too heavily on specific input features.\n",
    "\n",
    "**Recurrent Dropout:** Applied to the recurrent connections within a recurrent layer (like LSTM or GRU). This means it randomly drops connections between the recurrent units across time steps. \n",
    "+ Applies to the recurrent connections (i.e., the hidden state passed between time steps). \n",
    "+ At each time step t, some units in the hidden state are randomly dropped before being passed to the next time step.\n",
    "+ Helps prevent overfitting by regularizing how much the network can memorize across time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(\n",
    "    max_seq_len=MAX_SEQ_LEN, \n",
    "    num_features=NUM_FEATURES, \n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout_rate=0.3, \n",
    "    recurrent_dropout_rate=0.3\n",
    "):\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(max_seq_len, num_features)),\n",
    "        layers.LSTM(64, \n",
    "                    return_sequences=True, \n",
    "                    dropout=dropout_rate, \n",
    "                    recurrent_dropout=recurrent_dropout_rate),\n",
    "        layers.LSTM(32, \n",
    "                    dropout=dropout_rate, \n",
    "                    recurrent_dropout=recurrent_dropout_rate),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m50,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,980</span> (246.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,980\u001b[0m (246.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,980</span> (246.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,980\u001b[0m (246.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "build_lstm_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "def kfold_validation(save_model_path, k=5, model_fn=None, epochs=EPOCH, patience=PATIENCE, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    k: Number of folds\n",
    "    model_fn: A function that returns a freshly compiled model. \n",
    "              Example: build_lstm_model() or build_gru_model()\n",
    "    epochs: Max number of epochs\n",
    "    batch_size: training batch size\n",
    "    patience: early stopping patience\n",
    "    \n",
    "    Returns a dictionary with:\n",
    "      - fold_accuracies: list of accuracy for each fold\n",
    "      - mean_acc: average accuracy across folds\n",
    "      - std_acc: standard deviation of accuracy\n",
    "      - fold_histories: list of 'history.history' from model.fit for each fold\n",
    "      - confusion_matrices: list of confusion matrices for each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_histories = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    fold_index = 1\n",
    "    for train_index, val_index in kf.split(X_seq_padded):\n",
    "        print(f\"\\n=== Fold {fold_index} ===\")\n",
    "        fold_index += 1\n",
    "        \n",
    "        # Split into train/val sets\n",
    "        X_train, X_val = X_seq_padded[train_index], X_seq_padded[val_index]\n",
    "        y_train, y_val = y_int[train_index], y_int[val_index]\n",
    "        \n",
    "        # Build a fresh model for this fold\n",
    "        if model_fn is None:\n",
    "            raise ValueError(\"Please provide a model-building function (model_fn).\")\n",
    "        model = model_fn()  # e.g. build_lstm_model()\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save training history dict\n",
    "        fold_histories.append(history.history)\n",
    "        \n",
    "        # Evaluate on the fold's val set\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_preds_label = np.argmax(val_preds, axis=1)\n",
    "        acc = accuracy_score(y_val, val_preds_label)\n",
    "        print(f\"Fold Validation Accuracy = {acc:.4f}\")\n",
    "        \n",
    "        fold_accuracies.append(acc)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_val, val_preds_label)\n",
    "        confusion_matrices.append(cm)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        \n",
    "        # Classification Report\n",
    "        print(\"Classification Report:\\n\",\n",
    "              classification_report(y_val, val_preds_label,\n",
    "                                    target_names=label_encoder.classes_,\n",
    "                                    labels=np.arange(NUM_CLASSES)))\n",
    "    \n",
    "    model.save(save_model_path)  # or \"my_model\" for SavedModel format\n",
    "    \n",
    "    # Compute average accuracy\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "    print(f\"\\n=== Final Cross-Validation Results ===\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f} (std: {std_acc:.4f})\")\n",
    "    \n",
    "    results = {\n",
    "        \"fold_accuracies\": fold_accuracies,\n",
    "        \"mean_acc\": mean_acc,\n",
    "        \"std_acc\": std_acc,\n",
    "        \"fold_histories\": fold_histories,         # ADDED\n",
    "        \"confusion_matrices\": confusion_matrices  # ADDED\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.2537 - loss: 1.1463 - val_accuracy: 0.5000 - val_loss: 1.0530\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4036 - loss: 1.0845 - val_accuracy: 0.5625 - val_loss: 1.0547\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4526 - loss: 1.0434 - val_accuracy: 0.5625 - val_loss: 1.0246\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6475 - loss: 0.9684 - val_accuracy: 0.5000 - val_loss: 0.9754\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5862 - loss: 0.9243 - val_accuracy: 0.6875 - val_loss: 0.9512\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7531 - loss: 0.8509 - val_accuracy: 0.6250 - val_loss: 0.9790\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7333 - loss: 0.7571 - val_accuracy: 0.5625 - val_loss: 0.9445\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6619 - loss: 0.7413 - val_accuracy: 0.6250 - val_loss: 0.9067\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7454 - loss: 0.6440 - val_accuracy: 0.6875 - val_loss: 0.8649\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8114 - loss: 0.5240 - val_accuracy: 0.6250 - val_loss: 0.9812\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6670 - loss: 0.6278 - val_accuracy: 0.6250 - val_loss: 0.9195\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7406 - loss: 0.6006 - val_accuracy: 0.5625 - val_loss: 0.8910\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8588 - loss: 0.4586 - val_accuracy: 0.6875 - val_loss: 1.0581\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8174 - loss: 0.5035 - val_accuracy: 0.5000 - val_loss: 0.8981\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8352 - loss: 0.4582 - val_accuracy: 0.6250 - val_loss: 0.9157\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8392 - loss: 0.4390 - val_accuracy: 0.6875 - val_loss: 0.8988\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7802 - loss: 0.5193 - val_accuracy: 0.5625 - val_loss: 0.8781\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7769 - loss: 0.4374 - val_accuracy: 0.6250 - val_loss: 0.8511\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7408 - loss: 0.5709 - val_accuracy: 0.5625 - val_loss: 0.8623\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8691 - loss: 0.4132 - val_accuracy: 0.6250 - val_loss: 0.8940\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8301 - loss: 0.5514 - val_accuracy: 0.5625 - val_loss: 0.8413\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8599 - loss: 0.3287 - val_accuracy: 0.6250 - val_loss: 0.9019\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7343 - loss: 0.6104 - val_accuracy: 0.6250 - val_loss: 0.9062\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8352 - loss: 0.3398 - val_accuracy: 0.6250 - val_loss: 0.9486\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8695 - loss: 0.4146 - val_accuracy: 0.6250 - val_loss: 0.9217\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8420 - loss: 0.3952 - val_accuracy: 0.6250 - val_loss: 0.9212\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8388 - loss: 0.4671 - val_accuracy: 0.6250 - val_loss: 0.9909\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8438 - loss: 0.4460 - val_accuracy: 0.6250 - val_loss: 1.0026\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8620 - loss: 0.3892 - val_accuracy: 0.5625 - val_loss: 0.9343\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7681 - loss: 0.5178 - val_accuracy: 0.6250 - val_loss: 0.8873\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7226 - loss: 0.5015 - val_accuracy: 0.6250 - val_loss: 0.9115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926ms/step\n",
      "Fold Validation Accuracy = 0.5625\n",
      "Confusion Matrix:\n",
      " [[2 1 2]\n",
      " [1 1 1]\n",
      " [2 0 6]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       0.40      0.40      0.40         5\n",
      " Non-violent       0.50      0.33      0.40         3\n",
      "    Punching       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.52      0.49      0.50        16\n",
      "weighted avg       0.55      0.56      0.55        16\n",
      "\n",
      "\n",
      "=== Fold 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.2607 - loss: 1.1075 - val_accuracy: 0.3125 - val_loss: 1.0979\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3867 - loss: 1.0686 - val_accuracy: 0.3125 - val_loss: 1.0763\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4475 - loss: 1.0569 - val_accuracy: 0.4375 - val_loss: 1.0233\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4605 - loss: 0.9789 - val_accuracy: 0.6875 - val_loss: 0.9138\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6049 - loss: 0.9596 - val_accuracy: 0.9375 - val_loss: 0.8287\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6419 - loss: 0.8708 - val_accuracy: 0.8750 - val_loss: 0.7714\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6670 - loss: 0.8103 - val_accuracy: 0.9375 - val_loss: 0.6546\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7417 - loss: 0.7313 - val_accuracy: 0.9375 - val_loss: 0.5771\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6762 - loss: 0.7488 - val_accuracy: 0.9375 - val_loss: 0.4648\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7669 - loss: 0.6893 - val_accuracy: 0.8125 - val_loss: 0.4706\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6577 - loss: 0.6570 - val_accuracy: 0.9375 - val_loss: 0.3537\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6538 - loss: 0.7192 - val_accuracy: 0.9375 - val_loss: 0.3580\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6499 - loss: 0.7089 - val_accuracy: 0.9375 - val_loss: 0.3663\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7187 - loss: 0.6151 - val_accuracy: 0.9375 - val_loss: 0.2983\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7047 - loss: 0.7217 - val_accuracy: 0.9375 - val_loss: 0.2940\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8069 - loss: 0.6973 - val_accuracy: 0.8750 - val_loss: 0.3105\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7904 - loss: 0.6111 - val_accuracy: 0.9375 - val_loss: 0.2710\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7284 - loss: 0.5757 - val_accuracy: 0.9375 - val_loss: 0.2701\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7092 - loss: 0.6097 - val_accuracy: 0.9375 - val_loss: 0.2912\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7686 - loss: 0.6491 - val_accuracy: 0.9375 - val_loss: 0.2783\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8088 - loss: 0.6413 - val_accuracy: 0.9375 - val_loss: 0.2873\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7859 - loss: 0.5377 - val_accuracy: 0.9375 - val_loss: 0.2379\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7376 - loss: 0.6202 - val_accuracy: 0.9375 - val_loss: 0.2530\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7090 - loss: 0.5950 - val_accuracy: 0.9375 - val_loss: 0.2288\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8175 - loss: 0.5130 - val_accuracy: 0.8750 - val_loss: 0.2965\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7703 - loss: 0.5189 - val_accuracy: 0.9375 - val_loss: 0.2540\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8632 - loss: 0.4418 - val_accuracy: 0.8750 - val_loss: 0.2633\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8346 - loss: 0.5353 - val_accuracy: 0.9375 - val_loss: 0.1862\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6803 - loss: 0.6409 - val_accuracy: 0.8750 - val_loss: 0.2883\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8039 - loss: 0.4710 - val_accuracy: 0.8750 - val_loss: 0.2669\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8079 - loss: 0.4992 - val_accuracy: 0.9375 - val_loss: 0.2133\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8663 - loss: 0.5539 - val_accuracy: 0.9375 - val_loss: 0.2412\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8134 - loss: 0.5578 - val_accuracy: 0.9375 - val_loss: 0.2162\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7864 - loss: 0.5964 - val_accuracy: 0.8750 - val_loss: 0.2458\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7778 - loss: 0.5961 - val_accuracy: 0.9375 - val_loss: 0.2068\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7108 - loss: 0.5658 - val_accuracy: 0.9375 - val_loss: 0.2006\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7164 - loss: 0.6623 - val_accuracy: 0.9375 - val_loss: 0.2072\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8521 - loss: 0.5385 - val_accuracy: 1.0000 - val_loss: 0.2290\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step\n",
      "Fold Validation Accuracy = 0.9375\n",
      "Confusion Matrix:\n",
      " [[2 0 1]\n",
      " [0 8 0]\n",
      " [0 0 5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      0.67      0.80         3\n",
      " Non-violent       1.00      1.00      1.00         8\n",
      "    Punching       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.94      0.89      0.90        16\n",
      "weighted avg       0.95      0.94      0.93        16\n",
      "\n",
      "\n",
      "=== Fold 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - accuracy: 0.4040 - loss: 1.0866 - val_accuracy: 0.3125 - val_loss: 1.0750\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3820 - loss: 1.0491 - val_accuracy: 0.5000 - val_loss: 1.1157\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5587 - loss: 1.0046 - val_accuracy: 0.5625 - val_loss: 1.0881\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5963 - loss: 0.9713 - val_accuracy: 0.5625 - val_loss: 1.0321\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5413 - loss: 0.9450 - val_accuracy: 0.5625 - val_loss: 0.9276\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6553 - loss: 0.8188 - val_accuracy: 0.6250 - val_loss: 0.7939\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7430 - loss: 0.7908 - val_accuracy: 0.6875 - val_loss: 0.7247\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7570 - loss: 0.7192 - val_accuracy: 0.6250 - val_loss: 0.6872\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6655 - loss: 0.7366 - val_accuracy: 0.6250 - val_loss: 0.6152\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6954 - loss: 0.7035 - val_accuracy: 0.6250 - val_loss: 0.7045\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8024 - loss: 0.5420 - val_accuracy: 0.8125 - val_loss: 0.5575\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7300 - loss: 0.6054 - val_accuracy: 0.7500 - val_loss: 0.5419\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7620 - loss: 0.6422 - val_accuracy: 0.8125 - val_loss: 0.5111\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7851 - loss: 0.5546 - val_accuracy: 0.8125 - val_loss: 0.4844\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7358 - loss: 0.5611 - val_accuracy: 0.8125 - val_loss: 0.5226\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7792 - loss: 0.5096 - val_accuracy: 0.7500 - val_loss: 0.5581\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8008 - loss: 0.5209 - val_accuracy: 0.6875 - val_loss: 0.6984\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7688 - loss: 0.5288 - val_accuracy: 0.8125 - val_loss: 0.5094\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7432 - loss: 0.5698 - val_accuracy: 0.8125 - val_loss: 0.5002\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7928 - loss: 0.5268 - val_accuracy: 0.7500 - val_loss: 0.5405\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8114 - loss: 0.4861 - val_accuracy: 0.6875 - val_loss: 0.6513\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7694 - loss: 0.6607 - val_accuracy: 0.8750 - val_loss: 0.4385\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8441 - loss: 0.4974 - val_accuracy: 0.7500 - val_loss: 0.6445\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7637 - loss: 0.4966 - val_accuracy: 0.7500 - val_loss: 0.5480\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8354 - loss: 0.5078 - val_accuracy: 0.8750 - val_loss: 0.4606\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7841 - loss: 0.5336 - val_accuracy: 0.8125 - val_loss: 0.4842\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7952 - loss: 0.5341 - val_accuracy: 0.6875 - val_loss: 0.6499\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8512 - loss: 0.4766 - val_accuracy: 0.6875 - val_loss: 0.5616\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8023 - loss: 0.4171 - val_accuracy: 0.8125 - val_loss: 0.4816\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8202 - loss: 0.4225 - val_accuracy: 0.6875 - val_loss: 0.6635\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7151 - loss: 0.7010 - val_accuracy: 0.8125 - val_loss: 0.4639\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8862 - loss: 0.3487 - val_accuracy: 0.8750 - val_loss: 0.4427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
      "Fold Validation Accuracy = 0.8750\n",
      "Confusion Matrix:\n",
      " [[5 0 2]\n",
      " [0 4 0]\n",
      " [0 0 5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      0.71      0.83         7\n",
      " Non-violent       1.00      1.00      1.00         4\n",
      "    Punching       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.90      0.90      0.89        16\n",
      "weighted avg       0.91      0.88      0.88        16\n",
      "\n",
      "\n",
      "=== Fold 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.4060 - loss: 1.0715 - val_accuracy: 0.1250 - val_loss: 1.0638\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6280 - loss: 0.9884 - val_accuracy: 0.6875 - val_loss: 0.9269\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5098 - loss: 1.0091 - val_accuracy: 0.7500 - val_loss: 0.8374\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6187 - loss: 0.9685 - val_accuracy: 0.8750 - val_loss: 0.7427\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6180 - loss: 0.8937 - val_accuracy: 0.8125 - val_loss: 0.6537\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5816 - loss: 0.8658 - val_accuracy: 0.8750 - val_loss: 0.5678\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6951 - loss: 0.7454 - val_accuracy: 0.9375 - val_loss: 0.4676\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6034 - loss: 0.7810 - val_accuracy: 0.8125 - val_loss: 0.4015\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6222 - loss: 0.6963 - val_accuracy: 0.9375 - val_loss: 0.4045\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6407 - loss: 0.7617 - val_accuracy: 0.8750 - val_loss: 0.4414\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7949 - loss: 0.6795 - val_accuracy: 0.8750 - val_loss: 0.4008\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7303 - loss: 0.6780 - val_accuracy: 0.8125 - val_loss: 0.3919\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7371 - loss: 0.6532 - val_accuracy: 0.9375 - val_loss: 0.2760\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5901 - loss: 0.7738 - val_accuracy: 0.8750 - val_loss: 0.3993\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7588 - loss: 0.6507 - val_accuracy: 0.8125 - val_loss: 0.4756\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8005 - loss: 0.5978 - val_accuracy: 0.9375 - val_loss: 0.3165\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7261 - loss: 0.7201 - val_accuracy: 0.9375 - val_loss: 0.2901\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6193 - loss: 0.7124 - val_accuracy: 0.9375 - val_loss: 0.3039\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7746 - loss: 0.5594 - val_accuracy: 0.8750 - val_loss: 0.3248\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7346 - loss: 0.6419 - val_accuracy: 0.8750 - val_loss: 0.4023\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6954 - loss: 0.6197 - val_accuracy: 0.9375 - val_loss: 0.2785\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7696 - loss: 0.6026 - val_accuracy: 0.8750 - val_loss: 0.3339\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6989 - loss: 0.5507 - val_accuracy: 0.8750 - val_loss: 0.3125\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027615BD2200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027615BD2200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684ms/step\n",
      "Fold Validation Accuracy = 0.9375\n",
      "Confusion Matrix:\n",
      " [[1 0 1]\n",
      " [0 6 0]\n",
      " [0 0 8]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      0.50      0.67         2\n",
      " Non-violent       1.00      1.00      1.00         6\n",
      "    Punching       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.96      0.83      0.87        16\n",
      "weighted avg       0.94      0.94      0.93        16\n",
      "\n",
      "\n",
      "=== Fold 5 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.2713 - loss: 1.0980 - val_accuracy: 0.4000 - val_loss: 1.0626\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4638 - loss: 1.0455 - val_accuracy: 0.4000 - val_loss: 1.0371\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5444 - loss: 0.9854 - val_accuracy: 0.5333 - val_loss: 0.9893\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6866 - loss: 0.9360 - val_accuracy: 0.6000 - val_loss: 0.9337\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5877 - loss: 0.9052 - val_accuracy: 0.6000 - val_loss: 0.8974\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6478 - loss: 0.8206 - val_accuracy: 0.6000 - val_loss: 0.8102\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6496 - loss: 0.8320 - val_accuracy: 0.6667 - val_loss: 0.8136\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8038 - loss: 0.6296 - val_accuracy: 0.6000 - val_loss: 0.8576\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6219 - loss: 0.8302 - val_accuracy: 0.6000 - val_loss: 0.7444\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7752 - loss: 0.5842 - val_accuracy: 0.7333 - val_loss: 0.8328\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8618 - loss: 0.5832 - val_accuracy: 0.6667 - val_loss: 0.7783\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7963 - loss: 0.5060 - val_accuracy: 0.6667 - val_loss: 0.7616\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6094 - loss: 0.6644 - val_accuracy: 0.7333 - val_loss: 0.8836\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8431 - loss: 0.4874 - val_accuracy: 0.7333 - val_loss: 0.8464\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7748 - loss: 0.5585 - val_accuracy: 0.7333 - val_loss: 0.7237\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7612 - loss: 0.5678 - val_accuracy: 0.7333 - val_loss: 0.8201\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8385 - loss: 0.4541 - val_accuracy: 0.7333 - val_loss: 0.7847\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8750 - loss: 0.3634 - val_accuracy: 0.7333 - val_loss: 0.7634\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8177 - loss: 0.4222 - val_accuracy: 0.7333 - val_loss: 0.8020\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8164 - loss: 0.3985 - val_accuracy: 0.7333 - val_loss: 0.7179\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9047 - loss: 0.3805 - val_accuracy: 0.7333 - val_loss: 0.6950\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7448 - loss: 0.5576 - val_accuracy: 0.7333 - val_loss: 0.8872\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8567 - loss: 0.4298 - val_accuracy: 0.7333 - val_loss: 0.7587\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9109 - loss: 0.3750 - val_accuracy: 0.7333 - val_loss: 0.7141\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8328 - loss: 0.4468 - val_accuracy: 0.7333 - val_loss: 0.7101\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7881 - loss: 0.4354 - val_accuracy: 0.7333 - val_loss: 0.9541\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8326 - loss: 0.4619 - val_accuracy: 0.7333 - val_loss: 0.6573\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8010 - loss: 0.4645 - val_accuracy: 0.7333 - val_loss: 0.6985\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7647 - loss: 0.5746 - val_accuracy: 0.7333 - val_loss: 0.8962\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8937 - loss: 0.3654 - val_accuracy: 0.7333 - val_loss: 0.7057\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8350 - loss: 0.4555 - val_accuracy: 0.7333 - val_loss: 0.8672\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7984 - loss: 0.4551 - val_accuracy: 0.7333 - val_loss: 0.7289\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6961 - loss: 0.5784 - val_accuracy: 0.7333 - val_loss: 0.8493\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7239 - loss: 0.5872 - val_accuracy: 0.6667 - val_loss: 0.7845\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7790 - loss: 0.5552 - val_accuracy: 0.7333 - val_loss: 0.8494\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8405 - loss: 0.4240 - val_accuracy: 0.7333 - val_loss: 0.7064\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8722 - loss: 0.3985 - val_accuracy: 0.6667 - val_loss: 0.6558\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8771 - loss: 0.3516 - val_accuracy: 0.7333 - val_loss: 0.9318\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8170 - loss: 0.4185 - val_accuracy: 0.7333 - val_loss: 0.8641\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7615 - loss: 0.4697 - val_accuracy: 0.7333 - val_loss: 0.6622\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8975 - loss: 0.3132 - val_accuracy: 0.7333 - val_loss: 0.8674\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9229 - loss: 0.2819 - val_accuracy: 0.7333 - val_loss: 0.7588\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9187 - loss: 0.2675 - val_accuracy: 0.8000 - val_loss: 0.6283\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9145 - loss: 0.3101 - val_accuracy: 0.7333 - val_loss: 0.9551\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8172 - loss: 0.4088 - val_accuracy: 0.7333 - val_loss: 0.7084\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7273 - loss: 0.6137 - val_accuracy: 0.8667 - val_loss: 0.5894\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8166 - loss: 0.4138 - val_accuracy: 0.7333 - val_loss: 0.9582\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9272 - loss: 0.2927 - val_accuracy: 0.7333 - val_loss: 0.7937\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8688 - loss: 0.4205 - val_accuracy: 0.7333 - val_loss: 0.7020\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7733 - loss: 0.4872 - val_accuracy: 0.7333 - val_loss: 0.5926\n",
      "WARNING:tensorflow:6 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002762C84BAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002762C84BAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Validation Accuracy = 0.8667\n",
      "Confusion Matrix:\n",
      " [[4 0 0]\n",
      " [2 3 0]\n",
      " [0 0 6]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       0.67      1.00      0.80         4\n",
      " Non-violent       1.00      0.60      0.75         5\n",
      "    Punching       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.89      0.87      0.85        15\n",
      "weighted avg       0.91      0.87      0.86        15\n",
      "\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Mean Accuracy: 0.8358 (std: 0.1399)\n",
      "LSTM results: {'fold_accuracies': [0.5625, 0.9375, 0.875, 0.9375, 0.8666666666666667], 'mean_acc': 0.8358333333333334, 'std_acc': 0.139905722224329, 'fold_histories': [{'accuracy': [0.3174603283405304, 0.4444444477558136, 0.5079365372657776, 0.6190476417541504, 0.6190476417541504, 0.7142857313156128, 0.7460317611694336, 0.682539701461792, 0.761904776096344, 0.8095238208770752, 0.682539701461792, 0.7777777910232544, 0.7936508059501648, 0.8095238208770752, 0.8095238208770752, 0.841269850730896, 0.8095238208770752, 0.7460317611694336, 0.8095238208770752, 0.8095238208770752, 0.8253968358039856, 0.8253968358039856, 0.8095238208770752, 0.8095238208770752, 0.8888888955116272, 0.8730158805847168, 0.8571428656578064, 0.8095238208770752, 0.8253968358039856, 0.7777777910232544, 0.7936508059501648], 'loss': [1.1259390115737915, 1.0817548036575317, 1.031720519065857, 0.9739256501197815, 0.9059779047966003, 0.8585606813430786, 0.7113123536109924, 0.6849968433380127, 0.6142314076423645, 0.5321763753890991, 0.6489902138710022, 0.5657787919044495, 0.590194582939148, 0.5109720230102539, 0.5099722146987915, 0.4866669774055481, 0.5006321668624878, 0.4994184970855713, 0.4772442579269409, 0.5088686943054199, 0.4821341335773468, 0.4209092855453491, 0.5006358027458191, 0.399447500705719, 0.40998369455337524, 0.3911062777042389, 0.4131046533584595, 0.49007388949394226, 0.4051550626754761, 0.49923381209373474, 0.4332803189754486], 'val_accuracy': [0.5, 0.5625, 0.5625, 0.5, 0.6875, 0.625, 0.5625, 0.625, 0.6875, 0.625, 0.625, 0.5625, 0.6875, 0.5, 0.625, 0.6875, 0.5625, 0.625, 0.5625, 0.625, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.625, 0.625], 'val_loss': [1.0530152320861816, 1.0546839237213135, 1.0246176719665527, 0.9753974080085754, 0.9511970281600952, 0.9790453910827637, 0.9444800615310669, 0.9067230224609375, 0.8649172782897949, 0.9812058210372925, 0.9195013642311096, 0.8909869194030762, 1.0581181049346924, 0.8980920314788818, 0.9156967997550964, 0.8987732529640198, 0.8780807852745056, 0.8510560989379883, 0.8623326420783997, 0.894005298614502, 0.8413375020027161, 0.9018607139587402, 0.9062145948410034, 0.9486077427864075, 0.9216710925102234, 0.9212017059326172, 0.9909323453903198, 1.0025849342346191, 0.9343304634094238, 0.887265682220459, 0.9114580154418945]}, {'accuracy': [0.30158731341362, 0.4285714328289032, 0.4761904776096344, 0.460317462682724, 0.6507936716079712, 0.60317462682724, 0.682539701461792, 0.682539701461792, 0.682539701461792, 0.7301587462425232, 0.6190476417541504, 0.6507936716079712, 0.682539701461792, 0.682539701461792, 0.6984127163887024, 0.7936508059501648, 0.7777777910232544, 0.7460317611694336, 0.7301587462425232, 0.7460317611694336, 0.7936508059501648, 0.7777777910232544, 0.7301587462425232, 0.7301587462425232, 0.761904776096344, 0.761904776096344, 0.8095238208770752, 0.8571428656578064, 0.7142857313156128, 0.8095238208770752, 0.7777777910232544, 0.7936508059501648, 0.8095238208770752, 0.8095238208770752, 0.7936508059501648, 0.7301587462425232, 0.7301587462425232, 0.8253968358039856], 'loss': [1.0908900499343872, 1.0460925102233887, 1.0122874975204468, 0.969506025314331, 0.9344828724861145, 0.9118253588676453, 0.8137602806091309, 0.7323446869850159, 0.7963839173316956, 0.7019793391227722, 0.7275062799453735, 0.745151937007904, 0.7211071252822876, 0.6912047266960144, 0.730469286441803, 0.6684992909431458, 0.605312705039978, 0.6463080048561096, 0.6460874676704407, 0.6896951794624329, 0.642984926700592, 0.5467885136604309, 0.6316507458686829, 0.5819316506385803, 0.5942420363426208, 0.535153329372406, 0.5723036527633667, 0.5116034150123596, 0.6315814256668091, 0.5250215530395508, 0.5234621167182922, 0.6427360773086548, 0.5711151361465454, 0.5723876357078552, 0.5526620745658875, 0.583242654800415, 0.6221170425415039, 0.5829467177391052], 'val_accuracy': [0.3125, 0.3125, 0.4375, 0.6875, 0.9375, 0.875, 0.9375, 0.9375, 0.9375, 0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.875, 0.9375, 0.875, 0.875, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.9375, 0.9375, 1.0], 'val_loss': [1.097918152809143, 1.0762789249420166, 1.0233283042907715, 0.9137893915176392, 0.8287273645401001, 0.7713651061058044, 0.6546081304550171, 0.5771198868751526, 0.46476221084594727, 0.4705938994884491, 0.35372528433799744, 0.35796546936035156, 0.3663329482078552, 0.2983076572418213, 0.29397672414779663, 0.3104560971260071, 0.27101609110832214, 0.2700984477996826, 0.2911880612373352, 0.2783403992652893, 0.2873424291610718, 0.23794445395469666, 0.25302326679229736, 0.2288151979446411, 0.29651424288749695, 0.2540459632873535, 0.26325565576553345, 0.1861906349658966, 0.28833380341529846, 0.2668594717979431, 0.21334347128868103, 0.2411758005619049, 0.21620945632457733, 0.24578677117824554, 0.2068415880203247, 0.20059049129486084, 0.20716458559036255, 0.22895726561546326]}, {'accuracy': [0.380952388048172, 0.460317462682724, 0.5873016119003296, 0.6666666865348816, 0.6349206566810608, 0.682539701461792, 0.7777777910232544, 0.7777777910232544, 0.7142857313156128, 0.6984127163887024, 0.761904776096344, 0.761904776096344, 0.7936508059501648, 0.7936508059501648, 0.7301587462425232, 0.6984127163887024, 0.7936508059501648, 0.761904776096344, 0.7142857313156128, 0.7777777910232544, 0.7936508059501648, 0.761904776096344, 0.8095238208770752, 0.7936508059501648, 0.8095238208770752, 0.7936508059501648, 0.761904776096344, 0.841269850730896, 0.761904776096344, 0.7777777910232544, 0.7936508059501648, 0.7936508059501648], 'loss': [1.094396948814392, 1.0186513662338257, 0.975837230682373, 0.9224565029144287, 0.8485590219497681, 0.8009947538375854, 0.7345453500747681, 0.6975196599960327, 0.6826500296592712, 0.7032526135444641, 0.5895509719848633, 0.6105783581733704, 0.6161506772041321, 0.5630019903182983, 0.6102285385131836, 0.6201743483543396, 0.5783756971359253, 0.5782152414321899, 0.6353999376296997, 0.5203173160552979, 0.5189028382301331, 0.6138350367546082, 0.5092709064483643, 0.5191506147384644, 0.5321996808052063, 0.503073513507843, 0.5625954866409302, 0.48872891068458557, 0.4917446970939636, 0.5339361429214478, 0.5256330370903015, 0.43807050585746765], 'val_accuracy': [0.3125, 0.5, 0.5625, 0.5625, 0.5625, 0.625, 0.6875, 0.625, 0.625, 0.625, 0.8125, 0.75, 0.8125, 0.8125, 0.8125, 0.75, 0.6875, 0.8125, 0.8125, 0.75, 0.6875, 0.875, 0.75, 0.75, 0.875, 0.8125, 0.6875, 0.6875, 0.8125, 0.6875, 0.8125, 0.875], 'val_loss': [1.0750389099121094, 1.1156646013259888, 1.088106632232666, 1.032050371170044, 0.9275708198547363, 0.7938601970672607, 0.7246881723403931, 0.6871654987335205, 0.6151909828186035, 0.7044506669044495, 0.5574575662612915, 0.5418511033058167, 0.5111145973205566, 0.48437079787254333, 0.522648811340332, 0.5581366419792175, 0.698421061038971, 0.509432315826416, 0.5001881718635559, 0.5404630303382874, 0.6512874960899353, 0.43847721815109253, 0.6444560289382935, 0.5480148792266846, 0.4605816900730133, 0.4841812551021576, 0.6498593688011169, 0.5616099238395691, 0.4816480278968811, 0.663500964641571, 0.46390944719314575, 0.4427153468132019]}, {'accuracy': [0.3174603283405304, 0.5714285969734192, 0.5714285969734192, 0.6507936716079712, 0.60317462682724, 0.7142857313156128, 0.6349206566810608, 0.6349206566810608, 0.6349206566810608, 0.6666666865348816, 0.7301587462425232, 0.761904776096344, 0.7301587462425232, 0.6190476417541504, 0.7460317611694336, 0.7301587462425232, 0.7460317611694336, 0.6349206566810608, 0.7777777910232544, 0.761904776096344, 0.7460317611694336, 0.7460317611694336, 0.6984127163887024], 'loss': [1.1114164590835571, 1.0032227039337158, 0.9880702495574951, 0.9314614534378052, 0.899824857711792, 0.8041921257972717, 0.7969532608985901, 0.7983675003051758, 0.7089870572090149, 0.729351282119751, 0.7301912903785706, 0.6073378324508667, 0.6647077202796936, 0.7217894196510315, 0.6590526103973389, 0.6814014911651611, 0.639419436454773, 0.6956583261489868, 0.5630771517753601, 0.5473679900169373, 0.5659667253494263, 0.5782405734062195, 0.5993603467941284], 'val_accuracy': [0.125, 0.6875, 0.75, 0.875, 0.8125, 0.875, 0.9375, 0.8125, 0.9375, 0.875, 0.875, 0.8125, 0.9375, 0.875, 0.8125, 0.9375, 0.9375, 0.9375, 0.875, 0.875, 0.9375, 0.875, 0.875], 'val_loss': [1.063812017440796, 0.9269239902496338, 0.8374245762825012, 0.7427287101745605, 0.6536519527435303, 0.5677952170372009, 0.46756601333618164, 0.4015263319015503, 0.4045414626598358, 0.441358745098114, 0.4008023142814636, 0.3918807804584503, 0.27599310874938965, 0.3993013799190521, 0.47560644149780273, 0.3165156841278076, 0.29012811183929443, 0.30390113592147827, 0.32480502128601074, 0.4022974371910095, 0.278516560792923, 0.33390265703201294, 0.3124760687351227]}, {'accuracy': [0.296875, 0.453125, 0.5, 0.671875, 0.5625, 0.65625, 0.71875, 0.765625, 0.6875, 0.75, 0.8125, 0.75, 0.65625, 0.796875, 0.734375, 0.734375, 0.859375, 0.828125, 0.703125, 0.796875, 0.828125, 0.75, 0.875, 0.859375, 0.828125, 0.8125, 0.84375, 0.84375, 0.78125, 0.875, 0.8125, 0.8125, 0.796875, 0.796875, 0.84375, 0.859375, 0.875, 0.84375, 0.859375, 0.796875, 0.875, 0.859375, 0.890625, 0.90625, 0.828125, 0.78125, 0.796875, 0.90625, 0.859375, 0.796875], 'loss': [1.0878595113754272, 1.0370234251022339, 1.013826608657837, 0.9316493272781372, 0.9054971933364868, 0.8030211329460144, 0.7559854388237, 0.679504930973053, 0.7050740122795105, 0.5997169613838196, 0.5838465690612793, 0.5822470784187317, 0.6000794172286987, 0.5672616362571716, 0.571566641330719, 0.6098734140396118, 0.3903942406177521, 0.4326888918876648, 0.5597578287124634, 0.4636344015598297, 0.43277648091316223, 0.5371694564819336, 0.3843584656715393, 0.4274696111679077, 0.44489213824272156, 0.4426925778388977, 0.4299982488155365, 0.40157872438430786, 0.5116184949874878, 0.3990757167339325, 0.4634559154510498, 0.4271410405635834, 0.4753708243370056, 0.5056450963020325, 0.42097699642181396, 0.39466336369514465, 0.3902778625488281, 0.3986639678478241, 0.3341079354286194, 0.39571282267570496, 0.3312223255634308, 0.4388491213321686, 0.304014652967453, 0.32099616527557373, 0.36461740732192993, 0.49061527848243713, 0.4682210683822632, 0.3320333957672119, 0.37352895736694336, 0.4207967519760132], 'val_accuracy': [0.4000000059604645, 0.4000000059604645, 0.5333333611488342, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6666666865348816, 0.6000000238418579, 0.6000000238418579, 0.7333333492279053, 0.6666666865348816, 0.6666666865348816, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.6666666865348816, 0.7333333492279053, 0.7333333492279053, 0.6666666865348816, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.800000011920929, 0.7333333492279053, 0.7333333492279053, 0.8666666746139526, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053], 'val_loss': [1.062577486038208, 1.0370938777923584, 0.9892936944961548, 0.933731734752655, 0.8974382281303406, 0.8102115392684937, 0.813595175743103, 0.8576279282569885, 0.7444222569465637, 0.8328158259391785, 0.7783380150794983, 0.761588990688324, 0.8836432099342346, 0.8463832139968872, 0.7236509919166565, 0.8200536370277405, 0.7847186326980591, 0.7633923888206482, 0.8019967675209045, 0.717948853969574, 0.6949531435966492, 0.8872117400169373, 0.7587407231330872, 0.7140670418739319, 0.7100857496261597, 0.9540654420852661, 0.6572832465171814, 0.6984551548957825, 0.8961693048477173, 0.7056551575660706, 0.8672106266021729, 0.728908896446228, 0.8493449091911316, 0.7845203280448914, 0.8494224548339844, 0.7063533663749695, 0.6558479070663452, 0.9318094849586487, 0.8640676140785217, 0.6622253656387329, 0.8673628568649292, 0.7587815523147583, 0.6282886862754822, 0.9551345705986023, 0.7084206342697144, 0.5894095301628113, 0.9581862092018127, 0.7937349677085876, 0.7019985318183899, 0.5925674438476562]}], 'confusion_matrices': [array([[2, 1, 2],\n",
      "       [1, 1, 1],\n",
      "       [2, 0, 6]], dtype=int64), array([[2, 0, 1],\n",
      "       [0, 8, 0],\n",
      "       [0, 0, 5]], dtype=int64), array([[5, 0, 2],\n",
      "       [0, 4, 0],\n",
      "       [0, 0, 5]], dtype=int64), array([[1, 0, 1],\n",
      "       [0, 6, 0],\n",
      "       [0, 0, 8]], dtype=int64), array([[4, 0, 0],\n",
      "       [2, 3, 0],\n",
      "       [0, 0, 6]], dtype=int64)]}\n"
     ]
    }
   ],
   "source": [
    "# And a model function (like the build_lstm_model above).\n",
    "results_lstm = kfold_validation(save_model_path=\"lstm_model.h5\", model_fn=build_lstm_model)\n",
    "# This prints out each fold's accuracy, confusion matrix, classification report\n",
    "# Then returns a dictionary with the final cross-validation results.\n",
    "print(\"LSTM results:\", results_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Build and Train GRU Model\n",
    "Similar to LSTM but we replace layers.LSTM with layers.GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,016</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m38,016\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,523</span> (185.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,523\u001b[0m (185.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,523</span> (185.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,523\u001b[0m (185.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_gru_model(\n",
    "    max_seq_len=MAX_SEQ_LEN, \n",
    "    num_features=NUM_FEATURES, \n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout_rate=0.3, \n",
    "    recurrent_dropout_rate=0.3\n",
    "):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(max_seq_len, num_features)),\n",
    "        layers.GRU(64, \n",
    "                   return_sequences=True, \n",
    "                   dropout=dropout_rate, \n",
    "                   recurrent_dropout=recurrent_dropout_rate),\n",
    "        layers.GRU(32, \n",
    "                   dropout=dropout_rate, \n",
    "                   recurrent_dropout=recurrent_dropout_rate),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "build_gru_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 142ms/step - accuracy: 0.4455 - loss: 1.1217 - val_accuracy: 0.5000 - val_loss: 1.0163\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4355 - loss: 1.0990 - val_accuracy: 0.5000 - val_loss: 0.9555\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6246 - loss: 0.9319 - val_accuracy: 0.4375 - val_loss: 0.9961\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5945 - loss: 0.8781 - val_accuracy: 0.6250 - val_loss: 0.9314\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6457 - loss: 0.8240 - val_accuracy: 0.5000 - val_loss: 0.8797\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6280 - loss: 0.8157 - val_accuracy: 0.6250 - val_loss: 0.8437\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6919 - loss: 0.7869 - val_accuracy: 0.6250 - val_loss: 0.8273\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7978 - loss: 0.5779 - val_accuracy: 0.6875 - val_loss: 0.8678\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8569 - loss: 0.5869 - val_accuracy: 0.5625 - val_loss: 0.8611\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7943 - loss: 0.5364 - val_accuracy: 0.6250 - val_loss: 0.8408\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7707 - loss: 0.5790 - val_accuracy: 0.6875 - val_loss: 0.8315\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8178 - loss: 0.5262 - val_accuracy: 0.6250 - val_loss: 0.8371\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7969 - loss: 0.5406 - val_accuracy: 0.5625 - val_loss: 0.8513\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8686 - loss: 0.5111 - val_accuracy: 0.6250 - val_loss: 0.8693\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8204 - loss: 0.4880 - val_accuracy: 0.6250 - val_loss: 0.8812\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8102 - loss: 0.4634 - val_accuracy: 0.5625 - val_loss: 0.8715\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8460 - loss: 0.3821 - val_accuracy: 0.5625 - val_loss: 0.8738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694ms/step\n",
      "Fold Validation Accuracy = 0.6250\n",
      "Confusion Matrix:\n",
      " [[2 2 1]\n",
      " [2 0 1]\n",
      " [0 0 8]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       0.50      0.40      0.44         5\n",
      " Non-violent       0.00      0.00      0.00         3\n",
      "    Punching       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.43      0.47      0.44        16\n",
      "weighted avg       0.56      0.62      0.58        16\n",
      "\n",
      "\n",
      "=== Fold 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.3303 - loss: 1.1412 - val_accuracy: 0.3125 - val_loss: 1.0439\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3190 - loss: 1.1048 - val_accuracy: 0.5625 - val_loss: 0.9158\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4603 - loss: 0.9986 - val_accuracy: 0.7500 - val_loss: 0.8719\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5453 - loss: 0.9309 - val_accuracy: 0.8750 - val_loss: 0.7502\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5849 - loss: 0.8947 - val_accuracy: 0.9375 - val_loss: 0.6946\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6196 - loss: 0.8364 - val_accuracy: 0.9375 - val_loss: 0.6091\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6628 - loss: 0.8772 - val_accuracy: 0.9375 - val_loss: 0.5278\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6996 - loss: 0.6423 - val_accuracy: 0.8750 - val_loss: 0.4957\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6160 - loss: 0.7564 - val_accuracy: 0.9375 - val_loss: 0.4310\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6998 - loss: 0.7522 - val_accuracy: 0.9375 - val_loss: 0.4098\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6841 - loss: 0.6845 - val_accuracy: 0.9375 - val_loss: 0.3742\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7466 - loss: 0.7297 - val_accuracy: 0.9375 - val_loss: 0.3381\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7028 - loss: 0.6563 - val_accuracy: 0.9375 - val_loss: 0.3028\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7386 - loss: 0.7057 - val_accuracy: 0.9375 - val_loss: 0.2938\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7013 - loss: 0.7585 - val_accuracy: 0.9375 - val_loss: 0.2752\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7918 - loss: 0.5843 - val_accuracy: 0.9375 - val_loss: 0.2662\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7214 - loss: 0.6777 - val_accuracy: 1.0000 - val_loss: 0.2658\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8275 - loss: 0.5480 - val_accuracy: 0.9375 - val_loss: 0.2602\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6866 - loss: 0.6759 - val_accuracy: 0.9375 - val_loss: 0.2510\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8162 - loss: 0.4699 - val_accuracy: 0.9375 - val_loss: 0.2521\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7145 - loss: 0.5728 - val_accuracy: 0.9375 - val_loss: 0.2415\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7257 - loss: 0.7740 - val_accuracy: 0.9375 - val_loss: 0.2358\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8072 - loss: 0.5123 - val_accuracy: 0.9375 - val_loss: 0.2286\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8090 - loss: 0.5677 - val_accuracy: 0.9375 - val_loss: 0.2223\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7842 - loss: 0.5136 - val_accuracy: 0.9375 - val_loss: 0.2235\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7368 - loss: 0.5377 - val_accuracy: 0.9375 - val_loss: 0.2196\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7436 - loss: 0.5674 - val_accuracy: 0.9375 - val_loss: 0.2160\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8027 - loss: 0.5534 - val_accuracy: 0.9375 - val_loss: 0.2128\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6885 - loss: 0.6333 - val_accuracy: 1.0000 - val_loss: 0.2345\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7166 - loss: 0.5995 - val_accuracy: 0.9375 - val_loss: 0.2169\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8291 - loss: 0.5310 - val_accuracy: 0.9375 - val_loss: 0.2211\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7343 - loss: 0.5798 - val_accuracy: 0.8750 - val_loss: 0.2387\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7583 - loss: 0.4665 - val_accuracy: 1.0000 - val_loss: 0.2237\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8501 - loss: 0.4867 - val_accuracy: 0.9375 - val_loss: 0.2062\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7824 - loss: 0.6073 - val_accuracy: 0.8750 - val_loss: 0.2117\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6444 - loss: 0.7986 - val_accuracy: 1.0000 - val_loss: 0.2084\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7073 - loss: 0.5767 - val_accuracy: 0.8750 - val_loss: 0.2105\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8428 - loss: 0.5442 - val_accuracy: 0.9375 - val_loss: 0.1988\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7715 - loss: 0.5109 - val_accuracy: 1.0000 - val_loss: 0.1830\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8210 - loss: 0.5776 - val_accuracy: 1.0000 - val_loss: 0.1830\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8146 - loss: 0.4881 - val_accuracy: 0.8750 - val_loss: 0.1954\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7361 - loss: 0.6336 - val_accuracy: 1.0000 - val_loss: 0.1796\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8240 - loss: 0.4420 - val_accuracy: 0.9375 - val_loss: 0.1881\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7894 - loss: 0.4940 - val_accuracy: 0.9375 - val_loss: 0.1857\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7120 - loss: 0.6245 - val_accuracy: 1.0000 - val_loss: 0.1880\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8873 - loss: 0.4243 - val_accuracy: 0.9375 - val_loss: 0.1659\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8199 - loss: 0.4720 - val_accuracy: 1.0000 - val_loss: 0.1583\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6687 - loss: 0.7059 - val_accuracy: 0.9375 - val_loss: 0.1756\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8097 - loss: 0.4424 - val_accuracy: 0.9375 - val_loss: 0.1672\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7977 - loss: 0.5051 - val_accuracy: 0.9375 - val_loss: 0.1908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step\n",
      "Fold Validation Accuracy = 1.0000\n",
      "Confusion Matrix:\n",
      " [[3 0 0]\n",
      " [0 8 0]\n",
      " [0 0 5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      1.00      1.00         3\n",
      " Non-violent       1.00      1.00      1.00         8\n",
      "    Punching       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "\n",
      "=== Fold 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - accuracy: 0.3210 - loss: 1.2683 - val_accuracy: 0.5625 - val_loss: 1.5348\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4265 - loss: 1.2773 - val_accuracy: 0.4375 - val_loss: 1.1621\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5184 - loss: 1.0073 - val_accuracy: 0.5000 - val_loss: 1.0491\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4842 - loss: 0.9560 - val_accuracy: 0.5625 - val_loss: 1.0354\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6995 - loss: 0.9613 - val_accuracy: 0.5625 - val_loss: 1.0413\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7100 - loss: 0.8971 - val_accuracy: 0.6250 - val_loss: 0.8889\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7327 - loss: 0.8221 - val_accuracy: 0.6250 - val_loss: 0.8866\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8081 - loss: 0.7029 - val_accuracy: 0.6250 - val_loss: 0.9297\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7646 - loss: 0.6801 - val_accuracy: 0.6250 - val_loss: 0.8575\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6242 - loss: 0.7235 - val_accuracy: 0.6875 - val_loss: 0.6648\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8167 - loss: 0.6198 - val_accuracy: 0.6875 - val_loss: 0.6997\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6926 - loss: 0.6433 - val_accuracy: 0.6875 - val_loss: 0.7250\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7817 - loss: 0.5847 - val_accuracy: 0.6875 - val_loss: 0.5887\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8153 - loss: 0.4664 - val_accuracy: 0.6875 - val_loss: 0.6171\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6711 - loss: 0.5963 - val_accuracy: 0.6875 - val_loss: 0.7541\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8150 - loss: 0.4796 - val_accuracy: 0.6875 - val_loss: 0.5678\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7042 - loss: 0.6346 - val_accuracy: 0.8125 - val_loss: 0.5077\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8922 - loss: 0.4066 - val_accuracy: 0.7500 - val_loss: 0.5810\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8927 - loss: 0.4675 - val_accuracy: 0.6250 - val_loss: 0.5912\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7524 - loss: 0.5620 - val_accuracy: 0.6250 - val_loss: 0.5704\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7245 - loss: 0.7125 - val_accuracy: 0.7500 - val_loss: 0.5886\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8155 - loss: 0.4829 - val_accuracy: 0.7500 - val_loss: 0.5756\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8559 - loss: 0.5040 - val_accuracy: 0.8750 - val_loss: 0.4209\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7498 - loss: 0.6267 - val_accuracy: 0.7500 - val_loss: 0.5122\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8175 - loss: 0.4632 - val_accuracy: 0.8750 - val_loss: 0.4822\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7894 - loss: 0.5910 - val_accuracy: 0.7500 - val_loss: 0.5401\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8566 - loss: 0.4710 - val_accuracy: 0.6250 - val_loss: 0.5735\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7512 - loss: 0.6763 - val_accuracy: 0.7500 - val_loss: 0.5331\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8292 - loss: 0.5060 - val_accuracy: 0.7500 - val_loss: 0.5046\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7928 - loss: 0.5423 - val_accuracy: 0.6875 - val_loss: 0.5516\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7715 - loss: 0.5123 - val_accuracy: 0.7500 - val_loss: 0.4883\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8814 - loss: 0.3774 - val_accuracy: 0.8750 - val_loss: 0.3956\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7720 - loss: 0.5669 - val_accuracy: 0.8125 - val_loss: 0.4998\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7662 - loss: 0.4657 - val_accuracy: 0.6875 - val_loss: 0.5563\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8818 - loss: 0.4011 - val_accuracy: 0.8125 - val_loss: 0.5339\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7528 - loss: 0.6024 - val_accuracy: 0.7500 - val_loss: 0.5403\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8740 - loss: 0.4065 - val_accuracy: 0.7500 - val_loss: 0.6676\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8207 - loss: 0.5400 - val_accuracy: 0.7500 - val_loss: 0.5054\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8186 - loss: 0.4439 - val_accuracy: 0.7500 - val_loss: 0.5041\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8458 - loss: 0.4903 - val_accuracy: 0.8125 - val_loss: 0.4974\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8677 - loss: 0.3737 - val_accuracy: 0.8125 - val_loss: 0.3979\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8661 - loss: 0.4682 - val_accuracy: 0.6875 - val_loss: 0.6312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731ms/step\n",
      "Fold Validation Accuracy = 0.8750\n",
      "Confusion Matrix:\n",
      " [[5 0 2]\n",
      " [0 4 0]\n",
      " [0 0 5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      0.71      0.83         7\n",
      " Non-violent       1.00      1.00      1.00         4\n",
      "    Punching       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.90      0.90      0.89        16\n",
      "weighted avg       0.91      0.88      0.88        16\n",
      "\n",
      "\n",
      "=== Fold 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - accuracy: 0.2833 - loss: 1.2267 - val_accuracy: 0.6875 - val_loss: 0.9985\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3722 - loss: 1.2193 - val_accuracy: 0.5625 - val_loss: 0.9071\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4584 - loss: 1.1116 - val_accuracy: 0.6250 - val_loss: 0.9128\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5420 - loss: 0.9244 - val_accuracy: 0.9375 - val_loss: 0.8399\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6337 - loss: 0.8723 - val_accuracy: 0.7500 - val_loss: 0.7105\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6556 - loss: 0.8060 - val_accuracy: 0.8125 - val_loss: 0.6733\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6720 - loss: 0.7745 - val_accuracy: 0.8125 - val_loss: 0.6180\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6310 - loss: 0.7670 - val_accuracy: 0.9375 - val_loss: 0.5193\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6711 - loss: 0.8383 - val_accuracy: 0.8125 - val_loss: 0.4908\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6679 - loss: 0.6936 - val_accuracy: 0.8750 - val_loss: 0.4035\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6853 - loss: 0.7310 - val_accuracy: 0.9375 - val_loss: 0.4144\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7245 - loss: 0.6635 - val_accuracy: 0.8750 - val_loss: 0.4576\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7268 - loss: 0.6214 - val_accuracy: 0.8750 - val_loss: 0.4003\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8086 - loss: 0.5849 - val_accuracy: 0.8125 - val_loss: 0.3988\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7334 - loss: 0.7483 - val_accuracy: 0.8125 - val_loss: 0.3668\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7588 - loss: 0.6471 - val_accuracy: 0.8750 - val_loss: 0.4044\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8218 - loss: 0.4974 - val_accuracy: 0.8125 - val_loss: 0.4676\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7934 - loss: 0.5184 - val_accuracy: 0.8750 - val_loss: 0.3162\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7765 - loss: 0.5821 - val_accuracy: 0.9375 - val_loss: 0.2947\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7820 - loss: 0.6526 - val_accuracy: 0.8750 - val_loss: 0.4107\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7610 - loss: 0.6399 - val_accuracy: 0.9375 - val_loss: 0.2742\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7826 - loss: 0.6730 - val_accuracy: 0.9375 - val_loss: 0.2636\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8242 - loss: 0.5062 - val_accuracy: 0.8125 - val_loss: 0.4748\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7154 - loss: 0.6490 - val_accuracy: 0.9375 - val_loss: 0.2721\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8176 - loss: 0.5925 - val_accuracy: 0.8750 - val_loss: 0.2746\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7330 - loss: 0.6072 - val_accuracy: 0.8125 - val_loss: 0.5373\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7940 - loss: 0.5130 - val_accuracy: 0.8750 - val_loss: 0.3103\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7847 - loss: 0.6203 - val_accuracy: 0.8750 - val_loss: 0.3107\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6724 - loss: 0.7995 - val_accuracy: 0.8125 - val_loss: 0.4136\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6625 - loss: 0.7372 - val_accuracy: 0.8750 - val_loss: 0.2938\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7814 - loss: 0.5265 - val_accuracy: 0.8750 - val_loss: 0.3201\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8221 - loss: 0.4419 - val_accuracy: 0.8125 - val_loss: 0.4547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832ms/step\n",
      "Fold Validation Accuracy = 0.9375\n",
      "Confusion Matrix:\n",
      " [[2 0 0]\n",
      " [0 6 0]\n",
      " [1 0 7]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       0.67      1.00      0.80         2\n",
      " Non-violent       1.00      1.00      1.00         6\n",
      "    Punching       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.89      0.96      0.91        16\n",
      "weighted avg       0.96      0.94      0.94        16\n",
      "\n",
      "\n",
      "=== Fold 5 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 280ms/step - accuracy: 0.4695 - loss: 1.1015 - val_accuracy: 0.5333 - val_loss: 1.0416\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5629 - loss: 0.9525 - val_accuracy: 0.5333 - val_loss: 1.0028\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5485 - loss: 0.9526 - val_accuracy: 0.6000 - val_loss: 0.9400\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5631 - loss: 0.9489 - val_accuracy: 0.7333 - val_loss: 0.9062\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5938 - loss: 0.8389 - val_accuracy: 0.6000 - val_loss: 0.8891\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6281 - loss: 0.8286 - val_accuracy: 0.6000 - val_loss: 0.8334\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6982 - loss: 0.7489 - val_accuracy: 0.6667 - val_loss: 0.8000\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7011 - loss: 0.7138 - val_accuracy: 0.6667 - val_loss: 0.7762\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6575 - loss: 0.7444 - val_accuracy: 0.6667 - val_loss: 0.8687\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7389 - loss: 0.6083 - val_accuracy: 0.6667 - val_loss: 0.8425\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7355 - loss: 0.6263 - val_accuracy: 0.6667 - val_loss: 0.8198\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7165 - loss: 0.6515 - val_accuracy: 0.7333 - val_loss: 0.8243\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7785 - loss: 0.5644 - val_accuracy: 0.7333 - val_loss: 0.8233\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8339 - loss: 0.5111 - val_accuracy: 0.6667 - val_loss: 0.7860\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7971 - loss: 0.5122 - val_accuracy: 0.6667 - val_loss: 0.7473\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7530 - loss: 0.4888 - val_accuracy: 0.7333 - val_loss: 0.8144\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7604 - loss: 0.5491 - val_accuracy: 0.6667 - val_loss: 0.7888\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7480 - loss: 0.4971 - val_accuracy: 0.7333 - val_loss: 0.9858\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8198 - loss: 0.3984 - val_accuracy: 0.7333 - val_loss: 0.8495\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7727 - loss: 0.5974 - val_accuracy: 0.7333 - val_loss: 0.7203\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8461 - loss: 0.5810 - val_accuracy: 0.7333 - val_loss: 0.8554\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8293 - loss: 0.4810 - val_accuracy: 0.7333 - val_loss: 0.8308\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7668 - loss: 0.4906 - val_accuracy: 0.7333 - val_loss: 0.7902\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8907 - loss: 0.3496 - val_accuracy: 0.7333 - val_loss: 0.7610\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8320 - loss: 0.3469 - val_accuracy: 0.7333 - val_loss: 0.9166\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7452 - loss: 0.6471 - val_accuracy: 0.7333 - val_loss: 0.8904\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8364 - loss: 0.4770 - val_accuracy: 0.7333 - val_loss: 0.8278\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8742 - loss: 0.4717 - val_accuracy: 0.7333 - val_loss: 0.7471\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8391 - loss: 0.5547 - val_accuracy: 0.7333 - val_loss: 0.7337\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8715 - loss: 0.4270 - val_accuracy: 0.7333 - val_loss: 0.8252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Validation Accuracy = 0.7333\n",
      "Confusion Matrix:\n",
      " [[2 0 2]\n",
      " [1 3 1]\n",
      " [0 0 6]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       0.67      0.50      0.57         4\n",
      " Non-violent       1.00      0.60      0.75         5\n",
      "    Punching       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.78      0.70      0.71        15\n",
      "weighted avg       0.78      0.73      0.72        15\n",
      "\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Mean Accuracy: 0.8342 (std: 0.1369)\n",
      "LSTM results: {'fold_accuracies': [0.5625, 0.9375, 0.875, 0.9375, 0.8666666666666667], 'mean_acc': 0.8358333333333334, 'std_acc': 0.139905722224329, 'fold_histories': [{'accuracy': [0.3174603283405304, 0.4444444477558136, 0.5079365372657776, 0.6190476417541504, 0.6190476417541504, 0.7142857313156128, 0.7460317611694336, 0.682539701461792, 0.761904776096344, 0.8095238208770752, 0.682539701461792, 0.7777777910232544, 0.7936508059501648, 0.8095238208770752, 0.8095238208770752, 0.841269850730896, 0.8095238208770752, 0.7460317611694336, 0.8095238208770752, 0.8095238208770752, 0.8253968358039856, 0.8253968358039856, 0.8095238208770752, 0.8095238208770752, 0.8888888955116272, 0.8730158805847168, 0.8571428656578064, 0.8095238208770752, 0.8253968358039856, 0.7777777910232544, 0.7936508059501648], 'loss': [1.1259390115737915, 1.0817548036575317, 1.031720519065857, 0.9739256501197815, 0.9059779047966003, 0.8585606813430786, 0.7113123536109924, 0.6849968433380127, 0.6142314076423645, 0.5321763753890991, 0.6489902138710022, 0.5657787919044495, 0.590194582939148, 0.5109720230102539, 0.5099722146987915, 0.4866669774055481, 0.5006321668624878, 0.4994184970855713, 0.4772442579269409, 0.5088686943054199, 0.4821341335773468, 0.4209092855453491, 0.5006358027458191, 0.399447500705719, 0.40998369455337524, 0.3911062777042389, 0.4131046533584595, 0.49007388949394226, 0.4051550626754761, 0.49923381209373474, 0.4332803189754486], 'val_accuracy': [0.5, 0.5625, 0.5625, 0.5, 0.6875, 0.625, 0.5625, 0.625, 0.6875, 0.625, 0.625, 0.5625, 0.6875, 0.5, 0.625, 0.6875, 0.5625, 0.625, 0.5625, 0.625, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.625, 0.625], 'val_loss': [1.0530152320861816, 1.0546839237213135, 1.0246176719665527, 0.9753974080085754, 0.9511970281600952, 0.9790453910827637, 0.9444800615310669, 0.9067230224609375, 0.8649172782897949, 0.9812058210372925, 0.9195013642311096, 0.8909869194030762, 1.0581181049346924, 0.8980920314788818, 0.9156967997550964, 0.8987732529640198, 0.8780807852745056, 0.8510560989379883, 0.8623326420783997, 0.894005298614502, 0.8413375020027161, 0.9018607139587402, 0.9062145948410034, 0.9486077427864075, 0.9216710925102234, 0.9212017059326172, 0.9909323453903198, 1.0025849342346191, 0.9343304634094238, 0.887265682220459, 0.9114580154418945]}, {'accuracy': [0.30158731341362, 0.4285714328289032, 0.4761904776096344, 0.460317462682724, 0.6507936716079712, 0.60317462682724, 0.682539701461792, 0.682539701461792, 0.682539701461792, 0.7301587462425232, 0.6190476417541504, 0.6507936716079712, 0.682539701461792, 0.682539701461792, 0.6984127163887024, 0.7936508059501648, 0.7777777910232544, 0.7460317611694336, 0.7301587462425232, 0.7460317611694336, 0.7936508059501648, 0.7777777910232544, 0.7301587462425232, 0.7301587462425232, 0.761904776096344, 0.761904776096344, 0.8095238208770752, 0.8571428656578064, 0.7142857313156128, 0.8095238208770752, 0.7777777910232544, 0.7936508059501648, 0.8095238208770752, 0.8095238208770752, 0.7936508059501648, 0.7301587462425232, 0.7301587462425232, 0.8253968358039856], 'loss': [1.0908900499343872, 1.0460925102233887, 1.0122874975204468, 0.969506025314331, 0.9344828724861145, 0.9118253588676453, 0.8137602806091309, 0.7323446869850159, 0.7963839173316956, 0.7019793391227722, 0.7275062799453735, 0.745151937007904, 0.7211071252822876, 0.6912047266960144, 0.730469286441803, 0.6684992909431458, 0.605312705039978, 0.6463080048561096, 0.6460874676704407, 0.6896951794624329, 0.642984926700592, 0.5467885136604309, 0.6316507458686829, 0.5819316506385803, 0.5942420363426208, 0.535153329372406, 0.5723036527633667, 0.5116034150123596, 0.6315814256668091, 0.5250215530395508, 0.5234621167182922, 0.6427360773086548, 0.5711151361465454, 0.5723876357078552, 0.5526620745658875, 0.583242654800415, 0.6221170425415039, 0.5829467177391052], 'val_accuracy': [0.3125, 0.3125, 0.4375, 0.6875, 0.9375, 0.875, 0.9375, 0.9375, 0.9375, 0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.875, 0.9375, 0.875, 0.875, 0.9375, 0.9375, 0.9375, 0.875, 0.9375, 0.9375, 0.9375, 1.0], 'val_loss': [1.097918152809143, 1.0762789249420166, 1.0233283042907715, 0.9137893915176392, 0.8287273645401001, 0.7713651061058044, 0.6546081304550171, 0.5771198868751526, 0.46476221084594727, 0.4705938994884491, 0.35372528433799744, 0.35796546936035156, 0.3663329482078552, 0.2983076572418213, 0.29397672414779663, 0.3104560971260071, 0.27101609110832214, 0.2700984477996826, 0.2911880612373352, 0.2783403992652893, 0.2873424291610718, 0.23794445395469666, 0.25302326679229736, 0.2288151979446411, 0.29651424288749695, 0.2540459632873535, 0.26325565576553345, 0.1861906349658966, 0.28833380341529846, 0.2668594717979431, 0.21334347128868103, 0.2411758005619049, 0.21620945632457733, 0.24578677117824554, 0.2068415880203247, 0.20059049129486084, 0.20716458559036255, 0.22895726561546326]}, {'accuracy': [0.380952388048172, 0.460317462682724, 0.5873016119003296, 0.6666666865348816, 0.6349206566810608, 0.682539701461792, 0.7777777910232544, 0.7777777910232544, 0.7142857313156128, 0.6984127163887024, 0.761904776096344, 0.761904776096344, 0.7936508059501648, 0.7936508059501648, 0.7301587462425232, 0.6984127163887024, 0.7936508059501648, 0.761904776096344, 0.7142857313156128, 0.7777777910232544, 0.7936508059501648, 0.761904776096344, 0.8095238208770752, 0.7936508059501648, 0.8095238208770752, 0.7936508059501648, 0.761904776096344, 0.841269850730896, 0.761904776096344, 0.7777777910232544, 0.7936508059501648, 0.7936508059501648], 'loss': [1.094396948814392, 1.0186513662338257, 0.975837230682373, 0.9224565029144287, 0.8485590219497681, 0.8009947538375854, 0.7345453500747681, 0.6975196599960327, 0.6826500296592712, 0.7032526135444641, 0.5895509719848633, 0.6105783581733704, 0.6161506772041321, 0.5630019903182983, 0.6102285385131836, 0.6201743483543396, 0.5783756971359253, 0.5782152414321899, 0.6353999376296997, 0.5203173160552979, 0.5189028382301331, 0.6138350367546082, 0.5092709064483643, 0.5191506147384644, 0.5321996808052063, 0.503073513507843, 0.5625954866409302, 0.48872891068458557, 0.4917446970939636, 0.5339361429214478, 0.5256330370903015, 0.43807050585746765], 'val_accuracy': [0.3125, 0.5, 0.5625, 0.5625, 0.5625, 0.625, 0.6875, 0.625, 0.625, 0.625, 0.8125, 0.75, 0.8125, 0.8125, 0.8125, 0.75, 0.6875, 0.8125, 0.8125, 0.75, 0.6875, 0.875, 0.75, 0.75, 0.875, 0.8125, 0.6875, 0.6875, 0.8125, 0.6875, 0.8125, 0.875], 'val_loss': [1.0750389099121094, 1.1156646013259888, 1.088106632232666, 1.032050371170044, 0.9275708198547363, 0.7938601970672607, 0.7246881723403931, 0.6871654987335205, 0.6151909828186035, 0.7044506669044495, 0.5574575662612915, 0.5418511033058167, 0.5111145973205566, 0.48437079787254333, 0.522648811340332, 0.5581366419792175, 0.698421061038971, 0.509432315826416, 0.5001881718635559, 0.5404630303382874, 0.6512874960899353, 0.43847721815109253, 0.6444560289382935, 0.5480148792266846, 0.4605816900730133, 0.4841812551021576, 0.6498593688011169, 0.5616099238395691, 0.4816480278968811, 0.663500964641571, 0.46390944719314575, 0.4427153468132019]}, {'accuracy': [0.3174603283405304, 0.5714285969734192, 0.5714285969734192, 0.6507936716079712, 0.60317462682724, 0.7142857313156128, 0.6349206566810608, 0.6349206566810608, 0.6349206566810608, 0.6666666865348816, 0.7301587462425232, 0.761904776096344, 0.7301587462425232, 0.6190476417541504, 0.7460317611694336, 0.7301587462425232, 0.7460317611694336, 0.6349206566810608, 0.7777777910232544, 0.761904776096344, 0.7460317611694336, 0.7460317611694336, 0.6984127163887024], 'loss': [1.1114164590835571, 1.0032227039337158, 0.9880702495574951, 0.9314614534378052, 0.899824857711792, 0.8041921257972717, 0.7969532608985901, 0.7983675003051758, 0.7089870572090149, 0.729351282119751, 0.7301912903785706, 0.6073378324508667, 0.6647077202796936, 0.7217894196510315, 0.6590526103973389, 0.6814014911651611, 0.639419436454773, 0.6956583261489868, 0.5630771517753601, 0.5473679900169373, 0.5659667253494263, 0.5782405734062195, 0.5993603467941284], 'val_accuracy': [0.125, 0.6875, 0.75, 0.875, 0.8125, 0.875, 0.9375, 0.8125, 0.9375, 0.875, 0.875, 0.8125, 0.9375, 0.875, 0.8125, 0.9375, 0.9375, 0.9375, 0.875, 0.875, 0.9375, 0.875, 0.875], 'val_loss': [1.063812017440796, 0.9269239902496338, 0.8374245762825012, 0.7427287101745605, 0.6536519527435303, 0.5677952170372009, 0.46756601333618164, 0.4015263319015503, 0.4045414626598358, 0.441358745098114, 0.4008023142814636, 0.3918807804584503, 0.27599310874938965, 0.3993013799190521, 0.47560644149780273, 0.3165156841278076, 0.29012811183929443, 0.30390113592147827, 0.32480502128601074, 0.4022974371910095, 0.278516560792923, 0.33390265703201294, 0.3124760687351227]}, {'accuracy': [0.296875, 0.453125, 0.5, 0.671875, 0.5625, 0.65625, 0.71875, 0.765625, 0.6875, 0.75, 0.8125, 0.75, 0.65625, 0.796875, 0.734375, 0.734375, 0.859375, 0.828125, 0.703125, 0.796875, 0.828125, 0.75, 0.875, 0.859375, 0.828125, 0.8125, 0.84375, 0.84375, 0.78125, 0.875, 0.8125, 0.8125, 0.796875, 0.796875, 0.84375, 0.859375, 0.875, 0.84375, 0.859375, 0.796875, 0.875, 0.859375, 0.890625, 0.90625, 0.828125, 0.78125, 0.796875, 0.90625, 0.859375, 0.796875], 'loss': [1.0878595113754272, 1.0370234251022339, 1.013826608657837, 0.9316493272781372, 0.9054971933364868, 0.8030211329460144, 0.7559854388237, 0.679504930973053, 0.7050740122795105, 0.5997169613838196, 0.5838465690612793, 0.5822470784187317, 0.6000794172286987, 0.5672616362571716, 0.571566641330719, 0.6098734140396118, 0.3903942406177521, 0.4326888918876648, 0.5597578287124634, 0.4636344015598297, 0.43277648091316223, 0.5371694564819336, 0.3843584656715393, 0.4274696111679077, 0.44489213824272156, 0.4426925778388977, 0.4299982488155365, 0.40157872438430786, 0.5116184949874878, 0.3990757167339325, 0.4634559154510498, 0.4271410405635834, 0.4753708243370056, 0.5056450963020325, 0.42097699642181396, 0.39466336369514465, 0.3902778625488281, 0.3986639678478241, 0.3341079354286194, 0.39571282267570496, 0.3312223255634308, 0.4388491213321686, 0.304014652967453, 0.32099616527557373, 0.36461740732192993, 0.49061527848243713, 0.4682210683822632, 0.3320333957672119, 0.37352895736694336, 0.4207967519760132], 'val_accuracy': [0.4000000059604645, 0.4000000059604645, 0.5333333611488342, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6666666865348816, 0.6000000238418579, 0.6000000238418579, 0.7333333492279053, 0.6666666865348816, 0.6666666865348816, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.6666666865348816, 0.7333333492279053, 0.7333333492279053, 0.6666666865348816, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.800000011920929, 0.7333333492279053, 0.7333333492279053, 0.8666666746139526, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053, 0.7333333492279053], 'val_loss': [1.062577486038208, 1.0370938777923584, 0.9892936944961548, 0.933731734752655, 0.8974382281303406, 0.8102115392684937, 0.813595175743103, 0.8576279282569885, 0.7444222569465637, 0.8328158259391785, 0.7783380150794983, 0.761588990688324, 0.8836432099342346, 0.8463832139968872, 0.7236509919166565, 0.8200536370277405, 0.7847186326980591, 0.7633923888206482, 0.8019967675209045, 0.717948853969574, 0.6949531435966492, 0.8872117400169373, 0.7587407231330872, 0.7140670418739319, 0.7100857496261597, 0.9540654420852661, 0.6572832465171814, 0.6984551548957825, 0.8961693048477173, 0.7056551575660706, 0.8672106266021729, 0.728908896446228, 0.8493449091911316, 0.7845203280448914, 0.8494224548339844, 0.7063533663749695, 0.6558479070663452, 0.9318094849586487, 0.8640676140785217, 0.6622253656387329, 0.8673628568649292, 0.7587815523147583, 0.6282886862754822, 0.9551345705986023, 0.7084206342697144, 0.5894095301628113, 0.9581862092018127, 0.7937349677085876, 0.7019985318183899, 0.5925674438476562]}], 'confusion_matrices': [array([[2, 1, 2],\n",
      "       [1, 1, 1],\n",
      "       [2, 0, 6]], dtype=int64), array([[2, 0, 1],\n",
      "       [0, 8, 0],\n",
      "       [0, 0, 5]], dtype=int64), array([[5, 0, 2],\n",
      "       [0, 4, 0],\n",
      "       [0, 0, 5]], dtype=int64), array([[1, 0, 1],\n",
      "       [0, 6, 0],\n",
      "       [0, 0, 8]], dtype=int64), array([[4, 0, 0],\n",
      "       [2, 3, 0],\n",
      "       [0, 0, 6]], dtype=int64)]}\n"
     ]
    }
   ],
   "source": [
    "# And a model function (like the build_lstm_model above).\n",
    "results_gru = kfold_validation(save_model_path=\"gru_model.h5\", model_fn=build_gru_model)\n",
    "# This prints out each fold's accuracy, confusion matrix, classification report\n",
    "# Then returns a dictionary with the final cross-validation results.\n",
    "print(\"LSTM results:\", results_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Build and Train DNN Model (Flattened Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_model(input_dim, num_classes=NUM_CLASSES, dropout_rates=(0.3, 0.2)):\n",
    "    \"\"\"\n",
    "    Returns a freshly compiled DNN model that exut_dim`.\n",
    "    The model outputs `num_classes` with 'softmax' for multi-class classification.pects a flattened input of size `inp\n",
    "    \n",
    "    dropout_rates is a tuple indicating the dropout after each Dense layer.\n",
    "    Example: (0.3, 0.2) => 30% dropout after first layer, 20% after second layer.\n",
    "    \"\"\"\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(dropout_rates[0]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(dropout_rates[1]),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_validation_dnn(save_model_path, k=5, model_fn=None, epochs=EPOCH, patience=PATIENCE, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    k: number of folds\n",
    "    model_fn: a function that builds and compiles a new DNN model\n",
    "              e.g. build_dnn_model(input_dim, num_classes)\n",
    "    epochs: max training epochs\n",
    "    batch_size: training batch size\n",
    "    patience: early stopping patience\n",
    "    \n",
    "    Assumes you have the following global variables accessible or\n",
    "    at least in the same scope:\n",
    "      - X_seq_padded: shape (N, MAX_SEQ_LEN, 132)\n",
    "      - y_int: shape (N,)\n",
    "      - label_encoder: to map integer labels back to class names\n",
    "      - num_classes\n",
    "    \"\"\"\n",
    "\n",
    "    # -- 1) Flatten data from (N, MAX_SEQ_LEN, 132) to (N, MAX_SEQ_LEN * 132)\n",
    "    N, MAX_SEQ_LEN, NUM_FEATS = X_seq_padded.shape\n",
    "    X_flat = X_seq_padded.reshape(N, -1)  # shape (N, MAX_SEQ_LEN*132)\n",
    "\n",
    "    # -- 2) Setup KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    \n",
    "        \n",
    "    fold_accuracies = []\n",
    "    fold_histories = []\n",
    "    confusion_matrices = []\n",
    "    fold_index = 1\n",
    "\n",
    "    for train_index, val_index in kf.split(X_flat):\n",
    "        print(f\"\\n=== Fold {fold_index} ===\")\n",
    "        fold_index += 1\n",
    "\n",
    "        # Split into train/val sets\n",
    "        X_train, X_val = X_flat[train_index], X_flat[val_index]\n",
    "        y_train, y_val = y_int[train_index], y_int[val_index]\n",
    "\n",
    "        # Build a fresh DNN model for this fold\n",
    "        if model_fn is None:\n",
    "            raise ValueError(\"Please provide a model-building function (model_fn).\")\n",
    "\n",
    "        # Note: We pass input_dim = MAX_SEQ_LEN * NUM_FEATS\n",
    "        model = model_fn(input_dim=X_train.shape[1])\n",
    "\n",
    "        # Early stopping\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_preds_label = np.argmax(val_preds, axis=1)\n",
    "        acc = accuracy_score(y_val, val_preds_label)\n",
    "        print(f\"Fold Validation Accuracy = {acc:.4f}\")\n",
    "        \n",
    "        fold_accuracies.append(acc)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_val, val_preds_label)\n",
    "        confusion_matrices.append(cm)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        \n",
    "        # Classification Report\n",
    "        print(\"Classification Report:\\n\",\n",
    "              classification_report(y_val, val_preds_label,\n",
    "                                    target_names=label_encoder.classes_,\n",
    "                                    labels=np.arange(NUM_CLASSES)))\n",
    "\n",
    "\n",
    "    model.save(save_model_path)  # or \"my_model\" for SavedModel format\n",
    "    \n",
    "    # Compute average accuracy\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "    print(f\"\\n=== Final Cross-Validation Results ===\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f} (std: {std_acc:.4f})\")\n",
    "    \n",
    "    results = {\n",
    "        \"fold_accuracies\": fold_accuracies,\n",
    "        \"mean_acc\": mean_acc,\n",
    "        \"std_acc\": std_acc,\n",
    "        \"fold_histories\": fold_histories,        \n",
    "        \"confusion_matrices\": confusion_matrices \n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.2659 - loss: 1.2341 - val_accuracy: 0.4375 - val_loss: 1.1192\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5253 - loss: 1.0089 - val_accuracy: 0.5000 - val_loss: 1.0257\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4777 - loss: 0.9226 - val_accuracy: 0.5625 - val_loss: 1.0444\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6796 - loss: 0.8397 - val_accuracy: 0.5000 - val_loss: 0.9579\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6755 - loss: 0.7415 - val_accuracy: 0.6250 - val_loss: 0.9260\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6285 - loss: 0.7314 - val_accuracy: 0.6250 - val_loss: 0.8915\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8481 - loss: 0.4343 - val_accuracy: 0.6875 - val_loss: 0.8701\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7939 - loss: 0.5657 - val_accuracy: 0.5625 - val_loss: 0.8723\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7107 - loss: 0.5495 - val_accuracy: 0.5625 - val_loss: 0.8873\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7647 - loss: 0.5166 - val_accuracy: 0.5000 - val_loss: 0.9447\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7512 - loss: 0.4859 - val_accuracy: 0.5625 - val_loss: 0.8835\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8924 - loss: 0.4537 - val_accuracy: 0.5000 - val_loss: 0.8802\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7853 - loss: 0.5075 - val_accuracy: 0.5625 - val_loss: 0.9480\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8304 - loss: 0.3699 - val_accuracy: 0.5625 - val_loss: 0.8476\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8342 - loss: 0.4682 - val_accuracy: 0.6250 - val_loss: 0.8321\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9049 - loss: 0.4138 - val_accuracy: 0.6250 - val_loss: 0.8042\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7868 - loss: 0.4818 - val_accuracy: 0.6875 - val_loss: 0.8588\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8410 - loss: 0.4451 - val_accuracy: 0.5625 - val_loss: 0.8383\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8389 - loss: 0.4390 - val_accuracy: 0.5000 - val_loss: 0.8393\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7721 - loss: 0.4383 - val_accuracy: 0.5625 - val_loss: 0.8336\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9055 - loss: 0.3203 - val_accuracy: 0.5625 - val_loss: 0.8480\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8280 - loss: 0.4006 - val_accuracy: 0.5625 - val_loss: 0.8551\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8233 - loss: 0.4800 - val_accuracy: 0.6250 - val_loss: 0.8950\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8254 - loss: 0.3471 - val_accuracy: 0.6875 - val_loss: 0.9639\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8330 - loss: 0.4049 - val_accuracy: 0.6250 - val_loss: 0.8337\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9135 - loss: 0.3509 - val_accuracy: 0.6250 - val_loss: 0.8437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Fold Validation Accuracy = 0.6250\n",
      "Confusion Matrix:\n",
      " [[2 1 2]\n",
      " [1 1 1]\n",
      " [1 0 7]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       0.50      0.40      0.44         5\n",
      " Non-violent       0.50      0.33      0.40         3\n",
      "    Punching       0.70      0.88      0.78         8\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.57      0.54      0.54        16\n",
      "weighted avg       0.60      0.62      0.60        16\n",
      "\n",
      "\n",
      "=== Fold 2 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.3636 - loss: 1.2809 - val_accuracy: 0.6250 - val_loss: 0.9564\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5298 - loss: 0.9780 - val_accuracy: 0.5625 - val_loss: 0.9313\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5128 - loss: 0.9001 - val_accuracy: 0.8125 - val_loss: 0.8394\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6546 - loss: 0.8407 - val_accuracy: 0.6875 - val_loss: 0.7287\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6235 - loss: 0.8748 - val_accuracy: 0.8750 - val_loss: 0.6941\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5759 - loss: 0.7913 - val_accuracy: 0.9375 - val_loss: 0.5649\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7395 - loss: 0.6988 - val_accuracy: 0.9375 - val_loss: 0.4679\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6652 - loss: 0.7412 - val_accuracy: 0.9375 - val_loss: 0.4830\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6789 - loss: 0.8481 - val_accuracy: 0.9375 - val_loss: 0.3927\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6566 - loss: 0.7420 - val_accuracy: 0.9375 - val_loss: 0.3567\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8151 - loss: 0.5601 - val_accuracy: 0.9375 - val_loss: 0.3986\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7599 - loss: 0.6590 - val_accuracy: 0.8750 - val_loss: 0.3866\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7755 - loss: 0.5661 - val_accuracy: 0.9375 - val_loss: 0.3178\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6630 - loss: 0.7081 - val_accuracy: 0.8125 - val_loss: 0.3747\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7413 - loss: 0.4853 - val_accuracy: 0.9375 - val_loss: 0.2797\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7442 - loss: 0.5065 - val_accuracy: 0.9375 - val_loss: 0.2996\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7373 - loss: 0.6011 - val_accuracy: 0.9375 - val_loss: 0.2729\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8044 - loss: 0.5197 - val_accuracy: 0.9375 - val_loss: 0.2513\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7390 - loss: 0.5429 - val_accuracy: 0.9375 - val_loss: 0.3167\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8146 - loss: 0.4227 - val_accuracy: 1.0000 - val_loss: 0.2357\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7431 - loss: 0.5571 - val_accuracy: 0.9375 - val_loss: 0.2598\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8051 - loss: 0.4435 - val_accuracy: 1.0000 - val_loss: 0.2519\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7800 - loss: 0.4662 - val_accuracy: 1.0000 - val_loss: 0.2311\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8251 - loss: 0.4568 - val_accuracy: 0.9375 - val_loss: 0.1887\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8313 - loss: 0.4859 - val_accuracy: 0.9375 - val_loss: 0.2562\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7175 - loss: 0.5483 - val_accuracy: 0.9375 - val_loss: 0.2041\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8776 - loss: 0.4751 - val_accuracy: 1.0000 - val_loss: 0.1645\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8258 - loss: 0.4993 - val_accuracy: 1.0000 - val_loss: 0.2425\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8076 - loss: 0.4630 - val_accuracy: 1.0000 - val_loss: 0.1949\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8929 - loss: 0.3782 - val_accuracy: 0.9375 - val_loss: 0.1948\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7875 - loss: 0.4426 - val_accuracy: 1.0000 - val_loss: 0.2034\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8454 - loss: 0.4253 - val_accuracy: 1.0000 - val_loss: 0.2081\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8832 - loss: 0.4138 - val_accuracy: 1.0000 - val_loss: 0.1932\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8048 - loss: 0.4772 - val_accuracy: 1.0000 - val_loss: 0.1576\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7898 - loss: 0.4625 - val_accuracy: 0.8125 - val_loss: 0.3523\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7386 - loss: 0.5753 - val_accuracy: 0.8750 - val_loss: 0.2292\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8854 - loss: 0.3822 - val_accuracy: 0.8750 - val_loss: 0.2697\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8814 - loss: 0.3343 - val_accuracy: 0.8750 - val_loss: 0.2531\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7655 - loss: 0.5275 - val_accuracy: 0.9375 - val_loss: 0.2138\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7757 - loss: 0.4277 - val_accuracy: 0.9375 - val_loss: 0.2003\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8049 - loss: 0.4084 - val_accuracy: 0.9375 - val_loss: 0.1619\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8388 - loss: 0.3990 - val_accuracy: 1.0000 - val_loss: 0.1898\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8907 - loss: 0.3013 - val_accuracy: 0.9375 - val_loss: 0.2001\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7906 - loss: 0.3686 - val_accuracy: 0.9375 - val_loss: 0.1762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Fold Validation Accuracy = 1.0000\n",
      "Confusion Matrix:\n",
      " [[3 0 0]\n",
      " [0 8 0]\n",
      " [0 0 5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      1.00      1.00         3\n",
      " Non-violent       1.00      1.00      1.00         8\n",
      "    Punching       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "\n",
      "=== Fold 3 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.2790 - loss: 1.2259 - val_accuracy: 0.5000 - val_loss: 1.2958\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4691 - loss: 1.0522 - val_accuracy: 0.5625 - val_loss: 1.0546\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5434 - loss: 0.9411 - val_accuracy: 0.5625 - val_loss: 0.9737\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4349 - loss: 0.9685 - val_accuracy: 0.5625 - val_loss: 1.0700\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7637 - loss: 0.7210 - val_accuracy: 0.5625 - val_loss: 0.8289\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6920 - loss: 0.7088 - val_accuracy: 0.5625 - val_loss: 0.8510\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7271 - loss: 0.6370 - val_accuracy: 0.6875 - val_loss: 0.6955\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6724 - loss: 0.7021 - val_accuracy: 0.6250 - val_loss: 0.6814\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7577 - loss: 0.7533 - val_accuracy: 0.6250 - val_loss: 0.8594\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6978 - loss: 0.6495 - val_accuracy: 0.6875 - val_loss: 0.6241\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7864 - loss: 0.6001 - val_accuracy: 0.7500 - val_loss: 0.5722\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7592 - loss: 0.6206 - val_accuracy: 0.6875 - val_loss: 0.6646\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7802 - loss: 0.5661 - val_accuracy: 0.5625 - val_loss: 0.7269\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8258 - loss: 0.4682 - val_accuracy: 0.6875 - val_loss: 0.6131\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7930 - loss: 0.5319 - val_accuracy: 0.8125 - val_loss: 0.4860\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7808 - loss: 0.4975 - val_accuracy: 0.6875 - val_loss: 0.7021\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7972 - loss: 0.4691 - val_accuracy: 0.6875 - val_loss: 0.5125\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7977 - loss: 0.5256 - val_accuracy: 0.8750 - val_loss: 0.4946\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8037 - loss: 0.6005 - val_accuracy: 0.6875 - val_loss: 0.5975\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7952 - loss: 0.4709 - val_accuracy: 0.7500 - val_loss: 0.5172\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8361 - loss: 0.4070 - val_accuracy: 0.8125 - val_loss: 0.4935\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7625 - loss: 0.5038 - val_accuracy: 0.7500 - val_loss: 0.5247\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8486 - loss: 0.4064 - val_accuracy: 0.7500 - val_loss: 0.5488\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8690 - loss: 0.3996 - val_accuracy: 0.9375 - val_loss: 0.3997\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8502 - loss: 0.3833 - val_accuracy: 0.8125 - val_loss: 0.4930\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8352 - loss: 0.4296 - val_accuracy: 0.8750 - val_loss: 0.4533\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7271 - loss: 0.5007 - val_accuracy: 0.8125 - val_loss: 0.4568\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8487 - loss: 0.4639 - val_accuracy: 0.7500 - val_loss: 0.6060\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7555 - loss: 0.4584 - val_accuracy: 0.9375 - val_loss: 0.3679\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8008 - loss: 0.5937 - val_accuracy: 0.8750 - val_loss: 0.4336\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8858 - loss: 0.3790 - val_accuracy: 0.8125 - val_loss: 0.4931\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8109 - loss: 0.3848 - val_accuracy: 0.8750 - val_loss: 0.4360\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8082 - loss: 0.4098 - val_accuracy: 0.6250 - val_loss: 0.6390\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8319 - loss: 0.4073 - val_accuracy: 0.9375 - val_loss: 0.3892\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8791 - loss: 0.3466 - val_accuracy: 0.7500 - val_loss: 0.5139\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8614 - loss: 0.3283 - val_accuracy: 0.8750 - val_loss: 0.4141\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9240 - loss: 0.3245 - val_accuracy: 0.8750 - val_loss: 0.4426\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8156 - loss: 0.3695 - val_accuracy: 0.8750 - val_loss: 0.4518\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.2978 - val_accuracy: 0.8750 - val_loss: 0.3991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Fold Validation Accuracy = 0.9375\n",
      "Confusion Matrix:\n",
      " [[6 0 1]\n",
      " [0 4 0]\n",
      " [0 0 5]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      0.86      0.92         7\n",
      " Non-violent       1.00      1.00      1.00         4\n",
      "    Punching       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.94      0.95      0.94        16\n",
      "weighted avg       0.95      0.94      0.94        16\n",
      "\n",
      "\n",
      "=== Fold 4 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3421 - loss: 1.3251 - val_accuracy: 0.8125 - val_loss: 0.9353\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4291 - loss: 1.1474 - val_accuracy: 0.8750 - val_loss: 0.7623\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5008 - loss: 1.0518 - val_accuracy: 0.9375 - val_loss: 0.7284\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5574 - loss: 0.9978 - val_accuracy: 0.8750 - val_loss: 0.6029\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6489 - loss: 0.8867 - val_accuracy: 0.8125 - val_loss: 0.6299\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5768 - loss: 0.8186 - val_accuracy: 0.8750 - val_loss: 0.5253\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5505 - loss: 0.9200 - val_accuracy: 0.9375 - val_loss: 0.4837\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7214 - loss: 0.7365 - val_accuracy: 0.9375 - val_loss: 0.5019\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7474 - loss: 0.6764 - val_accuracy: 0.8125 - val_loss: 0.5566\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8491 - loss: 0.6198 - val_accuracy: 0.8750 - val_loss: 0.4024\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7632 - loss: 0.5455 - val_accuracy: 0.8750 - val_loss: 0.3657\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7022 - loss: 0.7057 - val_accuracy: 0.8750 - val_loss: 0.4025\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8701 - loss: 0.5007 - val_accuracy: 0.8750 - val_loss: 0.3793\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7370 - loss: 0.6015 - val_accuracy: 0.8750 - val_loss: 0.4624\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6910 - loss: 0.6751 - val_accuracy: 0.8750 - val_loss: 0.2940\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6701 - loss: 0.6411 - val_accuracy: 0.8750 - val_loss: 0.4275\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6923 - loss: 0.6583 - val_accuracy: 0.8750 - val_loss: 0.3635\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8220 - loss: 0.5047 - val_accuracy: 0.8750 - val_loss: 0.3448\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7166 - loss: 0.5832 - val_accuracy: 0.9375 - val_loss: 0.2639\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7722 - loss: 0.4951 - val_accuracy: 0.8750 - val_loss: 0.3674\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8031 - loss: 0.4676 - val_accuracy: 0.8750 - val_loss: 0.3412\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7965 - loss: 0.5414 - val_accuracy: 0.9375 - val_loss: 0.2670\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8137 - loss: 0.5317 - val_accuracy: 0.8125 - val_loss: 0.4490\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8531 - loss: 0.3976 - val_accuracy: 0.8750 - val_loss: 0.2801\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7949 - loss: 0.4867 - val_accuracy: 0.8750 - val_loss: 0.4023\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7896 - loss: 0.4871 - val_accuracy: 0.8750 - val_loss: 0.3231\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8599 - loss: 0.3624 - val_accuracy: 0.8750 - val_loss: 0.2687\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8433 - loss: 0.4483 - val_accuracy: 0.8750 - val_loss: 0.3314\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8592 - loss: 0.4026 - val_accuracy: 0.9375 - val_loss: 0.2547\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8293 - loss: 0.4441 - val_accuracy: 0.8750 - val_loss: 0.3325\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9097 - loss: 0.3621 - val_accuracy: 0.8750 - val_loss: 0.2947\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8695 - loss: 0.4772 - val_accuracy: 0.8750 - val_loss: 0.4352\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7787 - loss: 0.5168 - val_accuracy: 0.8750 - val_loss: 0.2457\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8346 - loss: 0.4430 - val_accuracy: 0.8750 - val_loss: 0.3359\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8987 - loss: 0.3565 - val_accuracy: 0.8750 - val_loss: 0.3627\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7820 - loss: 0.5336 - val_accuracy: 0.9375 - val_loss: 0.2264\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8630 - loss: 0.4024 - val_accuracy: 0.8750 - val_loss: 0.3051\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8267 - loss: 0.4849 - val_accuracy: 0.8750 - val_loss: 0.2690\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8416 - loss: 0.3640 - val_accuracy: 0.8125 - val_loss: 0.4482\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9256 - loss: 0.3538 - val_accuracy: 0.9375 - val_loss: 0.1998\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8676 - loss: 0.3275 - val_accuracy: 0.8750 - val_loss: 0.2794\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7886 - loss: 0.4462 - val_accuracy: 0.8750 - val_loss: 0.2800\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8841 - loss: 0.3887 - val_accuracy: 0.8125 - val_loss: 0.3830\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9101 - loss: 0.3169 - val_accuracy: 0.9375 - val_loss: 0.2244\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8329 - loss: 0.4383 - val_accuracy: 0.8750 - val_loss: 0.3362\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8624 - loss: 0.3418 - val_accuracy: 0.9375 - val_loss: 0.1878\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8578 - loss: 0.3557 - val_accuracy: 0.9375 - val_loss: 0.2119\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8700 - loss: 0.3048 - val_accuracy: 0.7500 - val_loss: 0.5960\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7978 - loss: 0.5474 - val_accuracy: 0.9375 - val_loss: 0.1611\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8257 - loss: 0.4061 - val_accuracy: 0.8750 - val_loss: 0.3192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Fold Validation Accuracy = 0.9375\n",
      "Confusion Matrix:\n",
      " [[1 0 1]\n",
      " [0 6 0]\n",
      " [0 0 8]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       1.00      0.50      0.67         2\n",
      " Non-violent       1.00      1.00      1.00         6\n",
      "    Punching       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.96      0.83      0.87        16\n",
      "weighted avg       0.94      0.94      0.93        16\n",
      "\n",
      "\n",
      "=== Fold 5 ===\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.3314 - loss: 1.3785 - val_accuracy: 0.6000 - val_loss: 0.9472\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4288 - loss: 1.0200 - val_accuracy: 0.6000 - val_loss: 0.8953\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6570 - loss: 0.8344 - val_accuracy: 0.8000 - val_loss: 0.8325\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7744 - loss: 0.6341 - val_accuracy: 0.6000 - val_loss: 0.7840\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6095 - loss: 0.7600 - val_accuracy: 0.6000 - val_loss: 0.8109\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7859 - loss: 0.6689 - val_accuracy: 0.7333 - val_loss: 0.8134\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7432 - loss: 0.6916 - val_accuracy: 0.6000 - val_loss: 0.7819\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7302 - loss: 0.6094 - val_accuracy: 0.6000 - val_loss: 0.7529\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7117 - loss: 0.5884 - val_accuracy: 0.7333 - val_loss: 0.8075\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8175 - loss: 0.5262 - val_accuracy: 0.7333 - val_loss: 0.7640\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8080 - loss: 0.5904 - val_accuracy: 0.7333 - val_loss: 0.7859\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8380 - loss: 0.4663 - val_accuracy: 0.7333 - val_loss: 0.7512\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7916 - loss: 0.4989 - val_accuracy: 0.7333 - val_loss: 0.7878\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8347 - loss: 0.4288 - val_accuracy: 0.8000 - val_loss: 0.7618\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8263 - loss: 0.5294 - val_accuracy: 0.6000 - val_loss: 0.8220\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7526 - loss: 0.5496 - val_accuracy: 0.7333 - val_loss: 0.7021\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9277 - loss: 0.3263 - val_accuracy: 0.7333 - val_loss: 0.7373\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8418 - loss: 0.4421 - val_accuracy: 0.6667 - val_loss: 0.7997\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8378 - loss: 0.4345 - val_accuracy: 0.7333 - val_loss: 0.7451\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8261 - loss: 0.5529 - val_accuracy: 0.7333 - val_loss: 0.7078\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8750 - loss: 0.3153 - val_accuracy: 0.7333 - val_loss: 0.7520\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8239 - loss: 0.3888 - val_accuracy: 0.6667 - val_loss: 0.7538\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8112 - loss: 0.3995 - val_accuracy: 0.8000 - val_loss: 0.6544\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8354 - loss: 0.4155 - val_accuracy: 0.7333 - val_loss: 0.7286\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8367 - loss: 0.3705 - val_accuracy: 0.7333 - val_loss: 0.7438\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8606 - loss: 0.3687 - val_accuracy: 0.7333 - val_loss: 0.8171\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8218 - loss: 0.3977 - val_accuracy: 0.8000 - val_loss: 0.6460\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8884 - loss: 0.3762 - val_accuracy: 0.7333 - val_loss: 0.6758\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9093 - loss: 0.3465 - val_accuracy: 0.8000 - val_loss: 0.6871\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8673 - loss: 0.4069 - val_accuracy: 0.6667 - val_loss: 0.8240\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8848 - loss: 0.2617 - val_accuracy: 0.6667 - val_loss: 0.7016\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8646 - loss: 0.2767 - val_accuracy: 0.6667 - val_loss: 0.7217\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9267 - loss: 0.3510 - val_accuracy: 0.7333 - val_loss: 0.7021\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8669 - loss: 0.3392 - val_accuracy: 0.8000 - val_loss: 0.6700\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8814 - loss: 0.4571 - val_accuracy: 0.6667 - val_loss: 0.8102\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9021 - loss: 0.3051 - val_accuracy: 0.7333 - val_loss: 0.7001\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9075 - loss: 0.2866 - val_accuracy: 0.8000 - val_loss: 0.7486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Validation Accuracy = 0.8000\n",
      "Confusion Matrix:\n",
      " [[3 0 1]\n",
      " [1 3 1]\n",
      " [0 0 6]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Kicking       0.75      0.75      0.75         4\n",
      " Non-violent       1.00      0.60      0.75         5\n",
      "    Punching       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.83      0.78      0.79        15\n",
      "weighted avg       0.83      0.80      0.79        15\n",
      "\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Mean Accuracy: 0.8600 (std: 0.1345)\n",
      "DNN k-fold results: {'fold_accuracies': [0.625, 1.0, 0.9375, 0.9375, 0.8], 'mean_acc': 0.86, 'std_acc': 0.13448977656312766, 'fold_histories': [], 'confusion_matrices': [array([[2, 1, 2],\n",
      "       [1, 1, 1],\n",
      "       [1, 0, 7]], dtype=int64), array([[3, 0, 0],\n",
      "       [0, 8, 0],\n",
      "       [0, 0, 5]], dtype=int64), array([[6, 0, 1],\n",
      "       [0, 4, 0],\n",
      "       [0, 0, 5]], dtype=int64), array([[1, 0, 1],\n",
      "       [0, 6, 0],\n",
      "       [0, 0, 8]], dtype=int64), array([[3, 0, 1],\n",
      "       [1, 3, 1],\n",
      "       [0, 0, 6]], dtype=int64)]}\n"
     ]
    }
   ],
   "source": [
    "results_dnn = kfold_validation_dnn(save_model_path=\"dnn_model.h5\", model_fn=build_dnn_model)\n",
    "print(\"DNN k-fold results:\", results_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation and Comparison\n",
    "After training, we evaluate each model on the test set.\n",
    "\n",
    "For LSTM/GRU, we can feed X_test in its (N, 30, 132) shape.\n",
    "\n",
    "For DNN, we feed the flattened X_test_dnn.\n",
    "\n",
    "Note: Compare before and after dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Plot n fold, to evaluate training and validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fold_history(fold_history, fold_num=1):\n",
    "    \"\"\"\n",
    "    Plots accuracy and loss for a single fold's training process.\n",
    "    \n",
    "    fold_history: a dictionary like history.history, containing:\n",
    "                  'accuracy', 'val_accuracy', 'loss', 'val_loss'\n",
    "    fold_num: which fold index this represents (for labeling).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract\n",
    "    train_acc = fold_history.get('accuracy', [])\n",
    "    val_acc   = fold_history.get('val_accuracy', [])\n",
    "    train_loss = fold_history.get('loss', [])\n",
    "    val_loss   = fold_history.get('val_loss', [])\n",
    "    \n",
    "    epochs_range = range(1, len(train_acc)+1)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, train_acc, label='Train Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Val Accuracy')\n",
    "    plt.title(f'Fold {fold_num} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, train_loss, label='Train Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Val Loss')\n",
    "    plt.title(f'Fold {fold_num} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold_accuracies': [0.5625, 0.9375, 0.875, 0.9375, 0.8666666666666667],\n",
       " 'mean_acc': 0.8358333333333334,\n",
       " 'std_acc': 0.139905722224329,\n",
       " 'fold_histories': [{'accuracy': [0.3174603283405304,\n",
       "    0.4444444477558136,\n",
       "    0.5079365372657776,\n",
       "    0.6190476417541504,\n",
       "    0.6190476417541504,\n",
       "    0.7142857313156128,\n",
       "    0.7460317611694336,\n",
       "    0.682539701461792,\n",
       "    0.761904776096344,\n",
       "    0.8095238208770752,\n",
       "    0.682539701461792,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.841269850730896,\n",
       "    0.8095238208770752,\n",
       "    0.7460317611694336,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.8253968358039856,\n",
       "    0.8253968358039856,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.8888888955116272,\n",
       "    0.8730158805847168,\n",
       "    0.8571428656578064,\n",
       "    0.8095238208770752,\n",
       "    0.8253968358039856,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648],\n",
       "   'loss': [1.1259390115737915,\n",
       "    1.0817548036575317,\n",
       "    1.031720519065857,\n",
       "    0.9739256501197815,\n",
       "    0.9059779047966003,\n",
       "    0.8585606813430786,\n",
       "    0.7113123536109924,\n",
       "    0.6849968433380127,\n",
       "    0.6142314076423645,\n",
       "    0.5321763753890991,\n",
       "    0.6489902138710022,\n",
       "    0.5657787919044495,\n",
       "    0.590194582939148,\n",
       "    0.5109720230102539,\n",
       "    0.5099722146987915,\n",
       "    0.4866669774055481,\n",
       "    0.5006321668624878,\n",
       "    0.4994184970855713,\n",
       "    0.4772442579269409,\n",
       "    0.5088686943054199,\n",
       "    0.4821341335773468,\n",
       "    0.4209092855453491,\n",
       "    0.5006358027458191,\n",
       "    0.399447500705719,\n",
       "    0.40998369455337524,\n",
       "    0.3911062777042389,\n",
       "    0.4131046533584595,\n",
       "    0.49007388949394226,\n",
       "    0.4051550626754761,\n",
       "    0.49923381209373474,\n",
       "    0.4332803189754486],\n",
       "   'val_accuracy': [0.5,\n",
       "    0.5625,\n",
       "    0.5625,\n",
       "    0.5,\n",
       "    0.6875,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.6875,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.6875,\n",
       "    0.5,\n",
       "    0.625,\n",
       "    0.6875,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.625],\n",
       "   'val_loss': [1.0530152320861816,\n",
       "    1.0546839237213135,\n",
       "    1.0246176719665527,\n",
       "    0.9753974080085754,\n",
       "    0.9511970281600952,\n",
       "    0.9790453910827637,\n",
       "    0.9444800615310669,\n",
       "    0.9067230224609375,\n",
       "    0.8649172782897949,\n",
       "    0.9812058210372925,\n",
       "    0.9195013642311096,\n",
       "    0.8909869194030762,\n",
       "    1.0581181049346924,\n",
       "    0.8980920314788818,\n",
       "    0.9156967997550964,\n",
       "    0.8987732529640198,\n",
       "    0.8780807852745056,\n",
       "    0.8510560989379883,\n",
       "    0.8623326420783997,\n",
       "    0.894005298614502,\n",
       "    0.8413375020027161,\n",
       "    0.9018607139587402,\n",
       "    0.9062145948410034,\n",
       "    0.9486077427864075,\n",
       "    0.9216710925102234,\n",
       "    0.9212017059326172,\n",
       "    0.9909323453903198,\n",
       "    1.0025849342346191,\n",
       "    0.9343304634094238,\n",
       "    0.887265682220459,\n",
       "    0.9114580154418945]},\n",
       "  {'accuracy': [0.30158731341362,\n",
       "    0.4285714328289032,\n",
       "    0.4761904776096344,\n",
       "    0.460317462682724,\n",
       "    0.6507936716079712,\n",
       "    0.60317462682724,\n",
       "    0.682539701461792,\n",
       "    0.682539701461792,\n",
       "    0.682539701461792,\n",
       "    0.7301587462425232,\n",
       "    0.6190476417541504,\n",
       "    0.6507936716079712,\n",
       "    0.682539701461792,\n",
       "    0.682539701461792,\n",
       "    0.6984127163887024,\n",
       "    0.7936508059501648,\n",
       "    0.7777777910232544,\n",
       "    0.7460317611694336,\n",
       "    0.7301587462425232,\n",
       "    0.7460317611694336,\n",
       "    0.7936508059501648,\n",
       "    0.7777777910232544,\n",
       "    0.7301587462425232,\n",
       "    0.7301587462425232,\n",
       "    0.761904776096344,\n",
       "    0.761904776096344,\n",
       "    0.8095238208770752,\n",
       "    0.8571428656578064,\n",
       "    0.7142857313156128,\n",
       "    0.8095238208770752,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.7936508059501648,\n",
       "    0.7301587462425232,\n",
       "    0.7301587462425232,\n",
       "    0.8253968358039856],\n",
       "   'loss': [1.0908900499343872,\n",
       "    1.0460925102233887,\n",
       "    1.0122874975204468,\n",
       "    0.969506025314331,\n",
       "    0.9344828724861145,\n",
       "    0.9118253588676453,\n",
       "    0.8137602806091309,\n",
       "    0.7323446869850159,\n",
       "    0.7963839173316956,\n",
       "    0.7019793391227722,\n",
       "    0.7275062799453735,\n",
       "    0.745151937007904,\n",
       "    0.7211071252822876,\n",
       "    0.6912047266960144,\n",
       "    0.730469286441803,\n",
       "    0.6684992909431458,\n",
       "    0.605312705039978,\n",
       "    0.6463080048561096,\n",
       "    0.6460874676704407,\n",
       "    0.6896951794624329,\n",
       "    0.642984926700592,\n",
       "    0.5467885136604309,\n",
       "    0.6316507458686829,\n",
       "    0.5819316506385803,\n",
       "    0.5942420363426208,\n",
       "    0.535153329372406,\n",
       "    0.5723036527633667,\n",
       "    0.5116034150123596,\n",
       "    0.6315814256668091,\n",
       "    0.5250215530395508,\n",
       "    0.5234621167182922,\n",
       "    0.6427360773086548,\n",
       "    0.5711151361465454,\n",
       "    0.5723876357078552,\n",
       "    0.5526620745658875,\n",
       "    0.583242654800415,\n",
       "    0.6221170425415039,\n",
       "    0.5829467177391052],\n",
       "   'val_accuracy': [0.3125,\n",
       "    0.3125,\n",
       "    0.4375,\n",
       "    0.6875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    1.0],\n",
       "   'val_loss': [1.097918152809143,\n",
       "    1.0762789249420166,\n",
       "    1.0233283042907715,\n",
       "    0.9137893915176392,\n",
       "    0.8287273645401001,\n",
       "    0.7713651061058044,\n",
       "    0.6546081304550171,\n",
       "    0.5771198868751526,\n",
       "    0.46476221084594727,\n",
       "    0.4705938994884491,\n",
       "    0.35372528433799744,\n",
       "    0.35796546936035156,\n",
       "    0.3663329482078552,\n",
       "    0.2983076572418213,\n",
       "    0.29397672414779663,\n",
       "    0.3104560971260071,\n",
       "    0.27101609110832214,\n",
       "    0.2700984477996826,\n",
       "    0.2911880612373352,\n",
       "    0.2783403992652893,\n",
       "    0.2873424291610718,\n",
       "    0.23794445395469666,\n",
       "    0.25302326679229736,\n",
       "    0.2288151979446411,\n",
       "    0.29651424288749695,\n",
       "    0.2540459632873535,\n",
       "    0.26325565576553345,\n",
       "    0.1861906349658966,\n",
       "    0.28833380341529846,\n",
       "    0.2668594717979431,\n",
       "    0.21334347128868103,\n",
       "    0.2411758005619049,\n",
       "    0.21620945632457733,\n",
       "    0.24578677117824554,\n",
       "    0.2068415880203247,\n",
       "    0.20059049129486084,\n",
       "    0.20716458559036255,\n",
       "    0.22895726561546326]},\n",
       "  {'accuracy': [0.380952388048172,\n",
       "    0.460317462682724,\n",
       "    0.5873016119003296,\n",
       "    0.6666666865348816,\n",
       "    0.6349206566810608,\n",
       "    0.682539701461792,\n",
       "    0.7777777910232544,\n",
       "    0.7777777910232544,\n",
       "    0.7142857313156128,\n",
       "    0.6984127163887024,\n",
       "    0.761904776096344,\n",
       "    0.761904776096344,\n",
       "    0.7936508059501648,\n",
       "    0.7936508059501648,\n",
       "    0.7301587462425232,\n",
       "    0.6984127163887024,\n",
       "    0.7936508059501648,\n",
       "    0.761904776096344,\n",
       "    0.7142857313156128,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.761904776096344,\n",
       "    0.8095238208770752,\n",
       "    0.7936508059501648,\n",
       "    0.8095238208770752,\n",
       "    0.7936508059501648,\n",
       "    0.761904776096344,\n",
       "    0.841269850730896,\n",
       "    0.761904776096344,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.7936508059501648],\n",
       "   'loss': [1.094396948814392,\n",
       "    1.0186513662338257,\n",
       "    0.975837230682373,\n",
       "    0.9224565029144287,\n",
       "    0.8485590219497681,\n",
       "    0.8009947538375854,\n",
       "    0.7345453500747681,\n",
       "    0.6975196599960327,\n",
       "    0.6826500296592712,\n",
       "    0.7032526135444641,\n",
       "    0.5895509719848633,\n",
       "    0.6105783581733704,\n",
       "    0.6161506772041321,\n",
       "    0.5630019903182983,\n",
       "    0.6102285385131836,\n",
       "    0.6201743483543396,\n",
       "    0.5783756971359253,\n",
       "    0.5782152414321899,\n",
       "    0.6353999376296997,\n",
       "    0.5203173160552979,\n",
       "    0.5189028382301331,\n",
       "    0.6138350367546082,\n",
       "    0.5092709064483643,\n",
       "    0.5191506147384644,\n",
       "    0.5321996808052063,\n",
       "    0.503073513507843,\n",
       "    0.5625954866409302,\n",
       "    0.48872891068458557,\n",
       "    0.4917446970939636,\n",
       "    0.5339361429214478,\n",
       "    0.5256330370903015,\n",
       "    0.43807050585746765],\n",
       "   'val_accuracy': [0.3125,\n",
       "    0.5,\n",
       "    0.5625,\n",
       "    0.5625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.6875,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.6875,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.6875,\n",
       "    0.875,\n",
       "    0.75,\n",
       "    0.75,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.6875,\n",
       "    0.6875,\n",
       "    0.8125,\n",
       "    0.6875,\n",
       "    0.8125,\n",
       "    0.875],\n",
       "   'val_loss': [1.0750389099121094,\n",
       "    1.1156646013259888,\n",
       "    1.088106632232666,\n",
       "    1.032050371170044,\n",
       "    0.9275708198547363,\n",
       "    0.7938601970672607,\n",
       "    0.7246881723403931,\n",
       "    0.6871654987335205,\n",
       "    0.6151909828186035,\n",
       "    0.7044506669044495,\n",
       "    0.5574575662612915,\n",
       "    0.5418511033058167,\n",
       "    0.5111145973205566,\n",
       "    0.48437079787254333,\n",
       "    0.522648811340332,\n",
       "    0.5581366419792175,\n",
       "    0.698421061038971,\n",
       "    0.509432315826416,\n",
       "    0.5001881718635559,\n",
       "    0.5404630303382874,\n",
       "    0.6512874960899353,\n",
       "    0.43847721815109253,\n",
       "    0.6444560289382935,\n",
       "    0.5480148792266846,\n",
       "    0.4605816900730133,\n",
       "    0.4841812551021576,\n",
       "    0.6498593688011169,\n",
       "    0.5616099238395691,\n",
       "    0.4816480278968811,\n",
       "    0.663500964641571,\n",
       "    0.46390944719314575,\n",
       "    0.4427153468132019]},\n",
       "  {'accuracy': [0.3174603283405304,\n",
       "    0.5714285969734192,\n",
       "    0.5714285969734192,\n",
       "    0.6507936716079712,\n",
       "    0.60317462682724,\n",
       "    0.7142857313156128,\n",
       "    0.6349206566810608,\n",
       "    0.6349206566810608,\n",
       "    0.6349206566810608,\n",
       "    0.6666666865348816,\n",
       "    0.7301587462425232,\n",
       "    0.761904776096344,\n",
       "    0.7301587462425232,\n",
       "    0.6190476417541504,\n",
       "    0.7460317611694336,\n",
       "    0.7301587462425232,\n",
       "    0.7460317611694336,\n",
       "    0.6349206566810608,\n",
       "    0.7777777910232544,\n",
       "    0.761904776096344,\n",
       "    0.7460317611694336,\n",
       "    0.7460317611694336,\n",
       "    0.6984127163887024],\n",
       "   'loss': [1.1114164590835571,\n",
       "    1.0032227039337158,\n",
       "    0.9880702495574951,\n",
       "    0.9314614534378052,\n",
       "    0.899824857711792,\n",
       "    0.8041921257972717,\n",
       "    0.7969532608985901,\n",
       "    0.7983675003051758,\n",
       "    0.7089870572090149,\n",
       "    0.729351282119751,\n",
       "    0.7301912903785706,\n",
       "    0.6073378324508667,\n",
       "    0.6647077202796936,\n",
       "    0.7217894196510315,\n",
       "    0.6590526103973389,\n",
       "    0.6814014911651611,\n",
       "    0.639419436454773,\n",
       "    0.6956583261489868,\n",
       "    0.5630771517753601,\n",
       "    0.5473679900169373,\n",
       "    0.5659667253494263,\n",
       "    0.5782405734062195,\n",
       "    0.5993603467941284],\n",
       "   'val_accuracy': [0.125,\n",
       "    0.6875,\n",
       "    0.75,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875],\n",
       "   'val_loss': [1.063812017440796,\n",
       "    0.9269239902496338,\n",
       "    0.8374245762825012,\n",
       "    0.7427287101745605,\n",
       "    0.6536519527435303,\n",
       "    0.5677952170372009,\n",
       "    0.46756601333618164,\n",
       "    0.4015263319015503,\n",
       "    0.4045414626598358,\n",
       "    0.441358745098114,\n",
       "    0.4008023142814636,\n",
       "    0.3918807804584503,\n",
       "    0.27599310874938965,\n",
       "    0.3993013799190521,\n",
       "    0.47560644149780273,\n",
       "    0.3165156841278076,\n",
       "    0.29012811183929443,\n",
       "    0.30390113592147827,\n",
       "    0.32480502128601074,\n",
       "    0.4022974371910095,\n",
       "    0.278516560792923,\n",
       "    0.33390265703201294,\n",
       "    0.3124760687351227]},\n",
       "  {'accuracy': [0.296875,\n",
       "    0.453125,\n",
       "    0.5,\n",
       "    0.671875,\n",
       "    0.5625,\n",
       "    0.65625,\n",
       "    0.71875,\n",
       "    0.765625,\n",
       "    0.6875,\n",
       "    0.75,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.65625,\n",
       "    0.796875,\n",
       "    0.734375,\n",
       "    0.734375,\n",
       "    0.859375,\n",
       "    0.828125,\n",
       "    0.703125,\n",
       "    0.796875,\n",
       "    0.828125,\n",
       "    0.75,\n",
       "    0.875,\n",
       "    0.859375,\n",
       "    0.828125,\n",
       "    0.8125,\n",
       "    0.84375,\n",
       "    0.84375,\n",
       "    0.78125,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.796875,\n",
       "    0.796875,\n",
       "    0.84375,\n",
       "    0.859375,\n",
       "    0.875,\n",
       "    0.84375,\n",
       "    0.859375,\n",
       "    0.796875,\n",
       "    0.875,\n",
       "    0.859375,\n",
       "    0.890625,\n",
       "    0.90625,\n",
       "    0.828125,\n",
       "    0.78125,\n",
       "    0.796875,\n",
       "    0.90625,\n",
       "    0.859375,\n",
       "    0.796875],\n",
       "   'loss': [1.0878595113754272,\n",
       "    1.0370234251022339,\n",
       "    1.013826608657837,\n",
       "    0.9316493272781372,\n",
       "    0.9054971933364868,\n",
       "    0.8030211329460144,\n",
       "    0.7559854388237,\n",
       "    0.679504930973053,\n",
       "    0.7050740122795105,\n",
       "    0.5997169613838196,\n",
       "    0.5838465690612793,\n",
       "    0.5822470784187317,\n",
       "    0.6000794172286987,\n",
       "    0.5672616362571716,\n",
       "    0.571566641330719,\n",
       "    0.6098734140396118,\n",
       "    0.3903942406177521,\n",
       "    0.4326888918876648,\n",
       "    0.5597578287124634,\n",
       "    0.4636344015598297,\n",
       "    0.43277648091316223,\n",
       "    0.5371694564819336,\n",
       "    0.3843584656715393,\n",
       "    0.4274696111679077,\n",
       "    0.44489213824272156,\n",
       "    0.4426925778388977,\n",
       "    0.4299982488155365,\n",
       "    0.40157872438430786,\n",
       "    0.5116184949874878,\n",
       "    0.3990757167339325,\n",
       "    0.4634559154510498,\n",
       "    0.4271410405635834,\n",
       "    0.4753708243370056,\n",
       "    0.5056450963020325,\n",
       "    0.42097699642181396,\n",
       "    0.39466336369514465,\n",
       "    0.3902778625488281,\n",
       "    0.3986639678478241,\n",
       "    0.3341079354286194,\n",
       "    0.39571282267570496,\n",
       "    0.3312223255634308,\n",
       "    0.4388491213321686,\n",
       "    0.304014652967453,\n",
       "    0.32099616527557373,\n",
       "    0.36461740732192993,\n",
       "    0.49061527848243713,\n",
       "    0.4682210683822632,\n",
       "    0.3320333957672119,\n",
       "    0.37352895736694336,\n",
       "    0.4207967519760132],\n",
       "   'val_accuracy': [0.4000000059604645,\n",
       "    0.4000000059604645,\n",
       "    0.5333333611488342,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6666666865348816,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.7333333492279053,\n",
       "    0.6666666865348816,\n",
       "    0.6666666865348816,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.6666666865348816,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.6666666865348816,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.800000011920929,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.8666666746139526,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053],\n",
       "   'val_loss': [1.062577486038208,\n",
       "    1.0370938777923584,\n",
       "    0.9892936944961548,\n",
       "    0.933731734752655,\n",
       "    0.8974382281303406,\n",
       "    0.8102115392684937,\n",
       "    0.813595175743103,\n",
       "    0.8576279282569885,\n",
       "    0.7444222569465637,\n",
       "    0.8328158259391785,\n",
       "    0.7783380150794983,\n",
       "    0.761588990688324,\n",
       "    0.8836432099342346,\n",
       "    0.8463832139968872,\n",
       "    0.7236509919166565,\n",
       "    0.8200536370277405,\n",
       "    0.7847186326980591,\n",
       "    0.7633923888206482,\n",
       "    0.8019967675209045,\n",
       "    0.717948853969574,\n",
       "    0.6949531435966492,\n",
       "    0.8872117400169373,\n",
       "    0.7587407231330872,\n",
       "    0.7140670418739319,\n",
       "    0.7100857496261597,\n",
       "    0.9540654420852661,\n",
       "    0.6572832465171814,\n",
       "    0.6984551548957825,\n",
       "    0.8961693048477173,\n",
       "    0.7056551575660706,\n",
       "    0.8672106266021729,\n",
       "    0.728908896446228,\n",
       "    0.8493449091911316,\n",
       "    0.7845203280448914,\n",
       "    0.8494224548339844,\n",
       "    0.7063533663749695,\n",
       "    0.6558479070663452,\n",
       "    0.9318094849586487,\n",
       "    0.8640676140785217,\n",
       "    0.6622253656387329,\n",
       "    0.8673628568649292,\n",
       "    0.7587815523147583,\n",
       "    0.6282886862754822,\n",
       "    0.9551345705986023,\n",
       "    0.7084206342697144,\n",
       "    0.5894095301628113,\n",
       "    0.9581862092018127,\n",
       "    0.7937349677085876,\n",
       "    0.7019985318183899,\n",
       "    0.5925674438476562]}],\n",
       " 'confusion_matrices': [array([[2, 1, 2],\n",
       "         [1, 1, 1],\n",
       "         [2, 0, 6]], dtype=int64),\n",
       "  array([[2, 0, 1],\n",
       "         [0, 8, 0],\n",
       "         [0, 0, 5]], dtype=int64),\n",
       "  array([[5, 0, 2],\n",
       "         [0, 4, 0],\n",
       "         [0, 0, 5]], dtype=int64),\n",
       "  array([[1, 0, 1],\n",
       "         [0, 6, 0],\n",
       "         [0, 0, 8]], dtype=int64),\n",
       "  array([[4, 0, 0],\n",
       "         [2, 3, 0],\n",
       "         [0, 0, 6]], dtype=int64)]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_histories = results_lstm[\"fold_histories\"]\n",
    "\n",
    "# Suppose we want to plot the 1st fold's training & validation curves:\n",
    "plot_fold_history(fold_histories[0], fold_num=1)\n",
    "\n",
    "# Or loop over all folds\n",
    "# for i, fh in enumerate(fold_histories):\n",
    "#     plot_fold_history(fh, fold_num=i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Plot Overall Accurary over K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_model_results(results_dicts, model_labels):\n",
    "    \"\"\"\n",
    "    results_dicts: list of dicts, e.g. [results_lstm, results_gru, results_dnn]\n",
    "                   each dict has \"fold_accuracies\", \"mean_acc\", \"std_acc\"\n",
    "    model_labels:  list of strings, e.g. [\"LSTM\", \"GRU\", \"DNN\"]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Bar chart of mean accuracy (with std as error bars)\n",
    "    means = [r[\"mean_acc\"] for r in results_dicts]\n",
    "    stds  = [r[\"std_acc\"] for r in results_dicts]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(model_labels, means, yerr=stds)  # error bars = std dev\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Comparison of Mean Accuracy (with Std Dev)\")\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Line plot for fold-by-fold accuracies\n",
    "    plt.figure()\n",
    "    for r, label in zip(results_dicts, model_labels):\n",
    "        fold_accs = r[\"fold_accuracies\"]\n",
    "        # Plot accuracies for each fold\n",
    "        plt.plot(range(1, len(fold_accs)+1), fold_accs, marker='o', label=label)\n",
    "    plt.xlabel(\"Fold Number\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Fold-wise Accuracy for Each Model\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies (Sorted High to Low):\n",
      "DNN: 0.8600\n",
      "LSTM: 0.8358\n",
      "GRU: 0.8342\n"
     ]
    }
   ],
   "source": [
    "model_results = {\n",
    "    \"LSTM\": results_lstm[\"mean_acc\"],\n",
    "    \"GRU\": results_gru[\"mean_acc\"],\n",
    "    \"DNN\": results_dnn[\"mean_acc\"]\n",
    "}\n",
    "\n",
    "sorted_models = sorted(model_results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Model Accuracies (Sorted High to Low):\")\n",
    "for model, accuracy in sorted_models:\n",
    "    print(f\"{model}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracies over 100 iteration on 5-fold validation (Sorted High to Low):\n",
    "+ DNN: 0.8455\n",
    "+ GRU: 0.8091\n",
    "+ LSTM: 0.7924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAl4VJREFUeJzt3QdYU1cbB/B/EjYCykZAUXEvnLj33uK2raNqq9Yua6u1tdYOtbafdli1ah1t3YJ7b+vee6KoKNPFlJXc73lPhAICQhLI4P31SXNzuTk5Gea+Oec958gkSZLAGGOMMWYi5PquAGOMMcaYLnFwwxhjjDGTwsENY4wxxkwKBzeMMcYYMykc3DDGGGPMpHBwwxhjjDGTwsENY4wxxkwKBzeMMcYYMykc3DDGGGPMpHBww4qFZcuWQSaT4d69e6891sfHB8OGDSu0urRq1UpcmPH58ccfUb58eSgUCvj5+cHU0L8P+nfy008/wdho8++WnvPXX3+t8zox/eHghhl8QJLTZdKkSfqunlFSKpUoXbq0eA137Nih7+oYld27d+Ozzz5D06ZNsXTpUkyfPr1QH49O1Ll9/q2srGCIDh48mFHHf/75J8dj6PWjv9eoUaPI68eKDzN9V4Cx1/nmm29Qrly5LPuM+YuRTpL6sn//foSHh4tfuStWrEDnzp31VhdjQ6+dXC7Hn3/+CQsLiyJ5TEtLSyxevPiV/dRyZMgo+Fq5ciXefPPNV1qGjh07ZrDBGTMdHNwwg0cn4Pr168NUFNWJMSf0a7pu3boYOnQoJk+ejISEBNja2sLQpKWlQaVS6fW1yi4qKgrW1tY6qxOtWZyUlCTKzI2ZmdkrAYIx6NKlCzZv3ozHjx/D2dk5Yz8FPG5ubqhYsSKePXum1zoy08bdUswkflE3b95cnKRLliyJnj174vr16/k6uXz33Xfw8vKCjY0NWrdujatXr+brMS9duiSa1ukLPN3Zs2fFPgoesgdn/v7+eebc/Pbbb6hevbqoR6lSpUQwRyeCzB49eoS3335bnBzoFz0dv2TJEuTXixcvsGHDBgwcOBD9+/cXtzdt2pTjsdRl1bJlS9jZ2cHe3h4NGjR4pT4nT54UJzGqL732tWrVwi+//JLn80zvbqGWo5zyPH7++WdUqFBBPL9r164hJSUFX331FerVqwcHBwfxOPReHzhw4JVyKRiix69Zs6ZoGXBxcUGnTp1w5swZ8Xd6PrVr187x+VauXBkdO3bM9bWj+lFXFAWD6d0u1G2aHoh9++23GfWm50aBY3JycpYyaH+3bt2wa9cu8f5SUPPHH39AW0+fPsWECRPE8y5RooR4v+gzd/HixVeOpWCKcksqVaokXiMPDw8EBATgzp07rxy7cOHCjOdE7//p06fzXSf6N0j3W7duXZb99Bmiz15OLU/5fR0L8u/2+fPn+Oijj+Dt7S3K9PX1xQ8//CA+K8y0ccsNM3gxMTHiF2Bm6b8G9+7dK77IKcmTvrTphE2BAvXrnzt3LstJNDs6adKXJJ2g6ULHd+jQQZxQX4e6xSiQOnz4MHr06CH2/fvvv6Lbgk4qsbGx4iRDX6LUDP/OO+/kWtaiRYvwwQcfoG/fvvjwww/FCYiCJwoeBg8eLI6JjIxEo0aNxEl13Lhx4sRNAciIESPEY9EX+OtQIBYfHy+CG3d3dxF4UNdU+mOko5M2BVEUPH3++efieZ4/fx47d+7MOHbPnj3iRE0nR6ozlUcB5datW8VtTVDwQM+dXis6ETk6OornRt0ygwYNwqhRoxAXFye6hSgQOXXqVJakXnotqO70eRg5cqQ4WdJ7cuLECRFMvPXWW6KMK1euZOnWpJP2rVu38OWXX+Zat7///luc7Okx07uJmjRpIq7psZYvXy7ev08++US8bzNmzBCvBwWTmd28eVM8l3fffVfUhYKq18n+2SfUekSfL3L37l1s3LgR/fr1E9239FmhoImCOQoQKccqPd+K3rN9+/aJzwC9T/R60ntJrwkFFZmDEPob1ZM+c7NmzRJBED2Wubn5a+tMQQcFOKtWrcKYMWPEPvp3QUEIvX70+c4uv69jfv/dJiYmiteAfhTQ8yhTpoz4t0ifaeqapUCamTCJMQO1dOlSiT6iOV3S+fn5Sa6urtKTJ08y9l28eFGSy+XSkCFDXikrJCRE3I6KipIsLCykrl27SiqVKuO4yZMni+OGDh362vrRfRs2bJhxOyAgQFwUCoW0Y8cOse/cuXOivE2bNmUc17JlS3FJ17NnT6l69ep5PtaIESMkDw8P6fHjx1n2Dxw4UHJwcJASExNfW99u3bpJTZs2zbi9cOFCyczMTLwW6Z4/fy7Z2dlJ/v7+0osXL7LcP/11SktLk8qVKyeVLVtWevbsWY7H5PQ809FrS/dNR+8JvUb29vZZ6pL+WMnJyVn20WO6ublJb7/9dsa+/fv3izI++OCDVx4vvU703KysrKSJEydm+Tvdx9bWVoqPj8/hVctabzouswsXLojHHTlyZJb9EyZMEPupXunoOdO+nTt35vk4mR8vt89/x44dM45LSkqSlEpllvvSa2ppaSl98803GfuWLFki7jt79uxcX6P098LJyUl6+vRpxt/p80v7t2zZkmedDxw4II5bt26dtHXrVkkmk0kPHjwQf/v000+l8uXLi236XGT+zOf3dSzIv9tvv/1WvF+3bt3KUuakSZPEv9H0ehG679SpU/N8bsy4cLcUM3i///67+HWZ+ULo19eFCxdENwf9yk9H3SPt27fH9u3bcy2TWnzol977778vfpmmy08LSDrqHqFfjdRVQY4cOSJ+SVJrArUYELqm8ps1a5ZrOdQy8vDhw1yb/em7NzAwEN27dxfb9Es+/UItGNSyRfXIy5MnT0R3CLUapOvTp4+o29q1azP20WtLv9hpNFr2pM/014lacUJCQsRrRXXP6RhNUH2oRSoz6r5Iz3GhVjDqgqEWGWqJyfyc6fWhx546deor5abXibq10lsT1OczdWvGmjVr0KtXL41yj9I/Y+PHj8+yn1oeyLZt27Lsp5aVvLq/sqP3IPtnny4zZ87MOIZauajFMP350HtN3VPUKpT9NaIWT/rMZ5f9fRswYIDobsz8WSfUcpNf1JpC/y5Xr14tXm+6zvz50+R1LMi/W+oSo3rT88j8b6Zdu3bidaJWV2a6uFuKGbyGDRvmmFB8//59cZ1T037VqlXFyTy3hNn0+1JiY2Z0cs38pU5fgtHR0VmOoS9sOuHSFyedaI8fPy769CnhlPZR03vm4KZatWpZgq/sJk6cKL606XlSTgCdFKj7h7rWCD0+5Q5QtwhdckKPnRc6gaempqJOnToIDg7O2E+5QNQ19d5774nb6bkXeY1Gy88xmsg+Ii4ddVX873//w40bN8RzyOl4qhN1v+T1OpMhQ4aI14LelxYtWojXnbpxqMtKE/Q5osCC3rfMqJuOAr/0z9nrnmNuKLijk3Fe0nON5s2bJ4JO+symc3JyyvIa0b8VSlJ+HerCySz930RBkoCp+4q6yqiLiz7boaGhr3SBFvR1zO+/W3L79m3R/ZU9YM7vvxlm3Di4YSwP9IWc/YREyayUr0IBF/2ypl+AdDJwdXUViZoU4NCJhhIh6STau3fvPB+DAjHKxaB8FcproV/YdH/KLZg2bVpG8iONmqFRTjmh1qq8UABD0gOm7OgXOeUt6RL9sk5vIcks88k3s5xGDdHoLmqZo5aVTz/9VLzGdMKnXIyckmBfh1pNKCGbyqXghq7pBPq6AOJ18ttildfIKE3RfDtTpkwReVKUkEsBHgUK1JqhaeJsbkPNc3o/80LBzIIFC0Q+HCVzU6CfF21a/rKj504tuDQ3UU7o3yozXRzcMKNVtmxZcU2BQXb0K5+a4HPraki/L/26y3xSp1aSzL9O6cSX3g2WLn3EDbXe0C9SCmAouElvuqdrCmwooKBWATqJvg7Vk7oC6ELN7pS8+f3334vkR/rlSaOWKCjQ5CRMv+YpkZISkSnBMvsJgFot6Nc1JdSmJ5VSgmn2X9HpMh+TV33ol3RO3RjZWzPysn79evH+BAUFZTnxZe9+ojpRSx11W+XVekMnbTrhUuIxjZqhRFxK7NV03hj6HNFrSJ8jClLT0ftOrW3pn7PCRK8RjRiiROvM6PEzD8Om14iSdKn1Kz9JwbpA3bH0b4Mm96PXW9vXMb//btOfLyXQaxu4MuPEOTfMaNFIHcpvoW4L+gJMRyddmiiP8l9yQ1949AVPI6sy/xrNPoKCWmbo2MyX7LkIdMKg1pz04IZOKPQFnf5lnr4/N5QjkRkFTfQLl+pFJyI68VI+CrXo0HPLLnu3WW6tNvQLlkaiZL7QsFwKeNKPoS4xCqSoZYRGLmWW/jrRUHdqzaLXKvPrnvmY9JMLBZmZ60cjZo4ePYr8Sg86MpdLrzd1BWZGrw8dQy1dr2ttoGCOToQ0goZOftrMI5P+Gcv+uZk9e7a47tq1KwobvUbZnyPlm9AooeyvEeWczJ07V+sWmfyigPTXX38VwWheXX/5fR3z+++W0GebPicU9GZHn1vqUmami1tumNGv9UNDfxs3biyGAqcPBafk0bzWiqHWEJobhE7iNDyWvlwpUZaGV2f+tfs6FLhQCwt1X2UOYqi1hobj0lB0mo8jLxRQUAsRdRlRlwkNfaUTEH2hU6BBKIGUAijKkaGWBgp+qJWCEkYpb4S2c0OBCwWBlBeUExrKTgmaVBYFLnPmzBHDcmluE2rloGCOghIaWkuBJHV5zJ8/XyQ4U7nDhw8XgSYFMpRvlH4yoW4SOjlRVxC9N5TjQF0UNMSchnjnB7031GpDXXv0elArFJVBz58Ck3TUckEnTzqR0q96mt+GWgKoVY3+Rq1W6SjviPKFKACgIDT7vEQFQa141FVIuVB0wqRAkYaL0+tEXWn02NqgE3BuyxjQa0ItfvQa0Sze9D7Q8PTLly+L9zx7NyPlG/31118iaZfqSJ9Xykmjz8/YsWNFsnVhoHJfV3Z+X8eC/Lulbkya/oCOo65NmiuJni+9PtTaRfMrFeTfOjMy+h6uxVhu0odvnz59Os/j9u7dK4Y4W1tbi+HE3bt3l65du5ZjWelDwQkNn502bZoYYk33bdWqlXTlyhUxZDc/Q8FJbGysGFZKw6dp2HK6f/75RzzeW2+99cp9sg+R/uOPP6QWLVqI4bc0fLdChQpi2GxMTEyW+0VGRkrvvfee5O3tLZmbm0vu7u5S27ZtxZDu3Jw9e1bUY8qUKbkec+/ePXHMxx9/nLFv8+bNUpMmTTJeUxryvmrVqiz3O3LkiNS+fXvx3GnIba1ataTffvstyzH0OtDwXxq+S8P2d+3aletQ8B9//PGVutFw3+nTp4vj6bWpU6eOGGKcvQxCrz+VUaVKFfF4Li4uUufOncVrkN2sWbPEY1LZ+ZXTUHCSmpoqPkc0PJ7eF3p/Pv/8czFEOzOqLw1hLsjj5TYUPPNnmR7nk08+yfgc07+F48eP5zgUn6YM+OKLLzLqSp+hvn37Snfu3Hnte5Gf4dKZh4LnJftQ8IK8jgX5dxsXFyfK8PX1FZ8JZ2dn8bn+6aefpJSUlAI9N2ZcZPQ/fQdYjDFWlGh00ccffyx+vWcfGcQYM34c3DDGihX6yqNuEBomndMyDowx48c5N4yxYoHyLSgHgwIayrvIbV0txpjx45YbxlixQF1QNMqLJoWjBFpKBGeMmSYObhhjjDFmUnieG8YYY4yZFA5uGGOMMWZSil1CMU3sFRYWJiZH0+U6JowxxhgrPJRFExcXJxbJpclE81LsghsKbHKbqZUxxhhjho1mhH/dzO/FLrhJn86eXhx7e3t9V4cxxhhj+UDLtlDjRPp5PC/FLrhJ74qiwIaDG8YYY8y45CelhBOKGWOMMWZSOLhhjDHGmEnh4IYxxhhjJqXY5dwwxhhjuqJUKpGamqrvapgMCwuL1w7zzg8ObhhjjDEN5lyJiIjA8+fP9V0VkyKXy8UacBTkaIODG8YYY6yA0gMbV1dX2NjY8KSwOpxkNzw8HGXKlNHqNeXghjHGGCtgV1R6YOPk5KTv6pgUFxcXEeCkpaXB3Nxc43I4oZgxxhgrgPQcG2qxYbqV3h1FAaQ2OLhhjDHGNMBdUYb7mnK3FGMvKdNScO7y34iOfQAX+zKoW/MtKMy0S2pjjDFW9PTacnP48GF0795drPBJ0drGjRtfe5+DBw+ibt26sLS0hK+vL5YtW1YkdWWmbe+RGej4V128felnTLwXJK7pNu1njDFmXPQa3CQkJKB27dr4/fff83V8SEgIunbtitatW+PChQv46KOPMHLkSOzatavQ68pMFwUw44NXIDLbv4YoOcR+DnAYY4VFqZJw/M4TbLrwSFzT7cI0bNgw9OrVK8e/Xbx4ET169BCJ0lZWVvDx8cGAAQMQFRWFr7/+WjRC5HVJL5+2R48e/Ur57733nvgbHVPY9Not1blzZ3HJrwULFojx7//73//E7apVq+LIkSOYM2cOOnbsWIg1ZabcFTXz1gpIFNhk6+uV6B+sJOGHWyvQutEn3EXFGNOpnVfCMW3LNYTHJGXs83CwwtTu1dCphkeR1iU6Ohpt27ZFt27dRINByZIlce/ePWzevFk0REyYMCFLwNKgQQO88847GDVq1Ctl0crdq1evFudma2trsS8pKQkrV64UQ7yLglHl3Bw/fhzt2rXLso+CGmrByU1ycrK4ZF4ynbF0lGMTqcg9gY0CnAiF+rgGdUYUad0YY6Yd2Iz55xyyt9NExCSJ/fPfrFukAc7Ro0cRExODxYsXw8xMHRpQYwL1lKQrUaJExrZCoYCdnR3c3d1fKYtSR+7cuYOgoCC88cYbYh9tU2BDZRYFubFNmuTm5pZlH92mgOXFixc53mfGjBlwcHDIuFBEyVg6Sh7W5XGMseI7Y3FiSlq+LnFJqZi6+eorgY0o5+X115uviePyUx49trbc3d3F3DIbNmzQSXlvv/02li5dmnF7yZIlGD58OIqKUbXcaOLzzz/H+PHjM25TIMQBDktHo6LyY83Ti3CJOI36bvV5+Cdj7BUvUpWo9pVu8j8ptIiITULNr3fn6/hr33SEjYV2p/NGjRph8uTJGDx4sOh+atiwIdq0aYMhQ4a80qiQH2+++aY4/96/fz+jZYi6qmhQUFEwqpYbiiwjIyOz7KPb9vb2Gf162dGoKvp75gtj6Wi4t5tSop9dOR/wcv+52Dt4e9fbCNgcgLU31yIxNbFoK8oYY4Xs+++/Fz0klN9avXp1cV2lShVcvnxZo5mGaQAQjWimFhzadnZ2RlExqpabxo0bY/v27Vn27dmzR+xnTBOUJDy+Qh9MDAl85W+UTEw+ffIM9yq2xpbYmwh+HoxvT3yLn8/9jN6+vTGwykB423FLIGPFnbW5QrSg5MepkKcYtvT0a49bNrwBGpZzzNdj64qTkxP69esnLtOnT0edOnXw008/Yfny5Rp1TY0bN05s53dUtEkEN/Hx8QgODs4y1JuGeDs6OorEI2rSevToEf766y/xd2oqmzt3Lj777DPxou3fvx9r167Ftm3b9PgsmLFTqpRipJRckqDK1OXkpgImwhHtYkOBs5vxYeOx2OhZBatvrUFoXCj+uvYX/r72N1p4tcDgKoPRuHRj7rJirJiif/v57RpqXtFFjIqi5OGc2ozpW8TdwUocp5DL9LoUQoUKFcRoKU106tQJKSkp4rUp6hHNeg1uzpw5kyUTOz03ZujQoaIpi1YGffDgv0ROyrKmQObjjz/GL7/8Ai8vL5HZzcPAmTYC7+8U3yajHWqjvk+brDMUy82AgzOAw7Ngf3wehlTtgTd7rcWR6HNYeX0ljoYdxaGHh8TFx94Hg6sORo8KPWBrbqvvp8UYM1AUsNBwbxoVRaFL5gAnPZShvxdWYBMTEyMaEjKjricaAj5w4EBUqlRJJBVv2bJF9JZkTgwuCBpRdf369YztYhPctGrVKs+s7JxmH6b7nD9/vpBrxoqLe/cO4awsWbTa9G78Kdzd/V49qM0XgFMFYPP7wPXNkMc8RItBq9Ci/QKExIRg9Y3V2HRnE+7F3sP0k9Pxy7lf0LNCTwyqMgg+Dj76eFqMMQNHw7xpuHf2eW7ci2Cem4MHD4rupsyooYFm/f/kk08QGhoq8lUrVqwoGhDeeustjR9LX3muMkkXY76MCI2WoiHhFLlycjGbHRiApfG30VJWAnOHHM/74PvHgNVvAC+eAvZewBtrAbfq4k8JqQnYFLwJq26sEkFOuqalm4rWnGaezSCXGVX+PmMsFzQhHaVRUG8CzeSrDZqRmHJwouKS4GpnJXJs9NkVZcivbUHO30aVUMyYLqWmJmJT7C1ALkOAb+/X36FsE2DkXmBlf+BJMPBnR6DfUqBie9ENRUEMJRifCDuBlTdW4vDDw6Lbii6UdDyw8kD0qtgL9hYcVDPG1CiQaVzBSd/VMDn8U5IVW4dP/YqnchmclRKaN1Bn9L8WdU+N2AP4NAdS4tSBzqlFGX+m1pkmnk0wt+1cbAvYhiHVhsDOwk4kIP945ke0W9cO3x7/Fnee3ym8J8YYY8UcBzes2FofrF6FvqdDFZib2+T/jjaOwJtBgN+bgKQCtk8AdkwEaNRVJtRa82mDT7G3715MaTQFviV98SLtBdbeWotem3ph5K6R2Pdgn3q0FmOMMZ3h4IYVSxHh53FUihfbAQ1yX5ssV7SIZs+5QNup6tsnFwCrBgHJca8camNug/6V+yOoRxD+7PAn2pZpK1p4TkacxEcHPkKXoC5YcmUJYpJjtH5ejDHGOLhhxdSGkz+JRTEbSpYoU6aZZoXQnDbNxwP9lgNmVsDtXcCSTkDMw1wOl6GhR0P83Ppn7AjYgbdrvA0HSweEJYRhztk5aLuuLaYem4qbT29q9+QYY6yY4+CGFTvKtBRseHpRbAf4dNa+wOq9gGHbAVtXIPIKsKgN8OhcnncpXaI0Pq73seiy+qbJN6jiWAXJymQE3Q5C3y19MXTHUOy6twupqlTt68cYY8UMBzes2Dl5fhHCFTLYqyS0azRBN4V61QNG7QNcqwHxkcDSLsD1La+9m5WZFXpX7I213dZieafl6OjTEQqZAueizmHCoQnoFNgJCy8txNOkp7qpJ2OMFQMc3LBiZ/2N1eK6m60PLK0cdFdwyTLA27sA33ZA2gtgzVvA0V9yX5QzW5dVXbe6+KnlT9jVZxfeqfUOHK0cEZUYhd/O/yZGWX1x5AtcfXxVd/VljDETxcENK1aePL6FA8pnYjugzhjdP4CVPTBoDdBglHpS9T1fAVs+AJT5715ys3XD+3Xex56+ezC92XTUcKohuqc239mMgdsG4o3tb2Db3W1ILUCZjDFWnHBww4qVrSd/RJpMhpoqM1Su2LVwHkRhBnT9Cej0A0CzEp/7C/gnAHihDqryy0Jhge4VumNVt1VY0WUFupbvCjO5GS5FX8KkfyehQ2AHzLswD9GJ0YXzPBhjzEhxcMOKDUmlQmDkSbEd4Nmq8B+w0Whg4CqAFtEMOQz82QF4elejomq51MLM5jNFa85Yv7FwsXbB4xePMf/ifBHkfHb4M1yIupDnWm2MMQNE81yF/AtcXq++LqJ5ryIiIvDhhx+K9aRomQM3Nzc0bdoU8+fPR2JiojjGx8dHdJmLFc9tbFCzZk2x1lT2NSBLliyZ42PQ/TZuVM8nVtR4+QVWbFy4shIhCgnWKgmdm0wsmget3AkYsQtYOQB4fAtY3A4YuBIo00ij4pytnTGm9hiMrDESex/sFSuTX4i+gB0hO8SlmlM1DK4yGJ3KdYKlwlLnT4cxpkPXNgM7JwKxYf/tsy+tbvWt1qPQHvbu3bsikKGgZPr06SJooYUyaWXwhQsXwtPTEz16qB//m2++wahRo0TAs27dOrFNf+/cWQcjTQsRt9ywYmP9laXiupOVO2xLuBfdA7vXBEbuAzz8gMQnwPLuwKV1WhVprjBH53Kd8XeXv7Gm2xqxCrmF3ALXnlzDl0e/RIf1HfDruV8RkRChs6fBGNNxYLN2SNbAhsSGq/fT3wvJ2LFjYWZmhjNnzqB///6oWrUqypcvj549e2Lbtm3o3r17xrF2dnZwd3cXf584cSIcHR2xZ88eGDoOblixEBf7CLuTI8V2QM23i74C9h7A8O1AlW6AMgUIGgkcnJmvkVSvQ6013zX7Dnv77cWHdT+Eu627GDq+6PIiMZR8/MHxOBNxhrusGCtM9O8rJSF/l6RYYMdn6kEHrxakvqIWHTouP+UV4N/2kydPsHv3brz33nuwtbXNtTspOxV16wcG4tmzZ7CwsICh424pVizsOD4LSXIZfJUy1K42UD+VsLAF+v8N7J0KHPsVODhDvbp4j7mAuZXWxZeyKoWRNUdiWPVhOBB6QHRZnYk8gz3394hL5VKVMajKIHQp3wXWZtY6eUqMsZdSE4HppXVUmKRu0Znpnb/DJ4epv1/yITg4WPzQqVy5cpb9zs7OSEpKEtsU+Pzwww9im1prvvzySyQnJyMtLU203IwcORKGjltuWLEQGHZIXAe4N4ZMrsePPT12h2+B7r8AcjPg8jrgr55AwmOdPQSNqGpftj2WdlqK9d3Xo0/FPrBSWOHms5v4+vjXaL++PWafmY1H8Y909piMMeN26tQpXLhwAdWrVxeBTLpPP/1U7N+/fz/8/f0xZ84ckYRs6Ljlhpm86zc34ZpcCXNJQrdG1BRsAOoNA0qWBdYOBUJPAIvbAoPXAS6VdPowlR0r4+smX4ulHjbc3oDVN1eLoGbp1aVYfm05Wnq1xOCqg+Hv7p9jUzRjLJ/MbdQtKPlx/xiwou/rj3tjPVC2Sf4eO598fX3Fv/WbN7OuYUc5NcTa2vqVFh26D10ooZiSj+vXr49q1aqJv9vb2yMhIUF0W8kz/XB8/vy5uHZw0OFEqQXALTfM5AVe+ENctzVzRCnHCjAYFVoDI/eog5xn94A/2wF3DxbKQ9ECncNqDMO23tvwa+tf0cijEVSSSnRfjdo9Cr039caaG2uQSE3rjLGCox8H1DWUn0uFNupRUcjtB4UMsPdUH5ef8grww8TJyQnt27fH3LlzRVBSEN7e3hgwYAA+//zzjH3UvUXdVdS6k9m5c+r19SpV0u0Ptvzi4IaZtBeJT7E98YHYDqg6GAbHpTIwaj/g7Q8kxQD/9AHOLi+0h1PIFWhdpjUWdViETT03YUDlASL/5k7MHXx38juxzMMPp37Ag1j1a8YYKwRyhXq4t5A9MHl5u9NM9XGFYN68eSIgoRaYNWvW4Pr166Il559//sGNGzegUOT+uDQ3zpYtW8RIK0LdWB06dMDbb7+Nffv2ISQkBDt37hQjsigQomHj+iCTitkQitjYWNFMFhMTI5rTmGnbcuALTH6wGZ5KYPvQ85DT7MGGKDUJ2PQecGW9+nbTD4G2X6tzdApZXEocNgVvwqobq/AgTh3UyCBDM89mosuqSekmkNNMy4wxgRJv6SRerlw5MQGebue58VQHNoU4zw0JDw8Xc9zQ0O+HDx+KeW6oq6lfv34iMKFJ+2gSv48++khcMuvUqZPogtq+fXtGF9TUqVNFWWFhYfDy8kLv3r0xZcoUlChRArp6bQty/ubghpm0Ycvq46wsGe+X9MM7Pf+GQaN/ijQ8/NBM9e2q3YHeCwGL/Pena4O6qY4+OoqVN1biyKMjGft97H0wsMpAMZdOCYuCfVExZop0FtwQmpGYcnDiI4ESbuocm0JqsTEGHNxoiIOb4uPevUPofmgc5JKE3Z1Xws2tFozCpbXqVhyaD6d0HWDQasCuCCcdpHzH2PtYfWM1NgZvRHxqvNhnY2aDHhV6YFDVQSjvoE4+ZKw40mlwwwoluOG2Zmaygs78LK6by+2MJ7AhtfoDQzYD1o5A2HlgUVsg4nKRVqGsfVlMbDgR+/rtwxf+X4hgJjEtUYy26rmxJ97Z/Q4Ohh6EsojWwWGMsYLg4IaZpNTkBGyKuy22A3x7w+iUbQyM2gc4VQRiHwJLOgG3dhV5NWzMbUSX1MaeG7Gw/UK08m4l8nGOhx/H+/vfR7cN3bD86nLEJMcUed0YYyw3HNwwk3To9K94KpfBRSmhRYP3YZQcy6uHivs0B1LigVUDgZPqYe1FjebFaFy6MX5r8xu2B2wXsyDbW9jjYfxD/HTmJzEx4LTj03D7mTqgZIwxfeLghpmkwDubxHVPhyowMzfipQasSwFvBgF13gIklXo9mu2fAso0vVXJy84Ln9T/RKxlNbXxVFQsVREv0l5g/a31CNgcgLd3vY299/ciTaW/OjLGijcDHRfLmOYiws/jqBQvJrbq3SDrEEajZGYB9PgNcPJVr0t1aiHwNATouwSw0l9SPM2P07dSX7G8A61hRUPJ9z/Yj9MRp8XFw9YD/Sv3F3+nda8YY6yocMsNMzkbTv4ISSZDQ8kSZco0g0mgGUibfaReeJMWvQzeo87DeR6q75qJLqsG7g0wu9Vs7OyzUyzeWcqyFMITwvHLuV9El9WUo1Nw/cl1fVeVMVZMcHDDTIoyLQUbnl4S2wE+XWByaGKv4dvU82FEXQUWtQEenYWhcLd1x4d1P8SefnvwbdNvUdWxKpKVyWJIef+t/TFkxxDsDNmJVFWqvqvKGDNhHNwwk3Li/EKEK2SwV0lo1+gTmCTPesDIfYBrdSAhCljaFbimzjEyFJYKS/Ty7YU13dbg785/o7NPZ5jJzHA+6jw+PfwpOq3vhAUXF+DxC92ths4YY+k4uGEmJfDGGnHd3dYHllb6WY22SJT0Bt7eCfi2B9JeAGuHAEfmqGc5NiDUZeXn6odZLWdhV99dGF17NJysnBD1Igq/X/gdHdZ3wOf/fo7L0UU7jw9jzLRxcMNMxpPHt3BA+Uxs964zBiaPkolp9uKG76pv7/0a2Pw+kJYCQ+Rq44r3/N7Dnr57MKP5DNRyriW6p7be3YrB2wdj8LbB2HJnC1JoZmbGigmaCJMS8Lff3S6uC3tizGHDhokfHXQxNzeHm5ubWCV8yZIlUKlUGcfRulJ0zIkTJ7Lcn9aZatWqVcbtr7/+Whw3evToLMfRKuG0/969e9AHDm6YydhyYhbSZDLUVJmhcsWuKBZoIdAus4DOswBa3PL838A/AcALdZBniMwV5uhWvhtWdF2BVV1XoXv57jCXm+Py48uYfGSyaM2Ze34uohKj9F1VxgoVTZnQMbCjmD5h4r8TxTXdpv2FqVOnTmLhTAo8duzYgdatW4vVvrt16yZWC09Hyx9MnDjxteXRcX/++Sdu3zacea44uGEmQVKpEBh1SmwHeLVGseP/LjBoDUALW977F1jcHnhyB4auhnMNTG8+XbTmjPMbB1drVzxJeoI/Lv2Bjus74tNDn4o8nWK2BB4rBiiAGX9wPCITI7Psp6Ce9hdmgGNpaQl3d3d4enqibt26mDx5MjZt2iQCnWXLlmUc984774iWm/TVv3NTuXJlESB98cUXMBQc3DCTcP7yP7inkGCtktC58Wcolip1AN7eBdh7AU9uA4vbAfePwxg4WTvh3drvYmffnfix5Y+o61oXaVIadt7bKUZYDdg6ABtubxAjrxgzRBSAJ6Ym5usSlxyHGadmQMKrQbv08r+Zp2aK4/JTni6C/zZt2qB27doICgrK2EeLV1J30+eff56lyyonM2fORGBgIM6cOQNDwJP4MZMQeHW5uO5s5QHbEpqtoK1USTgV8hRRcUlwtbNCw3KOUMhlMCruNdRrUtFSDbTo5l89gB5zgdoDYAyoe6qTTydxufH0BlZeX4ntIdtx/el1fHXsK8w+O1tMCjig8gB4lPDIcl/KVTgXdQ7RidFwsXERAZJCrtDbc2EFl5KSjI2H/kBU7AO42pdBr5bvwsLCEsaAZun2X+mvs/KoRafJ6ib5Ovbk4JNiHThtValSBZcuqafSSPfll19i6dKlWLFiBd56661c70stQP379xfdWPv27YO+cXDDjF5sTCh2J0cCchkCao7QqIydV8Ixbcs1hMckZezzcLDC1O7V0KlG1pOowbNzB4ZtBza8A1zfor5+egdo9bl6MkAjUcWxCr5p+g3G1xuPwNuBWHNzjZgY8M8rf2Lp1aVo490Gg6sORn23+tj3YJ/4pZu5id/Nxg2TGk5Cu7Lt9Po8WP4s3PQFVj3eiMdmLzsU4oH5f/+BQc698E7P7/VdvWJBkiSRBJyZi4sLJkyYgK+++goDBuT9I+m7775D1apVsXv3bri6ukKfOLhhRm/HiR+RJJfBVylDrWr9NQpsxvxz7pUG4oiYJLF//pt1jS/AsbAB+v0F7JsGHP0ZOPSDOgen5++AuRWMSUmrkhhRcwSGVh+KQ6GHsPLGSpyKOIW9D/aKCy3zQEFPdum5CzRzMgc4hh/YzH22CZIi64n1iUIm9mMTDD7AoeVIqAUlP85GnsXYfWNfe9y8tvNQz61evh5bF65fvy66orIbP3485s2bJy55qVChAkaNGoVJkyaJBGN94uCGGb3AsMMieyzAvTFkcnmBu6KoxSanHmvaR1+19Pf21dyNr4uKXov20wCnCsDWj4Er64GYUGDgSsDWGcbGTG6GtmXbigutPk5rWdHQ8ZwCG5KezzD95HRUdqwMhYy7qAxRSmoyVjzeqA5ssrUa0DIqMknC6scbMSzlK4PuoqIWj/x2DTUp3US0LFIAnlPejQwy8Xc6rqi6Vvfv34/Lly/j448/fuVvJUqUwJQpU8Sw7x49euRZDrXwUJCzevVq6BMHN8yoXbuxEdflSphLEro3ev2QxewoxyZzV1R29LVDf6fjGldwglGqOwQoWRZY+xYQelK9ZMMb6wCXyjBWtBL5V42/QnPP5vjgwAd5Hhv9IhpdgkxwKQ5Tkt4VlQMKcKLNZCIXp3/7vN9rY0EBC3WZUssiBTKZAxy6TSY2nFhogU1ycjIiIiKgVCoRGRmJnTt3YsaMGWIo+JAhQ3K8D42cmjNnDlauXAl//9xzi2jeHGrp+fHHH6FPHNwwoxZ0caG4bmfmhJKO5Qt8f0oe1uVxBqt8S2DEXmBlP+DZPfVQ8f7LgQrGPWyekjjzg5Z+4ORiw5SWlgKl7PWjfSjJ2JRQVyl1meaUK0aBTWF2pe7cuRMeHh4wMzNDqVKlxCipX3/9FUOHDoU8l9ZvmvDv22+/xeDBg19bPuXozJ8/H0lJ+vvelEnFbAKJ2NhYODg4ICYmBvb29vquDtPCi8SnaLumBeLkMiyqMQ6N6r2cqbcAjt95gkGLss7AmZMGPqUwvn1lNCrv+ErCnVFJeAKsHgyEngCom6bbbKDeMBgrmtGVJj57nSUdl4iVy5lhiHn2GNe3z4NX8AqEWz7D2x5ur71Ph+Q++LjfZ/Aqpf2oIG3RSTskJETkp9AEdtrgUX75f20Lcv7mlhtmtPac+EkENp5KoKGfZqOkaLg3jYrKq2uKnL73TARBld3sMKRJWfSu4wkbCyP852PrBAzdDGwaB1xeC2z5UJ1o3G6aOkfHyNCJID+5C3Qc0797188gcu9vqPl4BxrJ1HMW2b6wgWuaEtEKueiCeoUkwV4FbLhbB5t+PCj+7Y1pVQHlXUrAFFAgw4G37hnftxljLwU+2CWuA5z9IKdlCDRAScKfd66S499kLy9fdauGN/zLwNpcgZuRcfhiwxU0mr4P3229hgdPEmF0zCyBgIVAq8nq28d+VefjpCTAWHMXMucqFGXuAns9ZVoazu36G1ent4DPmrbwf7IRNrJkhMjL4mT1r2D56Q0McO4tjqXk4SzotkyGOIUMVSreRZpKwrqzD9Fu9iG8v+o8bkTE6udJMYPH3VLMKIXcO4geh96HXJKwp/MquLrV1LisDecf4uM1F0GDNZSZ/jVkn+cm5kUq1p0Jxd8n7uP+y6CGfmi2qeyKoU180Lyis/F1WV1aB2waC9BilR5+6oU47T2Mcir77LkL7jbuhZ67wHL3/HEErm//HeXuroI7osU+pSTDxRLNYdl0DKo16pRldOMr89xQ/klaGsqkpuK0tXqo85sVP8Tt27Wx9/p/6461r+aGca19Udu7pFF2S7HC6Zbi4IYZpdnre2NpQjBayUrgtyHaLTHQ/4/jYjTUx+0qomE5p9fOUKxSSTh4KwrLjt3H4VvqL21S3sUWw5r4IKCuF0pYGlGX1YMT6jycxCeAvScweA3grnmwqC+cu2AY7lw+gSf7f0Wtp7thJUsV+57BDjdK90a5Th/AvUzF/M9Q7FURZmsGYpZjKaxwsBPH0MryzZ0HYd6hO9h+OVw07hD6cUFBjn/5wh/VyMFN4eHgRkMc3Bi/1OQEtFvpj6dyGX6tNBStG0/QuKy70fFo879DNLkxjk5qAw+Hgk2GdSc6Hn8fv4/1Zx8iPlm9mi4FNn3reWFI47LGkxfwNARY2R94fAswtwX6LQUqddR3rZiRSE1JxqW9/8D6/BJUS72SsT9YUQFPawxDrY5vw8pGw38Lu76AdHwu5ru4Y34JC7FrSLUhmFB/Au5EJ2DewWBsuhAm5qwiDX0c8V4bX7QoxJbU9BOwj48PrF+2KjHdePHihVitnIObAuLgxvjtOTId4++sgotSwu63zsBMixl3Z+y4jj8O3UXbKq74c5jmSX0U2ASefYjlx+/hbvR/uSstKrlgWJOyaFXJFXJDnwTwxXNg7RAg5BAgkwMdZ6hXGze2rjZWZJ5EPsSt7b+hwv21cMVTsS9VUuCifUuUaDYGlRu0K/DEmq9ISwYWtwUiLuPvcnUwC0/E7oCKAfiq0VeidS70aSLmH7qD9WceIkWpXuCxlpeDaMlpV9VN5//2aH6YW7duiSUGnJyMdP4rA0Xn5rCwMPj6+orh55lxcJMHDm6M3+jl/jiKRIwsURkf9lmvcTmpShUaz9iHx/EpWPhWPXSortmCm9m7rI4EP8byY/ew/2ZURpN5WScbvNWoLPrV94aDddZ/sAZFmQpsGw+c+0t9u8FIoNMPgIYJ28w03Tp3CDGH5qL28/2wkKlbLJ/AAbe8+sG3y/twKe2j2weMvgX80QJIe4EN/m/i6+gjUEkqdCjbATObz4S5wjxjyZSFh+9i5an7SEpVBzk0wnFs6wroVqu0TmcZDw8Px/Pnz0WAY2NjY3z5dgaIVh6nwIaCmjJlyrzymnJwkwcOboxbeNhZdNw9VAwZ3d56PrzLNNO4rJ1XIjD6n7NwsbPEsUltYK7Q7eBBGkn11/F7WHsmFLFJ6hOAjYUCAXU9MbSxDyq6qXMIDA59JRz7DdjzlXqOZt92QN+lgBX/eynOUpKTcGn3cthdXILKaTcy9t8yq4TYWm+jZoehsLQqxDlozi5TT10gN8ee7tPx2ZX5SFOloWnppmIyvMxLHzyOT8aSIyH46/j9jO7ics62Ygg5DSXXxb91OnXSLL8U4DDdoUkEqUvKwkLdBZkZBzd54ODGuM3fOBjzYi7DX7LC4mGntSpr2NJTOHgzWnzhTeyU83BwXUhMScOG849Ea86tyPiM/U19nTCksY9oNjfIdatoRfHAUeLXMlyrqRONS5bRd61YEXscdh+3d/yKiqHr4Qz1iTxFUuCSQxvYtxqHSnVbFU1F6FRFUxbQ59KxAo71+BEfHf1czFJdx7UO5radC3uLrN/pMYmpoqt4ydEQPE9UJzd7lrTG6JblRSuqlblCJ11Uqanqspn2KKjJbZZkDm7ywMGN8VKmpaDTX3URoZDhB58AdGk5TeOywp6/QNMf9ovvy4MTWsHH2RaFjf6pHb/7RAQ5e65F4mX+o/iyfatxWQxs4I2SNq/+WtGrR+eAVYOA+AjA1lU9VNzr9asUM+MmqVS4eWYfEv6dh1qxh2AuU4r9UXDEnbL9UbHzODi7exd9xRKfAvObAnFhQJ03caHxKIzdOxZxqXGo4lgFC9otgJP1qzkwCclpWHHyPhYeDhGtOoRabN9pXh6D/cvA1phGNxZjsRzc5I6DG+N15NRvGHN9IexVEvYPOgpLKweNy/pl723M2XsLjcs7YdU7jVDUHj5LxD8nHmD16QcZvygtzeTo5ecp5sypVtqAPpsxD4GVA4DIK4CZFdD7D6B6L33XihWCpBcJuLRzCRyvLIWv8k7G/uvm1ZDoNwK12r8Fc32vzB3yL7C8u7rLtO9S3ChdDe/ueRdPk57Cx94HC9svhEeJnOdqSkpVim7iBQfvIOzlrOSlbMzxdtNyGNLEx7Dz4Rg4uMkDBzfGa/zfzbBHFYM3rH0wqf8WjcuhIaMtZh3Ao+cv8MtAP/T084S+0Jft5gthWHbsHq6F/zfbKg1nHdbUBx2qucFMx7lAGkmOA9aPAG6rZ4VG26+AZuN5JJWJiHx4B3d3/Ioqj4JQCurPYbJkjoul2sOx9Tj41m4Kg7LvG+Df/wGWDsCYI7gnU2HUnlGISIiAu607FrVfBB+H3JOaU9JU2Hj+kRhGfu/lhJx2lmZiaRUKdJxK6DmAYzni4CYPHNwYpyePb6Hd1gCkyWQIbPIDKlXsonFZNPHekCWnxK+0k5Pb6qTfXVv0z/DM/WciyKFE5/Q5O2iWZFr6YVDDMvr/wlUpxZwjODlffdvvTaDbHMDMwLrSWL67nq6d2InkY/NRK+4IzGTq0UURcEZIuYGo0mUcSrl4GO6oviUdgUdngTKNgWHbEJ4YhXf2vIN7sffgaOWIP9r/Ibqq8pKmVGHb5XD8fiA4Ix+Ollmhrqp3WpSHmz1P0GdIOLjJAwc3xmnZ1pH435OTqKUyw4rh57Uqa+yKs9h+OULMJvx1j+owNDSclfIDVp16IIapEwuFHN1qe4g61/Iqumnmc3RqEbDjMzo7Aj7Ngf5/ATaO+q0Ty7cXCXG4vGMRnK8tR3nVvYz9Vy1qIaXeSNRsMwhm5kYQsD69CyxoDqTEA62/AFp+hicvnmD03tG48fQG7MztMK/dPPi5+uVrCoc91yMxd38wLj+Kyfg316++F0a3rABvR/2vRM7AwU1eOLgxzl+YPZb54Z5CwtelO6BP+/9pXBYlE9LcNqlKCTs+bI6qHob7GUhOU2LbpXCRgHzxofoLl9QpU1IEOZ1reMAi0zo8Rer2HmDdcCAlDnDyBQavBZwq6KcuLF/C7t3Eg52/oGrERjhAPdHkC8kCl5w6wbXtOJSr7g+jc3E1sIEmmlQAw3cAZfwRmxKLcfvG4XzUeVibWePnVj+jiWeTfBVHp8NDt6JFS87pe8/EPhrJSLlwNFdOBWOZcdxEcXCTBw5ujM/Zi8sx7MJPsFZJONBvL2xLaD7Z3qLDd/H99utikb1N7xlYHkEezj94JoIcakKnwCx9tAd1WVETOq2FVeQir6oTjWNCAetSwMCVQNn8nURY0f0wuHp0C1KPL0DthOOQy9SfnTCZGx5UGIyqXd6Dg6MLjBadvoJGAZfXqacpGH0EsHIQw8M/PvAxjoYdhZncDLNazEL7su0LVPTJu08w90Aw/r39WNym9LIuNT3ErMeG/KPIlMVycJM7Dm6Mzxcr22BzajQCLNwxbdAejcuhj3q72YfEejQzAmqKPBZjQ4t6rjoZKrqtouLUQ1rNFTLRikOjrOqWKVm0M6XGRQKrBgJh58Tkaug5F6g9sOgen+UoIe45rmxfCLebf8FHFZqx/7JlXSgbvIOarfpBYWYiw5+TYoAFzYDnD4AafYE+i0UkkqpMxcR/J2LP/T2Qy+T4uvHX6F2xd4GLvxD6XHRX7b3+34rz7aq64r3WvqhTppSOnwzLCwc3eeDgxrjExoSibVBnJMllWFHvC9SqofmJ88y9p+i74LiYJfjUF+2Ma+XuHEZ77LwaIVpzzt5XN5+Tmp4OIsjpVsuj6BKlUxKBjaOBa5vUt1t8BrSezCOp9OBh8BU83P0rqkVugb1MPQooQbLCFZcucG//IcpWfn3+iVEKPQUs6QRISvVUBS8DbFopftrxadgQvEHcnthgIt6s9qZGD3E9PFZ0V1HrafpZs5mvM8a18YV/OUdefqEIcHCTBw5ujMuaXR/gu4gD8FXKEDTsglaL8H2y9iICzz1E//pemNW3NkzFlUcxYpTV5othIughTrYWGNjQG282Klvglc41olIB+78BjsxR367RB+g5D9BiUVOWPyqlEpcPBwEn/0DtpP9m7Q6VlcajSm+iepcxsHMoBgnfh2YBB74HLEoAo/8FHMuL3XSK++nMT/jrmnq9tDG1x4iLpsHIneh4zD94R8w6nj6qsX7ZUiLIaVnJhYOcQsTBTR44uDEu/Zf64bpciYmuTfFm5wUalxOblIqG3+8Vi+kFjmmCemVNrzn5aUKKGGG14sT9jAnKKBmyY3U3DGtSDg18ShX+F+/5f9Tr/6jSAK+G6jycEkac02HA4mKe4ur2+fC89Q+8pTCxTyXJcNmmAWQN30WNFr0hV+h/moMinapgWTfgwTHAsx7w9i7g5YKadJpbeGkh5l6YK26/WfVNfNrgU9FdpSlaifyPw3ew9vR/K5FTyyl1V9H8VLpeiZyBg5u8cHBjPK7d2IgBJ6fAXJKwv+cWlCxVTuOy/jlxH19uvIJKbiWw66MWJv3riubuoOUdqDXnZMjTjP2UBDmsSVkxaWGhdlmFHAbWvKnOhaAkz8HrANfCW7uruLl/8wIi9vyCGtHbYStTB7FxkjWuuvWAV4cP4OVbA8XW81D18gzJMUDzT9STTWay4voKzDw1U2z3rNATXzf5WiQcayMy9uVK5Ccf4EWqepkK+p6hIKdrTQ/DmITTRHBwkwcObozHd6s7Y03yQ3RWOGLWm4e0Kqv7b0fE/BVTulXDiGaaB0nGhvIEaGVyakKnVitS0sYcAxp4403/soU3f8fj28CKfsCzEMDSHui/HKjQpnAeqxhQpqXh8sF1UJxeiJrJ5zL235N7I7LKENTo/A5s7fQ8/5GhuLoBWDeMTm/A0C1AueZZ/rz5zmZMOToFKkmFdmXa4YcWP8BCof28Pk9oJfKjIfjr2H3EvVyJ3MfJ5uVK5F76m7bBhBhVcPP777/jxx9/FEvH165dG7/99hsaNmyY47G08uqMGTOwfPlyPHr0CJUrV8YPP/yATp065fvxOLgxDi8Sn6LNmhaIl8uwuOY4+Nd9V6uclG6/HRGTcp2Y3BaOtkYwQZmOPU9MEWvq/HX8Ph4+eyH2Uat526rUZeWDJhWcdN+alfBE3YJD3QQ0D0nX/wH1h+v2MUxczNNoXN8+F2XurEJpST1aRynJcMm2Mcwbj0b1pt21ykMzWZvGAef/BuxKA2OOvjLJ5L77+/Dp4U+RqkpFY4/G+Ln1z7Ax102gH/MiFX8dU69E/uzlunGlHazwbssK4keFIcyIbqyMJrhZs2YNhgwZggULFsDf3x8///wz1q1bh5s3b8LV1fWV4ydOnIh//vkHixYtQpUqVbBr1y6MHz8ex44dQ506dfL1mBzcGIfN+yfji9At8FIC24aeh1yhedPxlI1X8PeJ+2IE0dzBdVGcUQLk/htRYpTVkWD1/B2komsJMcqqdx1P3a6QnJYMbH4fuLRGfbvxOKD9N4Ccv+DzEnL1JKL2zUWtJzthLVPPUh0DW1x374UynT5EaZ/K+q6iYUuOBxa2BJ4EA1W7A/3/fmX03vGw4/jwwIdiTpzaLrXxe9vf4UBrVekIrUROXVUL/72L6JfTNjiXsMSo5uXwRqOyRj1aU1+MJrihgKZBgwaYO1ed5KVSqeDt7Y33338fkyZNeuX40qVL44svvsB7772Xsa9Pnz6wtrYWQU9+cHBjHIYuq4dzshR8UKoORvVQj3LQxIsUJRpO34u4pDT8M8IfzSo667Sexiw4Kg7Lj90XI8gSU9S5AnZWZuhf3xtDGpdFWSdb3TwQfcUc/lE9koVU7gr0WQRY6Kh8E5GWmoLL+1fB4uxiVE+5lLH/rtwHj6sPQ81OI2Fta6fXOhqVsPPA4vaAKhXo/gtQj7qqsroQdQFj941FXEocKpWqJNajcrZ21vniuOtoJfJDd8Viveldw8OblBOtpg42vBJ5fhXk/K239syUlBScPXsW7dq1+68ycrm4ffz48Rzvk5ycDCurrENLKbA5cuRIodeXFZ27IftFYCOXJPT0/0yrsnZcCReBjbejteh6Yf/xdbXDt71qiK66r7pVE/kB9Fr9eSQErX46iLeXncbBm1Fi3R2t0C/mlp8Bff4EFJbAzW3A0s5ArHqET3H3LDocx5d/gcffV0Wd4x+IwCZNkuNciRa41nE1yn15Hg37fMyBTUGVrvNfQvGOSUD0rVcOoXWnlnZcCicrJ9x6dgvDdg5DWLxuP5fUDfVWYx8c/LQVZvWthXLOtniemIo5e2+h6Q/7MWvnDZGvw3RLby03YWFh8PT0FF1KjRs3ztj/2Wef4dChQzh58uQr9xk8eDAuXryIjRs3okKFCti3bx969uwJpVIpAp+c0P7Mf6PIj1qHuOXGcP1vfW8sSwhGK5kdfhtyTKuy+v9xHKdCnmJCh0oY16aizupoiiiIOXQ7WnRZHbwZnbG/vLMt3mpcFn3recHOSstfmQ9OAqsHA4mP1fkQg1cDHqYz51BBBF88gmcH5qLWs72wlKlzM57BHjc8A1Cu0/tw9/bVdxWNH82/9E9v4O5BwL0mMHIfYGb5ymEPYh9g1O5RCEsIg5uNGxZ2WIjyDup5cgqja1isRL4/GDcj48Q+K3M5BjcsK1Yid3fguaGMuuVGE7/88gsqVqwo8m0sLCwwbtw4DB8+XLT45IYSkOnFSL9QYMMMV2pyAjbH3RbbfSoGaFXW3eh4EdhQ4mzfevy+vw7Ny9G6siuWDW+IAxNaYXhTH9hZmuHu4wRM23INjabvw1ebriA4Kl7zBynjD4zaBzhXBuLCgCWdgZs7UFykpiTj7LbFuP59Y/hu6IoGz3eIwOa2when/b6H9cQbaDzqFw5sdIXODTRjsY0TEHEZ2PdNjoeVsS+D5Z2Xo5xDOUQmRmL4zuG4/uR6oVSJ5p7qUbu0WLh34Vv1UMvLQYxkpATkFrMOYPKGy2IOHWakLTfULWVjY4P169ejV69eGfuHDh2K58+fY9Oml1O55yApKQlPnjwROTiUm7N161ZcvXo1x2O55ca47DkyHePvrIKLUsLut87ATIsZbmdsv44/Dt9F2yqu+HNYA53Ws7igpMigcw+x/Pj9LEFN84rOIl+gVWVX8WVdYC+eA+uGqn9R05DdjtOBRmNMdsmGxxGhuL1jLircXwtXqOceSpUUuGjfCiVajEXlem141FNhogCa1kAjbwYCvv+lQ2T2NOkpRu8ZjetPr6OEeQmRZFzXrXAHIdApmBbnpPWrTt1Tfzbo31RPv9IY28oXvq68ErlRJhTTsG8a/p2eUFymTBnRIpNTQnFOQ8OrVq2K/v37Y/r06fl6TE4oNmyjl/vjKBIxyq4KPghYp3E5tAxBk5n78Dg+Rfw66lBd85XEmfoL+GjwEzEx4L4bkRlr65RxtBHJx/3qeRc8MVKZCmyfAJxdpr5dfwTQeRagxcg4Q3PzzH7EHZ6HWjEHYCFTz33yGCVx27sfKnZ+H86ly+q7isXHtgnA6UWArSsw5liuM2dTcvG4feNwLuocrBRWmNN6Dpp5NiuSKua4EnkND4xtXQHVS+tuJJexMqqh4NRS88cff4ggh4aCr127Fjdu3ICbm5sYJk55OdS1RCgPh+a38fPzE9dff/01QkJCcO7cOZQsmb8JrDi4MVxhYWfQafcwSDIZtrdZAG/vphqXtfNKOEb/cw6udpY4NqkNzxKqQ9RkTkPr15wOFXN6EGtzBXrV8RStOZXdC5D4Sl8/x+cCu6fQDaBCW6DfUsDKeL/Ik5MScWnXMjhcXopKaf8lsd40q4K42m+jVoehsLDkvIoil/oCWNgaiL4OVOwADF6ba0shDQ8ff3A8jjw6ImYwntl8Jjr6dCyyql6klcgPBIuZxtNRC/R7bXxRtxivRB5rLMENoWHg6ZP4UdDy66+/ihYd0qpVK/j4+GDZMvUvO0o0HjNmDO7evYsSJUqgS5cumDlzpuieyi8ObgzXvA2DMD/2CvxhhcVD/1sAUBPDlp4SSbFjW1XAZ5146v/CQMPsN154JBKQb0SoEyNJo/KOYi2rdlVd8x9UXt8KBI0CUhMBl6rA4DVAKeNq1YgOu4c7239FxYfr4YQYsS9FMsPFkm1RstU4VKzTQt9VZJFX1QGOMlndSuif++SgqcpUTD4yGTvv7RRrUE1tPBUBWuYBFtSNCFqJ/A62XQpD+qDFpr5OGNe6ovh3ZsrLyBh9cFPUOLgxTMq0FHT6qy4iFDLM8umDzi2/1rissOcvxBBL+mQfnNAKPs48n0phoq8QWsOKgpzd1yIzVkr2LGktViUf2MAbpfIzK3TYBXVeRFw4YOsCDFoNeNWHIZNUKtw8vRcJR+ahVuxhmMvU8wVFwRF3fAagUudxcHLz0nc1WWYnFwI7PlVPSzBqP+Ce+1pcSpUS3574FoG3A8XtCfUnYGj1oShqdzOtRJ728t8XLf47rrUvWlUuPiuRx3JwkzsObgzTkVO/Ycz1hXBQSdg36CgsteiW+HnvLfy89zYal3fCqnca6bSe7PWBJS1Suvp0qFilnFiayUVy5JDGPqjh+Zr3NeYRsHIAEHkZMLMCes0HahTtr+X8SEqMx6VdS+B4ZRl8lXcy9l8zr4EXdUaiVrvBMLd4dcgxMwB0yqPP2O1dgEsVYNQBwCL3pRfoFDnn7BwsvbpU3H6n1jsY5zdOLwHFw2eJ+OPQXaw5EyryCkn10vZ4vw2tRO5u8iuRx3JwkzsObgzTx383w15VDN609sHE/ls0LodaDWg4Jc0E+stAP7ECNit6NCvrlothWH78Hq48is3YX79sKbHMQ6ca7jDPrcuKps4PHAHc2qm+3WaKeoVnA/h1GvHgNkJ2/Ioq4RtQCuquuCTJHJccO8CxzfvwrfnfnF3MgCU8BuY3AeIj1Yns3WbneTidJv+88id+OfeLuD2oyiBMajhJdFfpQ1RsEhb9exf/nPhvJXJaQoVWIqdlZsxMNMeQg5s8cHBjeB4/voH2W/siTSZDYNNZqOTbWeOyDt2KxtAlp+BgbY6Tk9vyInV6Rl8v5x48w7Jj97HjcnhGk7qbvSXe8C+LQQ3LwMUuhxYOlRLY/SVwYp76du3B6in0zSz00vV07fgOJB+bj9rxR6CQqZ9DOFxwv/wgVOnyHko682g8oxO8D/jnZavgwJVAla6vvcvqG6vx/Un1MiLdy3fHN02/EQnH+kKto0uPhmDZ0XsZK5HTCMaxrSogoK7prUTOwU0eOLgxPEu3jsDsJ6dQS2WGFcPPa1XW2BVnsf1yhBi183WP6jqrI9NeZGwSVpx8IBYTfPxyunlaqZ1+aVJrTm3vHEY8nl4MbP8MkJRA2WbAgL9fWeG5sCTGx+DyjsVwvb4c5VT3M/ZfsfRDar1RqNVmIBRmpjNsvVja9YV6tJ51KfXwcPvXD07ZcmcLphydAqWkRBvvNpjVchYsKX9Hj2KTUvH38ftY/O/djJXIPWgl8hblMbBhGZP5kcfBTR44uDEs9Ku4x7LauKcAppXuiID2P2lcFp0wG8/Yh1SlJGb/rOrB768holyB7ZfDxZw5F0KfZ+z38y6JoU3KoktND1iaZfoyvr0XWDcMSIkDHCsAb6wDnCoUWv0e3b2O0F2/oFrkZtgjQexLlCxx2bkz3Nq9D5+qhp3kzAq4av3idkDEJaBcC+CtTepZjV/jwIMDmHBoAlJUKfB398evbX6FjXnueTtFJTHl5Urkh+8iKmMlcguMbF5eJPcb+0rkHNzkgYMbw3LmwjIMv/g/2KgkHOi3HzYlXDUua+HhO5i+/YZoAdj0nuZz5DAU6XweNMpq66VwpCjVCZLOJSwxuKE33mhUFm72L+eDibwGrOwPxISqf2UP+AfwaabTIPvKvxuhPPEHaiWehPxl19NDmTse+r6Bql3GwqEUryhvkh7fBv5ooZ6GoN00oNlH+brbyfCTeH//+2JOnFrOtTCv3Tw4WDoYTM7b+rMPxQir9JXIqauellShVu2SNkXfvasLHNzkgYMbwzJ5RRtsSYtGHwsPfD1ot8bl0Me47exDuBudgBkBNUUuBzMe1Oq26uQD/HPyPiJj1b84zeQykXhMX8g0cZksPgpYPQh4dBaQmwM9fgP8Bmn1uPGxz3B1xx/wuPkXyqgeZey/ZFUfUsNRqNmyH+QK02jSZ3k4uxzY8gFA+TMj9gCe+Vty4XL0ZYzZNwYxyTGoWKoiFrZfCGdrwwmCU5UqbLoQhnkHgsUaccTWQr1K+cjm5cQPCWPCwU0eOLgxHLExoWgT1BnJchlW1P8StaoP0Lis0/eeot+C47CxUODUF+2Mvvm1uKIv411XI0Rrzul7zzL21/C0x9DGPuherRSstr4HXNuo/kPzCUDrL/LVlZBZ6O2LeLT7N9SI2ooSMvUv23jJGlddu8Kj/fsoU8lPt0+MGTY6Da4dAlzfDDiWB979F7DM35pOt5/dxrt73kX0i2h423ljUYdF8CxhWKM0lSpJdAX/fiA4Y8JNWol8YIMyeLdleXg4WMMYcHCTBw5uDMfqne/j+8iD8FXJETT0vFYLB36y9iICzz3EgPre+KFvLZ3Wk+nH1bAYEeTQL8/kl3N6ONpaYGB9T4xRrYbdafWwXFTvLebDUcrMcePkLrx49gjWpTxRxb9jloRflVKJy4cCITu1ELWS/psB+4HcE+GV3kK1zu/CzqFokpWZAUp8CixoBsQ+AvzeBHr9nu+7hsaGYtSeUXgU/wiuNq5Y1H4RypcsD0MjSRL2XY/CbweCRZcwMVfI0LeeF8a09EUZJ/3nDeWFg5s8cHBjOPov9cN1uRKTXJvhjc7zNS6H1jfyn74XSakqBI1tUqzXXjFFzxJSxKSANDlgev4AzVU21esC3noyB3JVKhJKlEVifCxc8F9rTyScENZ4Kso37Irr2+fBK3gFvKQI8TeVJMMlG38oGr2L6s16ctcTU7t3FFhGQ8IloO8SoEaffN81MiFStODcibmDkpYlsaD9AlR3MswRm5Ik4UiweiVyml08fSXyHrVpJfIKqOhWgPXhihAHN3ng4MYwXL0RhIEnp8JCkrC/11Y4lPTRuCxaxHHKxiuo5FYCuz5qUWymIi9u0pQq7L0eJVpzjt99IvY1kl/DEoufYIMk0bOQ+a2nKXXoZjLMYPVyRe5Y2OCaW094d3wfnuUN88TD9Gz/d8DhHwFKDh5zBCiZ//y9Z0nPMGbvGFx9chW25raY22Yu6rsb9ui60/eeiiCH5ggj9G+oU3V3MSHga2cUL2Ic3OSBgxvD8O3qTlib/AidFY6Y9eYhrcrq9tu/YhbcKd2qYUSzcjqrIzNcNyPixOzHG88+wEHFGLggJs8JjENk3oiqNgw1O4+CTQnD+sJmBkaZCiztDDw8DXg3AoZtAxT5z+GLT4kXo6jORJ4R89/MbjUbLbwMf9HUSw+fiyCH1odL17qyC8a1qSjWsTK287dpTV/IjEJi4mNsf/FQbPep9oZWZV15FCMCG5oMLqCOYSXxscJT2d0O03vXxN/tlHCV5R3YkMS2M+DfbwIHNuz1FOZAwCLAwg4IPQH8+78C3b2ERQnMbzcfLb1aIlmZjA/3f4gdITtg6Gp5lcTCIfVF6zd1T1HX74Gb0egz/xgGLTyBY8GPRXeWseDghhW5PSd+QrxcBi8l0KD221qVteZ0qLjuWMM9fytPM5MixatzaF7nxfPwQq8LMyGO5f5bb+rQTODBiQLd3crMCnNaz0Hncp2RJqVh4uGJWHdrHYzlh8Ovg+pg3yet0L++l5iSgbqBBy8+iYD5x7D/RqRRBDkc3LAiF/Rgj7ju41wX8gI092b3IkWJjRfUc5MMbOCts/ox40GjonR5HGMZavUHag2gGR6BwFFAUkyB7m4uN8eMZjPQv1J/SJDwzfFvsPSKemVxY1DO2Raz+tbGwU9bYUjjsmKdqvMPnuPtZWfQ9dcjYmi56uVacdmHnR+/8wSbLjwS13RbHzjnhhWpuyH70PPwR1BIEnZ3Xg1XtxoalxV49iE+WXcR3o7WODShNeTUjsqKFWVaGh5/Vwku0hPRjJ4dfa9GyZzg8uUtXgeKFVxSrHp4+PP76pFTff4s8Or0dIql1cRpVXEysuZIfFDnA6Mb+BAVm4TFR0LEqMXEFPVK5BVcbEXiMXVj0UrkO6+EY9qWawiPScq4H61xNbV7NXSq4aF1HTjnhhmsoDO/ievmcnutApvMXVI0tw0HNsUTBSw03Jtk/4GYfju88VQObJhmrOxfBjQK4EogcHF1gYugIOajeh/hw7ofituLLy8WK4urqEXIiLjaW2Fyl6o4OrENPmjjCzsrM9yJTsD4tRfR5n+HMDnoMsb8cy5LYEMiYpLEfgp8ihIHN6zIpCYnYHN8sNjuUyn/80fk5E50PE7deyp+rferz11SxVmdjkNxscmviJY5ZdlPLTa0n/7OmMa8GwCtP1dvb58APLmjUTHUYjOl0RTIIMOam2sw+chkpKrUK3gbk1K2FhjfoTKOTmqDTztWFhNrPniaiJWnHtDsQK9I30ctOkXZRcXBDSsyB07NwTO5DK5KCc3qvadVWWtfttq0qeL63+KKrNiiAMb5y1u42n4lztT/UVxTVxQHNkwnmo0HyjYFUuKBwJHq4eIa6F+5P2Y2nwkzmRm23d2G8QfGixFVxsjeylx0SR2Z2BpvNSqb57EU0lCLzqmXEwYWBQ5uWJEJurtFXPcsWQ1m5poHJClpKrHiLRnQgBfIZGrU9VS9aVfU7/aOuOauKKYzcgUQsBCwcgDCzgEHpmtcVJfyXfBz65/FHDgHHx7E2L1jkZCqXtTSGNlYmKG+T/7mwYmKy9plVZg4uGFF4tGjUzgmqf8B927wsVZl7bseiScJKXC1sxSTTDHGWKFz8AK6/6rePjIHCDmscVEtvVuKuXBszGxwKuIURu4aiedJ6rWejJGrnZVOj9MFDm5Ykdh4ag4kmQz+sIK3d2OtyqJ1hggt9kYZ+owxViSq9wLqDlF3tAS9q15sU0MN3BtgScclYh2qK0+uYPiu4YhKjIIxaljOUYyKym1YB+2nv9NxRYXPDKzQKdNSsOHZZbHdx4cWpdMcLZx4+LZ6DZQBPLcNY6yodZoJOPkCcWHA5vdprLfGRVV3ro5lnZbB1doVwc+DMXTHUITGqX+8GROFXCaGe5PsAU76bfo7HVdUOLhhhe7YuQWIVMjgoJLQxl+7Lql1Z0LFd0mTCk4o62Srszoyxli+WNiqh4fLzYEbW4Gz2k3MV6FkBSzvvBxeJbzwMP6hCHCCn6lHlRqTTjU8MP/NunB3yNr1RLdpvy7muSkIzrhjhS7o5lpx3d22PCwpIU9DNIwwfZQUt9owxvSmtB/Qbiqw+0tg52SgTBPAtYrGxXnZeeGvzn/hnT3viBacYbuGYUG7BajhrN1cYEWNApj21dzFqChKHqYcG+qKKsoWm3TccsMK1ePHN3BQqU6UC6g7Vquy/r0djbCYJDhYm6NjdXcd1ZAxxjTQ6D2gfGsg7YV6eHiqdiOBXGxcRBdVTeeaiEmOwYhdI3A64jSMjUIuQ+MKTujp5ymu9RHYEA5uWKHafHwW0mQy1FKZo6JvJ53MSNy7jieszBU6qiFjjGlALgd6LwBsnIDIy8C+aVoX6WDpgEUdFsHf3R+JaYkYvWc0DoYe1El1ixsOblihkVQqBEWrf3n08W6jVVmP45Ox51qk2B7YkLukGGMGwM4d6DlPvX1iHnBbvSiwNmzNbfF7u9/RyrsVUlQp+OjAR2LCP1YwHNywQnP20l+4rwBsVBI6NfpMq7KCzj1EmkqCn3dJVHHnBU8ZYwaicieg4Tvq7Y1jgHjth3PTBH+zW81Gt/LdoJSU+Pzfz7Hmxhrt61qMcHDDCk3Q1b/EdWer0rAp4apxObSqbvrcNgM5kZgxZmjafwu4VgMSotUBjkr7RTHN5eb4vtn3GFh5ICRI+O7kd2LRTZY/HNywQhET8wC7U9S/YPrUGqVVWafvPcPd6ATYWCjQrXZpHdWQMcZ0hJaToeHhZlZA8F7g1B86KVYuk2Oy/2SMqqn+Dv3l3C+Yc3aO+MHH8sbBDSsU24/PQrJchooqOWpU1W4F8NWnH4jr7rVKo4Qlz17AGDNAbtWADt+pt/d8BUSoJy7Vlkwmwwd1P8D4euPF7SVXluDbE99CqVLqpHxTxcENK5RE4sDwf8V2H/cmkNGoAg3FvEjF9svhYpsTiRljBq3BSKBSZ0CZAqwfAaQk6qzo4TWGY2rjqZBBhnW31uHzI58jVaXZ6uTFAQc3TOeu3dqIm3IVLCQJ3RpP1KqszRfDkJSqQmU3O5FMzBhjBksmA3r+DpRwBx7fBHZ/odPi+1bqi1ktZsFMZoYdITvESKqktKJbaduYcHDDdC7owkJx3c7MGQ4lfbQqa/WpBxkzElPzLGOMGTRbJ/X8N+TMEuD6Vp0W36lcJ/zS5hcxourww8MYvXc04lPidfoYpoCDG6ZTiYmPse3FQ7Hdp/qbWpV15VEMrobFwkIhFxP3McaYUajQGmjygXp78zggNkynxbfwaoE/2v+BEuYlcDbyLEbsHoFnSc90+hjGjoMbplO7j/+IBLkM3kqgfq1hOkkk7ljDHaVsLXRUQ8YYKwJtpgAetYEXz4CgdwAdJwDXc6uHPzv+iVKWpXDtyTUM2zkMkQnqiU4ZBzdMx4JC94rrAOe6kCs0H9n0IkWJTefVv3YG8dw2jDFjY2YB9FkCmNsA9/4Fjv2q84eo5lQNyzovg6uNK+7G3MXQnUMRGqueE6y44+CG6czdkH04L0uBQpLQs9GnWpVFI6TiktNQxtEGjco76ayOjDFWZJx9gc6z1Nv7vwMendX5Q5R3KC9WFC9jVwaP4h9hyM4huPXsFoo7Dm6YzgSd+U1ct5Dbw8W1hk66pCiRWK6nVWUZY0xrdd4EqvUCVGnq1cOT43T+EJ4lPLG883JULFURj188xvCdw3Ep+hKKMw5umE6kJMdhc3yw2O5Tqa9WZQVHxYtZiSmm6VvPS0c1ZIwxPaBRnt1/Buy9gKd3gR3aTY+RG2drZyztuBS1XGohNiUWI3ePxInwEyiuOLhhOnHg1M94JpfBVSmhab2xWpW19oy6z7hNFVe42VvpqIaMMaYn1qWAPosAmRy4sAK4vL5QHsbB0gGL2i+Cv4c/XqS9wNi9Y7H/wX4URxzcMJ0IurtFXPcsWQ1mtM6KhlLSVAg8qx5KPrBBGZ3VjzHG9KpsE6D5BPX21vHAs/uF8jA25jaY13Ye2pZpK2YwHn9wPLbcUX8/Fycc3DCtPXp0Cscl9TTjvRt8rFVZ+65H4klCClztLNGqsouOasgYYwag5UTAqyGQHKMeHq5MK5SHsVBY4KeWP6FHhR5QSkpMPjIZq26sQnHCwQ3T2sZTcyDJZGgEK3h7N9aqrFWn1V1S/ep7wUzBH0/GmAmh6TGoe8rCDgg9Afz7U6E9lJncDN82/RaDqwwWt6efnI6FlxYWmxXF+ezBtKJMS8GGZ+rVb/uU66ZVWQ+fJeLf29Fiu399ntuGMWaCSvkA3eaotw/9ADwovKRfuUyOSQ0nYXTt0eL2b+d/w+yzs4tFgMPBDdPK0bPzEamQwUEloY3/eK3KWnfmIejfXJMKTijrZKuzOjLGmEGp1Q+oNRCQVOrh4S+eF9pDyWQyvOf3Hj6tr557bNnVZZh2fBqUOp4x2dBwcMO0EnRrrbjuXqI8LCztNC5HqZKw7uUoqYENOZGYMWbiuvyobsWJCQW2fgTxy64QDak+BN80+Ua05gTeDsTEfyciVZkKU8XBDdPY4+jrOKSMEdt96rynVVnUHRUWk4SSNuboUM1NRzVkjDEDZWUP9PkTkCmAqxuACysL/SF7V+yNH1v8KPJxdt3bhQ8OfCCGjJsiDm6YxjadmIU0mQy1Vebw9e2oVVmrT6lbbWj1bytzhY5qyBhjBsyrPtB6snp7+6fAkzuF/pAdfDpgbpu5sFJY4cijIxi9ZzTiUnQ/a7K+cXDDNCKpVAiKPiO2+3i31aqs6Lhk7L0embHcAmOMFRvNPgZ8mgOpCUDgCCAtpdAfsqlnU/zR/g/YmdvhXNQ5jNg1Ak+TnsKUcHDDNHLm0jI8UAA2KgkdtVwkM+jcQ6SpJPh5l0QVd3ud1ZExxgyeXAH0/gOwKgmEnQcOfF8kD1vXrS6WdFoCRytHXH96HcN2DkNEQgRMBQc3TCNBV/8W152tSsOmhKvG5dCQxDUv57YZ1JBbbRhjxZCDJ9BDvfAwjv4C3D1YJA9bxbEKlnVaBndbd4TEhGDojqG4H1s4MycXNQ5uWIHFxDzAnhT1fDR9ao3SqqxTIU9x93ECbC0U6FartI5qyBhjRqZaD6DeMPrJB2wYDSQ8KZKHLedQDn91+gs+9j4ISwgTAc7Npzdh7Di4YQW27fgPSJbLUEkpR42qfbQqK73Vpnvt0rC1NNNRDRljzAh1nA44VwLiwoHN7xf68PB0HiU8sLTTUlQuVRlPkp5g+K7huBB1AcaMgxtW4ETiwPAjYjvAoylkcs0/QjEvUrHtcrjY5kRixlixZ2EL9FkMKCyAm9uAM0uK7KGdrZ1FDo6fi58YPfXOnndwLOwYjFWBz0w+Pj745ptv8ODBg8KpETNo125uwC25ChaShG6NP9OqrM0XHiE5TYXKbnYimZgxxoo9j9pAu6/V27smA1E3iuyh7S3sxSiqJqWbiPlvxu0bh33396FYBDcfffQRgoKCUL58ebRv3x6rV69GcnJy4dSOGZzAi4vEdTtzZziU9NGqrNUvu6QGNvQWU4QzxhgD4D8GqNAWSEtSDw9PTSqyh7Yxt8FvbX5D+7LtkapKxfhD47EpeBOKRXBz4cIFnDp1ClWrVsX7778PDw8PjBs3DufOnSucWjKDkJj4GNtfPBTbfaq9qVVZlx/G4GpYLCzM5GLiPsYYYy9Rd3+v+YCNMxB5Bdj7siWniFgoLDCrxSz08u0FlaTCl0e/xIrrK2BMNE6YqFu3Ln799VeEhYVh6tSpWLx4MRo0aAA/Pz8sWbKkWKw6WtzsOj4LCXIZyiiBBrWGa1XW6tPqbs1O1d1R0sZCRzVkjDETYeemDnDIyfnArd1F+vBmcjNMazINb1ZV/5CdeWom5l+cbzTndo2Dm9TUVKxduxY9evTAJ598gvr164sAp0+fPpg8eTLeeOMN3daU6V1Q6F5x3dulHmQKzZdISExJw+YLYWJ7ICcSM8ZYzip1APxHq7c3jQXio4r04eUyOT5r8BnG+o0Vt+ddmIcfz/xoFAFOgcfeUtfT0qVLsWrVKsjlcgwZMgRz5sxBlSpVMo7p3bu3aMVhpuPOnT24IEuFQpLQ01+7GYm3X45AXHIayjjaoFF5J53VkTHGTE67aUDIv0DUVWDjGGDwOnW3VRGRyWQYU3uMSDam1pu/r/2N+JR4TG08FQqaXdlAFfgVoqDl9u3bmD9/Ph49eoSffvopS2BDypUrh4EDB+qynkzPgs7NFdct5A5wca2uVVlrXnZJ0fBvuZwTiRljLFfmVkDfPwEzKyB4L3BygV6q8UbVN/Bd0+9Ea86G4A349PCnSFEW/jpYRdZyc/fuXZQtWzbPY2xtbUXrDjMNKclx2BJ/h9oo0aeSdpP2BUfF4fS9Z1DIZehbz0tndWSMMZPlWhXo+D2w7RNg71TApxngUavIq9HTtydszW3x2eHPsOf+HiSkJmBOqzlihJXRt9xERUXh5MmTr+ynfWfOqFeJZqZl/8k5eCaXwVUpoWk9dd+rtjMSt67sCjd7Kx3VkDHGTFz9EUDlLgC1ltDw8JREvVSjXdl2mNt2LqzNrMUkf+/ueRexKbEw+uDmvffeQ2io+gSVGXVR0d+Y6QkK2Sque5WqDjNqItVQSpoKgeceiW1OJGaMsQKgucB6zAVKuAOPb6kn+NOTJqWbYGH7hbCzsMOF6AsYsWsEnrwomrWwCi24uXbtmhgGnl2dOnXE3wrq999/F7MeW1lZwd/fX8yfk5eff/4ZlStXhrW1Nby9vfHxxx8jKanoJjgqbh4+PIHjeCG2ezf4WKuy9l6PxNOEFLjZW6JVZRcd1ZAxxooJWycg4A+KdICzS4HrW/RWFT9XPyztuBSOVo648fQGhu0chvD4cChVSpyOOI3td7eLa7ptFDk3lpaWiIyMFDMUZxYeHg4zs4IVt2bNGowfPx4LFiwQgQ0FLh07dsTNmzfh6ur6yvErV67EpEmTxDw6TZo0wa1btzBs2DCRzT179uyCPhWWDxtP/yyuG8EaXl6NdDIjcb963jBT8LJmjDFWYOVbAU0/AI7+ol5cs3RdwEE/E6FWdqyMvzr/hVG7R+Fe7D3039ofCplCLL6Zzs3GDZMaThLdWUWpwGeYDh064PPPP0dMTEzGvufPn4u5bWg5hoKggGTUqFEYPnw4qlWrJoIcGxsbEbzk5NixY2jatCkGDx4sWnuoLoMGDXptaw/TjDItBRueXRHbfcp11aqs0KeJ+Pd2tNjuX5+7pBhjTGOtvwQ8/IAXz4AN7wJ6ah0hZe3LigDHxdoFz5OfZwlsSFRiFMYfHI+999XzpBlscENDvynnhkZMtW7dWlxo6HdERAT+97//5buclJQUnD17Fu3a/RfN0bw5dPv48eM53odaa+g+6cEMjdzavn07unTpUtCnwfLh6NnfEaWQoaRKQhv/8VqVte7sQ9C8T019nVDGyfAy6xljzGiYWQB9lwDmtsC9f9WtOHrkYp17moEE9YR/P5z6oUi7qArcLeXp6YlLly5hxYoVuHjxosh9oZYXakExNzfPdzmPHz+GUqmEm5tblv10+8aNnFdBpRYbul+zZs3EDIlpaWkYPXq0aDXKDS3qmXlhz9hYw8vqNlSBt9aL6+4lKsDC0k7jcpQqCevOqLukBjQoo7P6McZYseVUAejyo3rm4gPfA+VaAl719FKVc1HnEP1C3TKfW4ATkRghjmvg3sAwg5v0eWzeeecdFLWDBw9i+vTpmDdvnsjRCQ4Oxocffohvv/0WU6ZMyfE+M2bMwLRp04q8rsbucfR1HFLGiAz9gLrajYI7fDsa4TFJKGljjg7VsgazjDHGNOQ3WD2x39UgIPBtYPQRQIsfopqKTozW6XF6C24IjYx68OCB6F7KjNaayg9nZ2coFAqRnJwZ3XZ3d8/xPhTAvPXWWxg5cqS4XbNmTSQkJIhA64svvhDdWtlRfhAlLWduuaFRVixvm07MglImQ22VOXwrdNCqrDWn1K02AXW8YGVuuNN1M8aY0Q0P7zYHeHgaeHYP2P4p0LvoZzB2sXHR6XF6m6GY1o66fPmyGKWUvoAWbRPqasoPCwsL1KtXD/v27UOvXr3EPpVKJW6PGzcux/skJia+EsBQgERyW8iLRnfRheWfpFIhKPoMoAD6eLfVqqzouGQxBDx9uQXGGGM6ZF0SCFgELOsCXFwFVGgL1OpXpFWo61pXjIqi5OH0HJvMZJCJv9NxBptQTN1AlEBMMxXTyKarV6/i8OHDYlVw6jYqCGpRWbRoEZYvX47r169jzJgxoiWGcngILcpJLS/punfvLta0Wr16NUJCQrBnzx7RmkP704Mcpr0zF5figQKwVUno2Ei7RTIDzz1EmkpCnTIlUdm96JtLGWPM5JVtDLT4TL29bby6FacI0QKaNNw7PZDJLP32xIYTi3ShzQK33NBIpv3794tuJWpFoQsl+FJuywcffIDz58/nu6wBAwYgOjoaX331lRht5efnh507d2YkGVO3V+aWmi+//FK0ENE1zYjs4uIiApvvv/++oE+D5SHw2j/iurO1J2xKvDrfUH5Ra1r6cgs8IzFjjBWiFp8Cdw8AoSeBwFHA8B2AQuPMkwKjeWxmt5otVg6PTPwv3YRabCiwKep5bmRSbv05uShVqhTOnTsnWm8qVKiAxYsXi+Hgd+7cETkw1HVkyCjnxsHBQczTY29vr+/qGJyYmAdos6ELUmQyrGrwFWpU07x58+TdJxiw8ARsLRQ49UU72FoW3T80xhgrdp7dBxY0A5JjgZYTgdZFv0QDDfcWo6cSo0WODXVF6arFpiDn7wKfbWrUqCGGgFNwQyOWZs2aJfJnFi5c+Mqsxcz4bDv+gwhsKqnkqF5FuxXA01tteviV5sCGMcYKW6my6gTjwBHA4R/VsxmXbVKkVaBApqiGe+s054a6hCjxl3zzzTci96V58+ZiMr1ff/21MOrIijCRODD8iNgOcG8KWQ6jz/IrJjEV2y6Hi22e24YxxopIzb5A7cH0ha7unqJZjIuhAv+cprWf0vn6+ooJ954+fSq6q9JHTDHjdPVGIG7JVbCQJHRrPFGrsjZdfITkNBWquNuhtpeDzurIGGPsNbrMAh4cB56FAFs/BvouVQ8bL0YK9NM8NTVVLI555Yp6vaF0jo6OHNiYgMBLi8V1e3MXOJQsq3E5lMa16uXcNjT8mz8bjDFWhCztgD5/AnIz4OoG4MIKFDcFCm5oeYUyZcrkey4bZjwS46Ow/cUjsd2n2ptalXXlUSyuh8fCwkyO3nX0s1otY4wVa171gNZfqLe3fwY8DkZxUuCkCpoJmNZyoq4oZjp2nfwJiXIZyiiB+rXV8wxpavXpB+K6cw13lLSx0FENGWOMFUjTDwGf5kBqgjrJOC3rigKmrMA5N3PnzhVrOpUuXVqsDE7rTGVGw8SZ8QkK3UuzLaG3Sz2tEokTU9Kw6UKY2OYZiRljTI/kCqD3H8CCpkD4BeDAd0D7b1AcFDi4SV8qgZmO4Du7cUGWCoUkoVejl7NcamjbpXDEJ6ehrJMNGpVz0lkdGWOMacDBE+jxG7DmTeDoL0D51kCF1jB1BQ5upk6dWjg1YXoTdO53cd1S4QBnl2o6mdumf31vyOWcSMwYY3pXtTtQbzhwdimwYTQw5hhga9o/PjXvf2AmISU5Dlvi74jtPpX6alVWcFQcztx/BoVchn71vHRUQ8YYY1rrOB1wrgTERwCbx9GwVpiyAgc3tNYTLVKZ24UZl/0n5+C5XAZXpYQmdcfopNWmTRVXuNpb6aiGjDHGtGZhox4errAAbm4HzvwJU1bgbqkNGza8MvcNLZZJK3tPmzZNl3VjRSAoZKu47lWqOszMNQ9IktOUCDynHkrOi2QyxpgB8qgFtJsG7Poc2PUFULYp4FoVpqjAwU3Pnj1f2de3b19Ur14da9aswYgRI3RVN1bIHj48geN4QaunIqDheK3K2nstCk8TUuBmb4mWlVx0VkfGGGM65D8auLMPCN4LrB8BjNoPaPHD1uRzbho1aoR9+/bpqjhWBDacniOuG8ls4Onpr5O5bfrV84aZglO5GGPMIMnlQK/5gK0LEHUV2Guag4R0chZ68eKFWDTT05NnozUWaalJ2PjsqtgOKNdNq7JCnybiSPDjjFFSjDHGDFgJV6DXAvX2yQXArV1Ace+Wyr5AJq0jFBcXBxsbG/zzzz+6rh8rJMfOzUeUQoaSKglt/D/Wqqx1Zx+KxPtmvs4o42SjszoyxhgrJBXbAY3GAifmARvHqoeH27mh2AY3c+bMyRLc0OgpFxcX+Pv7i8CHGYf1N9eL6+4lKsCCFlnTkFIlYd2Z/xbJZIwxZiTafQ2E/AtEXgY2jgbeCFR3WxXH4GbYsGGFUxNWZKKjruKwKgaQydCn7jityjp8KxrhMUkoaWOODtVNJ+pnjDGTZ2YJ9FkMLGwF3NmvbsVpot05wVAUOERbunQp1q1b98p+2kfDwZnh23TyRyhlMvhJ5qhQob1OEokD6njB0oznOWKMMaPiWgXoNF29vfdrIPwiimVwM2PGDDg7O7+y39XVFdOnv3yBmMGSVCoERZ8V2wHe7bQqKyouCfuuR4ntgQ25S4oxxoxSveFAlW6AKlU9PDwlAcUuuHnw4AHKlSv3yn5aIZz+xgzbmYtLEaoAbFUSOvpP0KqswLOPkKaSULdMSVRy0zxvhzHGmB7JZOrFNe08gCe3gZ2fo9gFN9RCc+nSpVf2X7x4EU5Opr0QlylYf+1vcd3Z2hM2NBxQQzRKbs3LLqmBDcrorH6MMcb0wMYR6P0HRTrAueXAtU36rlHRBjeDBg3CBx98gAMHDkCpVIrL/v378eGHH2LgwIGFU0umEzHP72Fvqno+mr61R2lV1smQp7j3JBG2Fgp0reWhoxoyxhjTm/ItgWYfqbc3fwDEPESxCW6+/fZbMey7bdu2sLa2FpcOHTqgTZs2nHNj4LYen4UUmQyVVXJUqxygk0Uye/iVhq1lgQfdMcYYM0StvwBK1wWSngNB7wIqJYpFcGNhYSHWkLp58yZWrFiBoKAg3LlzB0uWLBF/Y4abSBwYcVRsB3g0g0yLuQxiElOx/XK42B7AXVKMMWY6FObq4eHmtsD9I8AR9TI9xkbjn9wVK1YUF2Ycrt4IxG25ChaShK6NJ2pV1sYLj5CcpkIVdzvU9nLQWR0ZY4wZAKcKQNefgI1jgAPTgfKtAK/6MCYF/vnep08f/PDDD6/snzVrFvr166erejEdW39xkbhub+4CB4cyWiUSrzqVnkjsnWW2asYYYyai9iCgRh9AUgKBI4CkWJh0cHP48GF06dLllf2dO3cWf2OGJzE+CjuSwsR2n+pvaVXW5UcxuBERBwszOXrV4YVSGWPMJMlkQNfZAP0YfnYP2P4pTDq4iY+PzzG3xtzcHLGxxhXZFRe7TvyIRLkMZZRA/VraLZ+x+mUiceca7ihpwzlWjDFmsqxLAn0WATI5cGk1cGktTDa4qVmzpkgozm716tWoVq2arurFdCgwdJ+4DnCpr1UicWJKGjZfULcA8SKZjDFWDJRpBLR8mae5dTzwNAQmmVA8ZcoUBAQEiBFSNPyb7Nu3DytXrsT69eqVppnhCL6zGxflqVBIEno2+kyrsrZeCkd8chp8nGzQuDxP2MgYY8VC8wnAnQNA6AkgaBQwfCegMOwpQAr8M7579+7YuHEjgoODMXbsWHzyySd49OiRmMjP19e3cGrJNBZ4bq64bqlwgLNLVZ3MbdOfE4kZY6z4UJipu6csHYCHp4FDrw4qMjQa9VF07doVR48eRUJCAu7evYv+/ftjwoQJqF27tu5ryDSWkhyHLfF3xXafSv21Kut2ZBzO3n8GhVyGvnW9dFRDxhhjRqFkGaD7yzlv/v0JuKeeN81QaZyAQSOjhg4ditKlS+N///uf6KI6ceKEbmvHtLL/5GzEyGVwVUpoWm+MTlpt2lRxhau9lY5qyBhjzGjU6AP4vUmzwgJB7wAvnsFQFajTLCIiAsuWLcOff/4pRkZRi01ycrLopuJkYsMTGLJNXPcuVQMKM81HNiWnKRF0/lHG3DaMMcaKqc4/AA+OA0/vAFs+BPotVw8bN9aWG8q1qVy5slgR/Oeff0ZYWBh+++23wq0d09jDhydwAi8gkyT0bjheq7L2XIvE04QUuNtboWUlF53VkTHGmJGxLKFenkFupl45/Pw/MET5Dm527NiBESNGYNq0aSLnRqFQFG7NmFaCTs0W141kNvD0bKiTLql+9b1gptB8KDljjDET4FkXaDNFvb3jM+DxbRiafJ+pjhw5gri4ONSrV0+sCj537lw8fvy4cGvHNJKWmoRNz6+J7T7lu2tVVujTRPx7W/0+96/PXVKMMcYANPkAKNcCSE1UL8+QlgKjDG4aNWqERYsWITw8HO+++66YtI+SiVUqFfbs2SMCH2YYjp6dhyiFDKVUElo3/EirstadUbfaNPN1hrejjY5qyBhjzKjJ5UDvPwBrRyD8IrD/WxiSAvcx2Nra4u233xYtOZcvXxbz3MycOROurq7o0aNH4dSSFUjgrUBx3b1EBVhY2mlcjlIlYe2Zh2KbZyRmjDGWhX1poKd6LjUc+1U90Z+B0CqBghKMaTXwhw8fYtWqVbqrFdNYdNRVHFbFiO2AuuO0KuvQrShExCahlI05OlR301ENGWOMmYwqXYH6I9TbG94F4iKBkH+By+vV1yqlXqqlk/mTKbm4V69e4sL0a9OJWVDKZPCTzFGhQnutylp9St0lFVDXC5ZmnEDOGGMsBx2+A+4fBaJvAL/UBNKSs7budPoBqFa0PTs89MWEqJRpCHp8Tmz38dYusImKS8K+G1Fim7ukGGOM5crCBqjzlno7c2BDYsOBtUOAa5tRlDi4MSFnLi1DqAKwVUno0PhTrcoKPPtI5NzULVMSldw0z9thjDFm4lRK4MTvufxRUl/tnFSkXVQc3JiQwGvqyZS6WHvBxsZZ43IkScKa0w/E9sAGZXRWP8YYYybo/jEgNiyPAyQg9pH6uCLCwY2JiHl+D3tT1fPR9Kk9SquyTtx9intPElHC0gxda3noqIaMMcZMUnykbo/TAQ5uTMTW4z8gRSZDZZUc1Sr31qqs9Fab7rVLw9ZSJznnjDHGTFUJN90epwMc3JgASaXC+gh1c18fj+aQ0eRKGopJTMX2KxFimxfJZIwx9lplm6hHRSG3BTRlgL2n+rgiwsGNCbhyPRDBchUsVRK6NP5Mq7I2XniElDQVqrjboZaXg87qyBhjzETJFerh3kL2AOfl7U4z1ccVVZWK7JFYoQm8tEhct7dwgYNDGa0SiVedSk8k9obMAJexZ4wxZoCq9QD6/wXYZ8vTpBYd2l/E89xwQoWRS4yPwo6kMEAuQ0D1l/MMaOjSwxjciIiDhZkcvet46ayOjDHGioFqPdQzFtOoKEoephwb6ooqwhabdBzcGLmdJ2YhUS5DWSVQv9YwrcpafVo9I3GXGu5wsDHXUQ0ZY4wVG3IFUK65vmvB3VLGLjB0v7gOcGmgVSJxQnIaNl94JLYH8Nw2jDHGjBgHN0bsdvBOXJKnwkyS0KORdjMSb7scjoQUJXycbNCovKPO6sgYY4wVNQ5ujFjQ+XniuqXCAc4uVbUqa83LLqn+nEjMGGPMyHFwY6RSkuOwJf6u2A6o1F+rsm5FxuHs/WdQyGXoW48TiRljjBk3Dm6M1L4T/0OMXAY3pYSm9cbopNWmbRVXuNpZ6aiGjDHGmH5wcGOkAu9tE9e9S9WEwsxC43KS05QIOvdQbA9syDMSM8YYM34c3Bih0NDjOIkkyCQJvRp+rFVZe65F4lliKtztrdCioovO6sgYY4zpCwc3RmjD6TniurHMBp6eDXXSJdWvvhfMFPxxYIwxZvz4bGZk0lKTsOn5NbEdUL67VmWFPk3Ev7cfgwZH9a/PXVKMMcZMAwc3RubI2d8RpZChlEpC64YfaVXW2jPqVptmvs7wdrTRUQ0ZY4wx/eLgxsgE3goU1z1K+MLC0k7jctKUKqw7o04kHtCAW20YY4yZDg5ujEhU5BX8q4oV2wH139eqrMO3oxERm4RSNuZoX81NRzVkjDHG9I+DGyOy+eSPUMpkqCNZoHy5tlqVteqUuksqoK4XLM2KfsVWxhhjrLBwcGMkVMo0BD4+J7YDvNtpVVZUbBL234gS2wO5S4oxxpiJMYjg5vfff4ePjw+srKzg7++PU6dO5Xpsq1atxNpH2S9du3aFKTt9cQkeKoASKgkdGmu3SOb6cw+hVEmoV7YUKrppnrfDGGOMGSK9Bzdr1qzB+PHjMXXqVJw7dw61a9dGx44dERWlblnILigoCOHh4RmXK1euQKFQoF+/fjBlgddWiOsu1l6wsXHWuBxJkjLmtuFEYsYYY6ZI78HN7NmzMWrUKAwfPhzVqlXDggULYGNjgyVLluR4vKOjI9zd3TMue/bsEcebcnDz/FkI9qY9EdsBfu9oVdaJu09x/0kiSliaoWtNDx3VkDHGGDMceg1uUlJScPbsWbRr918OiVwuF7ePHz+erzL+/PNPDBw4ELa2tjn+PTk5GbGxsVkuxmbbiVlIlclQRSVHtUq9tCpr9ekH4rp77dKwtTTTUQ0ZY4wxw6HX4Obx48dQKpVwc8s6FJluR0REvPb+lJtD3VIjR47M9ZgZM2bAwcEh4+LtbVxdMZJKhfURx8R2gEdzyOSav2XPE1Ow44r6dR3Ei2QyxhgzUXrvltIGtdrUrFkTDRvmvr7S559/jpiYmIxLaKg638RYXL6+DsFyFSxVEro0/kyrsjaef4SUNBWqetijpqeDzurIGGOMGRK99ks4OzuLZODIyMgs++k25dPkJSEhAatXr8Y333yT53GWlpbiYqyCLv0prjtYuMLBoYxWicSrXyYS0/BvGmHGGGOMmSK9ttxYWFigXr162LdvX8Y+lUolbjdu3DjP+65bt07k07z55pswVQnxEdieFCa2A6oP0aqsSw9jcCMiDhZmcvTy89RRDRljjDHDo/eMUhoGPnToUNSvX190L/3888+iVYZGT5EhQ4bA09NT5M5k75Lq1asXnJycYKp2nfgJL+QylFUC9WoN0UkicZca7nCwMddRDRljjDHDo/fgZsCAAYiOjsZXX30lkoj9/Pywc+fOjCTjBw8eiBFUmd28eRNHjhzB7t27YcoCQ/eJtrUAlwZaJRInJKdh8wV1C9DAhpp3bTHGGGPGQO/BDRk3bpy45OTgwYOv7KtcubLIITFlt4J34JI8DWaShB5aJhJvuxSOhBQlfJxs4F/OUWd1ZIwxxgyRUY+WMmUbzs0T160UJeHsXEUnXVIDGpThRGLGGGMmj4MbA5ScFIMtCSFiO6Byf63KuhUZh3MPnkMhl6FPPU4kZowxZvo4uDFA+0/OQYxcBjelhCZ1R2tV1upT6uHfbau4wtXOSkc1ZIwxxgwXBzcGKPDeNnHdu1RNKMwsNC4nOU2JoPMPxfYgTiRmjDFWTHBwY2BCQ4/iJJIgkyT09v9Eq7J2X43E88RUuNtboUUlF53VkTHGGDNkHNwYmA2nfxbXTWS2KF26vlZlrXk5I3H/+l4i54YxxhgrDji4MSBpqUnY+Py62A4o312rskKfJuJI8GPQ4Kh+9XmRTMYYY8UHBzcG5MjZ3xGtkKGUSkLrhh/rpNWmma8zvB1tdFRDxhhjzPBxcGNAAm8FiuseJXxhbmmrcTlpShXWnU1fJJMTiRljjBUvHNwYiMjISzisihXbAfXf16qsQ7eiERmbDEdbC7Sr5qqjGjLGGGPGgYMbA7H55E9QyWSoK1mgfLm2WpW1+mWXVEAdT1iaKXRUQ8YYY8w4cHBjAFTKNAQ9Pi+2A8q016qsqNgk7L8RJbYHNOBEYsYYY8UPBzcG4PTFJXioAEqoJLRvNEGrstadfQilSkK9sqVQ0c1OZ3VkjDHGjAUHNwYg8NoKcd3F2gs2Ns4al6NSSVh7Jj2RmFttGGOMFU8c3OjZ82ch2Jv2RGwH+L2jVVknQp7g/pNElLA0Q9daHjqqIWOMMWZcOLjRs60nfkCqTIaqKgWqVwnQydw2PfxKw8bCTEc1ZIwxxowLBzd6JKlUCIw4LrYDPJprVdbzxBTsuBIhtrlLijHGWHHGwY0eXb6+DsFyFSxVEro0/kyrsjacf4SUNBWqetijpqeDzurIGGOMGRsObvQo8NJicd3BwhX2Dpq3tkiShNWn1F1Sgxp6Q0YLSjHGGGPFFAc3epIQH4EdSeFiO6D6EK3KuvgwBjcj42BpJkfP2p46qiFjjDFmnDi40ZOdx3/EC7kMPkqgXi3tgps1px+I6y41PeBgY66jGjLGGGPGiYMbPQl6uF9cB7g2hEyu+duQkJyGzRfCxDbPSMwYY4xxcKMXt4J34JI8DWaShO6NPtWqrK2XwpCQokQ5Z1v4l3PUWR0ZY4wxY8XBjR4EnZsnrlspSsLZuYpOFsmkVhtOJGaMMcY4uClyyUkx2JIQIrYDKvfXqqybEXE4/+A5zOQyBNTlRGLGGGOMcHBTxPadnI1YuQzuSglN6o7WyYzEbau6wtXOSkc1ZIwxxowbBzdFLOjednHdu1RNKMwsNC4nOU2JoPMPxfbABmV0Vj/GGGPM2HFwU4RCQ4/iJJIgkyT08v9Eq7J2XY3E88RUeDhYoUUlF53VkTHGGDN2HNwUoaBTc8R1E5ktSpeur5O5bfrV94ZCzonEjDHGWDoObopIWmoSNsbcENsB5btrVdaDJ4k4GvwENDiqXz0vHdWQMcYYMw0c3BSRf8/MxWOFDI4qCa0bfqxVWWvPqBOJm/k6w9vRRkc1ZIwxxkwDBzdFJOh2kLjuYVcR5pa2GpeTplRh3Vl1cMOJxIwxxtirOLgpApGRl3BYFSu2e9d7X6uyDt6MRmRsMhxtLdCumquOasgYY4yZDg5uisCmkz9CJZOhrmSB8uXa6GRG4j51PWFpptBRDRljjDHTwcFNIVMp0xD0+ILYDijTXquyImOTcOBmlNjmRTIZY4yxnHFwU8hOXfgTjxRACZWEDo0+06qs9WcfQqmSUL9sKfi62umsjowxxpgp4eCmkAVdXymuu1p7w9pG81W7VSopY7kFbrVhjDHGcsfBTSF69vQO9qY9EdsBfu9qVdaJu0/w4Gki7CzN0LWWh45qyBhjjJkeDm4K0dYTs5Aqk6GqSoFqVXrpJJG4h19p2FiY6aiGjDHGmOnh4KaQSCoVgiKOi+0Aj+ZalfUsIQU7r0SIbZ7bhjHGGMsbBzeF5NK1tQhWSLBSSejSWLtE4o0XHiFFqUI1D3vU8LTXWR0ZY4wxU8TBTSEJuvynuO5g6Qp7B80TgCVJwupTL2ckbugNGS0oxRhjjLFccXBTCBLiI7AjKVxsB1QfqlVZF0Kf42ZkHCzN5OhZ21NHNWSMMcZMFwc3hWDH8Vl4IZfBRwnUrfmWVmWlD//uWtMDDjbmOqohY4wxZro4uCkEQQ8PiOsA14aQyTV/ieOT07D5YpjY5rltGGOMsfzh4EbHbt7ehsvyNJhJEno0mqhVWdsuhSExRYlyzrZoWE7zCQAZY4yx4oQnTNERZVoKzl3+G39eWihut5I7wMm5klZlrnqZSEytNpxIzBhjjOUPBzc6sPfIDMy8tQKRiv8CkDPKGLG/XbPPNSrzRkSsSCY2k8vQp66XDmvLGGOMmTbultISBTDjg1cgMtsrGSOD2E9/1yaRuF1VN7jYWeqiqowxxlixwMGNll1R1GIj0Y1s3UbSy9s/3FohjiuIpFQlNpx/JLYHNOREYsYYY6wgOLjRAuXYiK6oXPJhKMCJUMjEcQWx+1okniemwsPBCi0quuiotowxxljxwMGNFqJjH+j0uHSrT6mP71ffGwo5JxIzxhhjBcHBjRZc7Mvo9Dhy/0kCjt15IhqD+tfnRGLGGGOsoDi40QLNPuymlCCTRNbNK2i/u1Iq0CzFa8+oE4mbV3SBVykbndWVMcYYKy44uNGCwswCkyq9IbazBzjptydWekMclx9pShXWnXkotgfyjMSMMcaYRji40RLNYzPb9w24qrLud1NB7C/IPDcHb0YjKi4ZjrYWYgg4Y4wxxgqOJ/HTAQpgWjf6RIyKouRhyrGhrqj8ttikW31anUjcp64nLMw47mSMMcY0wcGNjlAg06DOCI3vHxGThP03osQ2L5LJGGOMaY6bBwxE4LmHUElAA59S8HW103d1GGOMMaPFwY0BUKmkjOUWBjTI/7BxxhhjjL2KgxsDcOLuEzx4mgg7SzN0qemu7+owxhhjRo2DGwOw6mWrTQ+/0rCx4DQoxhhjTBsc3OjZs4QU7LoSIbYHcpcUY4wxpjUObvSMVv9OUapQvbQ9ano56Ls6jDHGmNHj4EaPJOm/RGKekZgxxhjTDQ5u9OhC6HPcjIyDpZkcPfw89V0dxhhjzCToPbj5/fff4ePjAysrK/j7++PUqVN5Hv/8+XO899578PDwgKWlJSpVqoTt27fDGK0+pW616VrTAw7W5vquDmOMMWYS9Do0Z82aNRg/fjwWLFggApuff/4ZHTt2xM2bN+Hq6vrK8SkpKWjfvr342/r16+Hp6Yn79++jZMmSMDbxyWnYcilMbPOMxIwxxpiJBDezZ8/GqFGjMHz4cHGbgpxt27ZhyZIlmDRp0ivH0/6nT5/i2LFjMDdXt3RQq48x2noxDIkpSpR3tkXDco76rg5jjDFmMvTWLUWtMGfPnkW7du3+q4xcLm4fP348x/ts3rwZjRs3Ft1Sbm5uqFGjBqZPnw6lUpnr4yQnJyM2NjbLxRCszpiR2BsymUzf1WGMMcZMht6Cm8ePH4ughIKUzOh2RIR63pfs7t69K7qj6H6UZzNlyhT873//w3fffZfr48yYMQMODg4ZF29v/XcB3YiIFcnEZnIZAup66bs6jDHGmEnRe0JxQahUKpFvs3DhQtSrVw8DBgzAF198IbqzcvP5558jJiYm4xIaqm4xMYRE4nZV3eBiZ6nv6jDGGGMmRW85N87OzlAoFIiMjMyyn267u+e8vhKNkKJcG7pfuqpVq4qWHurmsrCweOU+NKKKLoYiKVUpJu4jAxrqvxWJMcYYMzV6a7mhQIRaX/bt25elZYZuU15NTpo2bYrg4GBxXLpbt26JoCenwMYQ7boagZgXqSjtYIUWFV30XR3GGGPM5Oi1W4qGgS9atAjLly/H9evXMWbMGCQkJGSMnhoyZIjoVkpHf6fRUh9++KEIamhkFSUUU4KxsUifkbhffW8o5JxIzBhjjJnUUHDKmYmOjsZXX30lupb8/Pywc+fOjCTjBw8eiBFU6SgZeNeuXfj4449Rq1YtMc8NBToTJ06EMbj/JAHH7jwBDY7qV58TiRljjLHCIJNogaNihIaC06gpSi62t7cv0seetfMG5h28gxaVXPDX2w2L9LEZY4yx4nL+NqrRUsYsTanCurMPxTYvkskYY4wVHg5uisiBm9GIjkuGk62FGALOGGOMscLBwU0RWXP6gbjuU88LFmb8sjPGGGOFhc+yRSAiJgn7b0SJ7f71uUuKMcYYK0wc3BSB9WdDoZKABj6l4OtaQt/VYYwxxkwaBzeFTKWSsOZM+iKZZfRdHcYYY8zkcXBTyI7ffYLQpy9gZ2mGrjU99F0dxhhjzORxcFPIVr+ckbhnndKwtvhvTSzGGGOMFQ4ObgrR04QU7LoSIbYHcpcUY4wxViQ4uClEtPp3ilKF6qXtUcPTQd/VYYwxxooFDm4KCa1qkT63Dc9IzBhjjBUdDm4KyfnQ57gVGQ8rczl6+HnquzqMMcZYscHBTSFZc0qdSNylpgccrM31XR3GGGOs2ODgphDEJ6dhy6Uwsc2JxIwxxljR4uCmEGy5GIbEFCXKO9uKWYkZY4wxVnQ4uCnEuW0GNPCGTCbTd3UYY4yxYoWDGx27Hh6Li6HPYSaXiRXAGWOMMVa0zIr48UyWUiXhVMhTzD8YLG63q+oK5xKW+q4WY4wxVuxwcKMDO6+EY9qWawiPScrYdzLkqdjfqQavJ8UYY4wVJe6W0hIFMGP+OZclsCHPE1PFfvo7Y4wxxooOBzdadkVRi42Uw9/S99Hf6TjGGGOMFQ0ObrRAOTbZW2wyo5CG/k7HMcYYY6xocHCjhai4JJ0exxhjjDHtcXCjBVc7K50exxhjjDHtcXCjhYblHOHhYIXcpumj/fR3Oo4xxhhjRYODGy0o5DJM7V5NbGcPcNJv09/pOMYYY4wVDQ5utETz2Mx/sy7cHbJ2PdFt2s/z3DDGGGNFiyfx0wEKYNpXcxejoih5mHJsqCuKW2wYY4yxosfBjY5QINO4gpO+q8EYY4wVe9wtxRhjjDGTwsENY4wxxkwKBzeMMcYYMykc3DDGGGPMpHBwwxhjjDGTwsENY4wxxkwKBzeMMcYYMykc3DDGGGPMpHBwwxhjjDGTUuxmKJYkSVzHxsbquyqMMcYYy6f083b6eTwvxS64iYuLE9fe3t76rgpjjDHGNDiPOzg45HmMTMpPCGRCVCoVwsLCYGdnB5lMpvOokoKm0NBQ2Nvbw9SY+vMrDs+Rn5/xM/XnyM/P+MUW0nOkcIUCm9KlS0Muzzurpti13NAL4uXlVaiPQW+mqX5oi8PzKw7PkZ+f8TP158jPz/jZF8JzfF2LTTpOKGaMMcaYSeHghjHGGGMmhYMbHbK0tMTUqVPFtSky9edXHJ4jPz/jZ+rPkZ+f8bM0gOdY7BKKGWOMMWbauOWGMcYYYyaFgxvGGGOMmRQObhhjjDFmUji4YYwxxphJ4eAmnw4fPozu3buLmRFpZuONGze+9j4HDx5E3bp1Rca4r68vli1bBlN6jvT86Ljsl4iICBiiGTNmoEGDBmJ2aldXV/Tq1Qs3b9587f3WrVuHKlWqwMrKCjVr1sT27dthKs+PPpPZ3z96noZo/vz5qFWrVsbEYI0bN8aOHTtM4r3T9Dka0/uXk5kzZ4o6f/TRRyb1Phbk+Rnbe/j111+/Ul96bwzt/ePgJp8SEhJQu3Zt/P777/k6PiQkBF27dkXr1q1x4cIF8eEeOXIkdu3aBVN5junoBBoeHp5xoROrITp06BDee+89nDhxAnv27EFqaio6dOggnndujh07hkGDBmHEiBE4f/68CBjocuXKFZjC8yN0Es38/t2/fx+GiGYWp5PF2bNncebMGbRp0wY9e/bE1atXjf690/Q5GtP7l93p06fxxx9/iGAuL8b4Phbk+Rnje1i9evUs9T1y5IjhvX80FJwVDL1sGzZsyPOYzz77TKpevXqWfQMGDJA6duwomcpzPHDggDju2bNnkjGKiooS9T906FCux/Tv31/q2rVrln3+/v7Su+++K5nC81u6dKnk4OAgGatSpUpJixcvNrn3Lr/P0Vjfv7i4OKlixYrSnj17pJYtW0offvhhrsca4/tYkOdnbO/h1KlTpdq1a+f7eH29f9xyU0iOHz+Odu3aZdnXsWNHsd/U+Pn5wcPDA+3bt8fRo0dhLGJiYsS1o6OjSb6P+Xl+JD4+HmXLlhUL3b2ulcBQKJVKrF69WrRKUdeNqb13+X2Oxvr+UQsjtWxnf39M5X0syPMzxvfw9u3bIn2hfPnyeOONN/DgwQODe/+K3cKZRYXyTtzc3LLso9u0WuqLFy9gbW0NY0cBzYIFC1C/fn0kJydj8eLFaNWqFU6ePClyjQx9dXjqKmzatClq1KhR4PfRUPOKCvr8KleujCVLloimcwqGfvrpJzRp0kR8uRb2ArOauHz5sjjRJyUloUSJEtiwYQOqVatmUu9dQZ6jsb1/hAK2c+fOiW6b/DC297Ggz8/Y3kN/f3+RJ0T1pi6padOmoXnz5qKbifL9DOX94+CGaYw+3HRJR/8g79y5gzlz5uDvv/+GIaNfVvSPMa++YmOW3+dHJ9HMrQL0HlatWlXkCnz77bcwNPR5oxw2OgmsX78eQ4cOFblGuZ38jVFBnqOxvX+hoaH48MMPRU6YISfNFuXzM7b3sHPnzhnbFJBRsEOtTmvXrhV5NYaCg5tC4u7ujsjIyCz76DYljplCq01uGjZsaPABw7hx47B161YxOux1v4xyex9pvyk8v+zMzc1Rp04dBAcHwxBZWFiIkYekXr164tfxL7/8Ik4EpvDeFfQ5Gtv7R4nSUVFRWVp2qfuNPqtz584VLcAKhcJo30dNnp+xvYfZlSxZEpUqVcq1vvp6/zjnppBQJL5v374s+yiaz6vv3BTQL07qrjJElCdNJ35q5t+/fz/KlStnUu+jJs8vO/oipm4RQ30Pc+p+oxOGsb93mj5HY3v/2rZtK+pH3xPpF+rWprwN2s7pxG9M76Mmz8/Y3sOc8oWoxT63+urt/SvUdGUTQtnv58+fFxd62WbPni2279+/L/4+adIk6a233so4/u7du5KNjY306aefStevX5d+//13SaFQSDt37pRM5TnOmTNH2rhxo3T79m3p8uXLYkSAXC6X9u7dKxmiMWPGiFEJBw8elMLDwzMuiYmJGcfQ86Pnme7o0aOSmZmZ9NNPP4n3kUYKmJubi+drCs9v2rRp0q5du6Q7d+5IZ8+elQYOHChZWVlJV69elQwN1ZtGfoWEhEiXLl0St2UymbR7926jf+80fY7G9P7lJvtoIlN4Hwvy/IztPfzkk0/Edwx9Rum9adeuneTs7CxGZxrS+8fBTT6lD3vOfhk6dKj4O13Thzj7ffz8/CQLCwupfPnyYsifKT3HH374QapQoYL4h+jo6Ci1atVK2r9/v2SocnpudMn8vtDzS3++6dauXStVqlRJvI80vH/btm2SqTy/jz76SCpTpox4bm5ublKXLl2kc+fOSYbo7bfflsqWLSvq6uLiIrVt2zbjpG/s752mz9GY3r/8nvxN4X0syPMztvdwwIABkoeHh6ivp6enuB0cHGxw75+M/le4bUOMMcYYY0WHc24YY4wxZlI4uGGMMcaYSeHghjHGGGMmhYMbxhhjjJkUDm4YY4wxZlI4uGGMMcaYSeHghjHGGGMmhYMbxliho9XiaZXyvPj4+ODnn3+GIZPJZNi4caO+q8EYew0ObhhjrzVs2DBxYs9+KcrF/b7++mvxmKNHj86yn9bsof337t0rsrowxgwbBzeMsXzp1KkTwsPDs1w0WZxTG1ZWVvjzzz9x+/ZtmIqUlBR9V4Exk8PBDWMsXywtLeHu7p7lkr7K8aFDh9CwYUNxDK0OPGnSJKSlpeVaVlRUFLp37w5ra2sRIK1YsSJfdahcuTJat26NL774Itdjli1bhpIlS2bZR11J1LqTuRXIz88PS5YsQZkyZVCiRAmMHTtWrMg8a9Ys8dxcXV3x/fffv1I+BXWdO3cWdS9fvjzWr1+f5e+hoaHo37+/qIOjoyN69uyZpVWJWsF69eolyi5durR4Towx3eLghjGmlUePHqFLly5o0KABLl68iPnz54vWle+++y7X+9AJnoKAAwcOiOBg3rx5IuDJj5kzZyIwMBBnzpzRqt537tzBjh07sHPnTqxatUrUuWvXrnj48KEI1n744Qd8+eWXOHnyZJb7TZkyBX369BHP9Y033sDAgQNx/fp18bfU1FR07NgRdnZ2+Pfff3H06FEROFGrV+YWmn379uHmzZvYs2cPtm7dqtXzYIy9yiyHfYwx9go6CdOJOh21Xqxbt04EJt7e3pg7d65oHalSpQrCwsIwceJEfPXVV5DLs/6GunXrlggqTp06JQIiQoFF1apV81WPunXripYRKp+CBE2pVCrRckOBSLVq1USLEAUc27dvF3WmFhUKcCgA8/f3z7hfv379MHLkSLH97bffigDlt99+E6/DmjVrRLmLFy/OaClaunSpaMU5ePAgOnToIPbZ2tqKYywsLDSuP2MsdxzcMMbyhU7+1CqTjk7QhFotGjdunKXbp2nTpoiPjxetINTtkxkdb2Zmhnr16mXso4Aoe1dSXqhViIKh3bt3i+4jTdDoLAps0rm5uYlutszBGO3L3qJEzzX7bUpqJtSaQ0nWmcslSUlJoqUoXc2aNTmwYawQcXDDGMsXCmZ8fX1hCCpUqIBRo0aJ3B5q9cmMghNJkrLso+6i7MzNzbPcpuAsp33UEpNfFNBR0JZTDpGLi8srgSFjrHBwzg1jTCvUgnL8+PEsAQXlmlDrhZeX1yvHUysNJRufPXs2Yx91Bz1//rxAj0tdXtTFtXr16leCiLi4OCQkJGTsS29Z0YUTJ068cju9S426zGgkF7UmUSCY+eLg4KCzOjDG8sbBDWNMKzTKiJKD33//fdy4cQObNm3C1KlTMX78+FfybQjlslCC7bvvviuSdSnIoRwWGn1UENRlRI/x66+/ZtlP+TE2NjaYPHmy6ApauXKlGEGlK5RnRLk6FFjR86TcoXHjxom/UYKxs7OzGCFFCcUhISEi1+aDDz4QXXSMsaLBwQ1jTCuenp4iCZdO8rVr1xaT7I0YMUKMNMoNJdnSMOiWLVsiICAA77zzjka5MxMmTMiS5Exo+PU///wj6kS5LTQSioZ+68q0adNEa1GtWrXw119/ifIpIZlQUHX48GGRZ0TPi1p06LWgnBt7e3ud1YExljeZlL1zmjHGGGPMiHHLDWOMMcZMCgc3jDHGGDMpHNwwxhhjzKRwcMMYY4wxk8LBDWOMMcZMCgc3jDHGGDMpHNwwxhhjzKRwcMMYY4wxk8LBDWOMMcZMCgc3jDHGGDMpHNwwxhhjzKRwcMMYY4wxmJL/A1T4u/1QjaOrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_model_results(\n",
    "    results_dicts=[results_lstm, results_gru, results_dnn],\n",
    "    model_labels=[\"LSTM\", \"GRU\", \"DNN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    cm: a 2D NumPy array confusion matrix, shape (num_classes, num_classes).\n",
    "    classes: a list of class names, length = num_classes.\n",
    "    title: title for the plot.\n",
    "    \n",
    "    Displays a confusion matrix with each cell labeled by its integer count.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)  # show the confusion matrix as an image\n",
    "    plt.title(title)\n",
    "    plt.colorbar()  # add a colorbar to the side\n",
    "    \n",
    "    num_classes = len(classes)\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # Annotate each cell with the numeric counts\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(j, i, str(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment=\"center\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold_accuracies': [0.5625, 0.9375, 0.875, 0.9375, 0.8666666666666667],\n",
       " 'mean_acc': 0.8358333333333334,\n",
       " 'std_acc': 0.139905722224329,\n",
       " 'fold_histories': [{'accuracy': [0.3174603283405304,\n",
       "    0.4444444477558136,\n",
       "    0.5079365372657776,\n",
       "    0.6190476417541504,\n",
       "    0.6190476417541504,\n",
       "    0.7142857313156128,\n",
       "    0.7460317611694336,\n",
       "    0.682539701461792,\n",
       "    0.761904776096344,\n",
       "    0.8095238208770752,\n",
       "    0.682539701461792,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.841269850730896,\n",
       "    0.8095238208770752,\n",
       "    0.7460317611694336,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.8253968358039856,\n",
       "    0.8253968358039856,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.8888888955116272,\n",
       "    0.8730158805847168,\n",
       "    0.8571428656578064,\n",
       "    0.8095238208770752,\n",
       "    0.8253968358039856,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648],\n",
       "   'loss': [1.1259390115737915,\n",
       "    1.0817548036575317,\n",
       "    1.031720519065857,\n",
       "    0.9739256501197815,\n",
       "    0.9059779047966003,\n",
       "    0.8585606813430786,\n",
       "    0.7113123536109924,\n",
       "    0.6849968433380127,\n",
       "    0.6142314076423645,\n",
       "    0.5321763753890991,\n",
       "    0.6489902138710022,\n",
       "    0.5657787919044495,\n",
       "    0.590194582939148,\n",
       "    0.5109720230102539,\n",
       "    0.5099722146987915,\n",
       "    0.4866669774055481,\n",
       "    0.5006321668624878,\n",
       "    0.4994184970855713,\n",
       "    0.4772442579269409,\n",
       "    0.5088686943054199,\n",
       "    0.4821341335773468,\n",
       "    0.4209092855453491,\n",
       "    0.5006358027458191,\n",
       "    0.399447500705719,\n",
       "    0.40998369455337524,\n",
       "    0.3911062777042389,\n",
       "    0.4131046533584595,\n",
       "    0.49007388949394226,\n",
       "    0.4051550626754761,\n",
       "    0.49923381209373474,\n",
       "    0.4332803189754486],\n",
       "   'val_accuracy': [0.5,\n",
       "    0.5625,\n",
       "    0.5625,\n",
       "    0.5,\n",
       "    0.6875,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.6875,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.6875,\n",
       "    0.5,\n",
       "    0.625,\n",
       "    0.6875,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.625],\n",
       "   'val_loss': [1.0530152320861816,\n",
       "    1.0546839237213135,\n",
       "    1.0246176719665527,\n",
       "    0.9753974080085754,\n",
       "    0.9511970281600952,\n",
       "    0.9790453910827637,\n",
       "    0.9444800615310669,\n",
       "    0.9067230224609375,\n",
       "    0.8649172782897949,\n",
       "    0.9812058210372925,\n",
       "    0.9195013642311096,\n",
       "    0.8909869194030762,\n",
       "    1.0581181049346924,\n",
       "    0.8980920314788818,\n",
       "    0.9156967997550964,\n",
       "    0.8987732529640198,\n",
       "    0.8780807852745056,\n",
       "    0.8510560989379883,\n",
       "    0.8623326420783997,\n",
       "    0.894005298614502,\n",
       "    0.8413375020027161,\n",
       "    0.9018607139587402,\n",
       "    0.9062145948410034,\n",
       "    0.9486077427864075,\n",
       "    0.9216710925102234,\n",
       "    0.9212017059326172,\n",
       "    0.9909323453903198,\n",
       "    1.0025849342346191,\n",
       "    0.9343304634094238,\n",
       "    0.887265682220459,\n",
       "    0.9114580154418945]},\n",
       "  {'accuracy': [0.30158731341362,\n",
       "    0.4285714328289032,\n",
       "    0.4761904776096344,\n",
       "    0.460317462682724,\n",
       "    0.6507936716079712,\n",
       "    0.60317462682724,\n",
       "    0.682539701461792,\n",
       "    0.682539701461792,\n",
       "    0.682539701461792,\n",
       "    0.7301587462425232,\n",
       "    0.6190476417541504,\n",
       "    0.6507936716079712,\n",
       "    0.682539701461792,\n",
       "    0.682539701461792,\n",
       "    0.6984127163887024,\n",
       "    0.7936508059501648,\n",
       "    0.7777777910232544,\n",
       "    0.7460317611694336,\n",
       "    0.7301587462425232,\n",
       "    0.7460317611694336,\n",
       "    0.7936508059501648,\n",
       "    0.7777777910232544,\n",
       "    0.7301587462425232,\n",
       "    0.7301587462425232,\n",
       "    0.761904776096344,\n",
       "    0.761904776096344,\n",
       "    0.8095238208770752,\n",
       "    0.8571428656578064,\n",
       "    0.7142857313156128,\n",
       "    0.8095238208770752,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.8095238208770752,\n",
       "    0.8095238208770752,\n",
       "    0.7936508059501648,\n",
       "    0.7301587462425232,\n",
       "    0.7301587462425232,\n",
       "    0.8253968358039856],\n",
       "   'loss': [1.0908900499343872,\n",
       "    1.0460925102233887,\n",
       "    1.0122874975204468,\n",
       "    0.969506025314331,\n",
       "    0.9344828724861145,\n",
       "    0.9118253588676453,\n",
       "    0.8137602806091309,\n",
       "    0.7323446869850159,\n",
       "    0.7963839173316956,\n",
       "    0.7019793391227722,\n",
       "    0.7275062799453735,\n",
       "    0.745151937007904,\n",
       "    0.7211071252822876,\n",
       "    0.6912047266960144,\n",
       "    0.730469286441803,\n",
       "    0.6684992909431458,\n",
       "    0.605312705039978,\n",
       "    0.6463080048561096,\n",
       "    0.6460874676704407,\n",
       "    0.6896951794624329,\n",
       "    0.642984926700592,\n",
       "    0.5467885136604309,\n",
       "    0.6316507458686829,\n",
       "    0.5819316506385803,\n",
       "    0.5942420363426208,\n",
       "    0.535153329372406,\n",
       "    0.5723036527633667,\n",
       "    0.5116034150123596,\n",
       "    0.6315814256668091,\n",
       "    0.5250215530395508,\n",
       "    0.5234621167182922,\n",
       "    0.6427360773086548,\n",
       "    0.5711151361465454,\n",
       "    0.5723876357078552,\n",
       "    0.5526620745658875,\n",
       "    0.583242654800415,\n",
       "    0.6221170425415039,\n",
       "    0.5829467177391052],\n",
       "   'val_accuracy': [0.3125,\n",
       "    0.3125,\n",
       "    0.4375,\n",
       "    0.6875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    1.0],\n",
       "   'val_loss': [1.097918152809143,\n",
       "    1.0762789249420166,\n",
       "    1.0233283042907715,\n",
       "    0.9137893915176392,\n",
       "    0.8287273645401001,\n",
       "    0.7713651061058044,\n",
       "    0.6546081304550171,\n",
       "    0.5771198868751526,\n",
       "    0.46476221084594727,\n",
       "    0.4705938994884491,\n",
       "    0.35372528433799744,\n",
       "    0.35796546936035156,\n",
       "    0.3663329482078552,\n",
       "    0.2983076572418213,\n",
       "    0.29397672414779663,\n",
       "    0.3104560971260071,\n",
       "    0.27101609110832214,\n",
       "    0.2700984477996826,\n",
       "    0.2911880612373352,\n",
       "    0.2783403992652893,\n",
       "    0.2873424291610718,\n",
       "    0.23794445395469666,\n",
       "    0.25302326679229736,\n",
       "    0.2288151979446411,\n",
       "    0.29651424288749695,\n",
       "    0.2540459632873535,\n",
       "    0.26325565576553345,\n",
       "    0.1861906349658966,\n",
       "    0.28833380341529846,\n",
       "    0.2668594717979431,\n",
       "    0.21334347128868103,\n",
       "    0.2411758005619049,\n",
       "    0.21620945632457733,\n",
       "    0.24578677117824554,\n",
       "    0.2068415880203247,\n",
       "    0.20059049129486084,\n",
       "    0.20716458559036255,\n",
       "    0.22895726561546326]},\n",
       "  {'accuracy': [0.380952388048172,\n",
       "    0.460317462682724,\n",
       "    0.5873016119003296,\n",
       "    0.6666666865348816,\n",
       "    0.6349206566810608,\n",
       "    0.682539701461792,\n",
       "    0.7777777910232544,\n",
       "    0.7777777910232544,\n",
       "    0.7142857313156128,\n",
       "    0.6984127163887024,\n",
       "    0.761904776096344,\n",
       "    0.761904776096344,\n",
       "    0.7936508059501648,\n",
       "    0.7936508059501648,\n",
       "    0.7301587462425232,\n",
       "    0.6984127163887024,\n",
       "    0.7936508059501648,\n",
       "    0.761904776096344,\n",
       "    0.7142857313156128,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.761904776096344,\n",
       "    0.8095238208770752,\n",
       "    0.7936508059501648,\n",
       "    0.8095238208770752,\n",
       "    0.7936508059501648,\n",
       "    0.761904776096344,\n",
       "    0.841269850730896,\n",
       "    0.761904776096344,\n",
       "    0.7777777910232544,\n",
       "    0.7936508059501648,\n",
       "    0.7936508059501648],\n",
       "   'loss': [1.094396948814392,\n",
       "    1.0186513662338257,\n",
       "    0.975837230682373,\n",
       "    0.9224565029144287,\n",
       "    0.8485590219497681,\n",
       "    0.8009947538375854,\n",
       "    0.7345453500747681,\n",
       "    0.6975196599960327,\n",
       "    0.6826500296592712,\n",
       "    0.7032526135444641,\n",
       "    0.5895509719848633,\n",
       "    0.6105783581733704,\n",
       "    0.6161506772041321,\n",
       "    0.5630019903182983,\n",
       "    0.6102285385131836,\n",
       "    0.6201743483543396,\n",
       "    0.5783756971359253,\n",
       "    0.5782152414321899,\n",
       "    0.6353999376296997,\n",
       "    0.5203173160552979,\n",
       "    0.5189028382301331,\n",
       "    0.6138350367546082,\n",
       "    0.5092709064483643,\n",
       "    0.5191506147384644,\n",
       "    0.5321996808052063,\n",
       "    0.503073513507843,\n",
       "    0.5625954866409302,\n",
       "    0.48872891068458557,\n",
       "    0.4917446970939636,\n",
       "    0.5339361429214478,\n",
       "    0.5256330370903015,\n",
       "    0.43807050585746765],\n",
       "   'val_accuracy': [0.3125,\n",
       "    0.5,\n",
       "    0.5625,\n",
       "    0.5625,\n",
       "    0.5625,\n",
       "    0.625,\n",
       "    0.6875,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.625,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.6875,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.6875,\n",
       "    0.875,\n",
       "    0.75,\n",
       "    0.75,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.6875,\n",
       "    0.6875,\n",
       "    0.8125,\n",
       "    0.6875,\n",
       "    0.8125,\n",
       "    0.875],\n",
       "   'val_loss': [1.0750389099121094,\n",
       "    1.1156646013259888,\n",
       "    1.088106632232666,\n",
       "    1.032050371170044,\n",
       "    0.9275708198547363,\n",
       "    0.7938601970672607,\n",
       "    0.7246881723403931,\n",
       "    0.6871654987335205,\n",
       "    0.6151909828186035,\n",
       "    0.7044506669044495,\n",
       "    0.5574575662612915,\n",
       "    0.5418511033058167,\n",
       "    0.5111145973205566,\n",
       "    0.48437079787254333,\n",
       "    0.522648811340332,\n",
       "    0.5581366419792175,\n",
       "    0.698421061038971,\n",
       "    0.509432315826416,\n",
       "    0.5001881718635559,\n",
       "    0.5404630303382874,\n",
       "    0.6512874960899353,\n",
       "    0.43847721815109253,\n",
       "    0.6444560289382935,\n",
       "    0.5480148792266846,\n",
       "    0.4605816900730133,\n",
       "    0.4841812551021576,\n",
       "    0.6498593688011169,\n",
       "    0.5616099238395691,\n",
       "    0.4816480278968811,\n",
       "    0.663500964641571,\n",
       "    0.46390944719314575,\n",
       "    0.4427153468132019]},\n",
       "  {'accuracy': [0.3174603283405304,\n",
       "    0.5714285969734192,\n",
       "    0.5714285969734192,\n",
       "    0.6507936716079712,\n",
       "    0.60317462682724,\n",
       "    0.7142857313156128,\n",
       "    0.6349206566810608,\n",
       "    0.6349206566810608,\n",
       "    0.6349206566810608,\n",
       "    0.6666666865348816,\n",
       "    0.7301587462425232,\n",
       "    0.761904776096344,\n",
       "    0.7301587462425232,\n",
       "    0.6190476417541504,\n",
       "    0.7460317611694336,\n",
       "    0.7301587462425232,\n",
       "    0.7460317611694336,\n",
       "    0.6349206566810608,\n",
       "    0.7777777910232544,\n",
       "    0.761904776096344,\n",
       "    0.7460317611694336,\n",
       "    0.7460317611694336,\n",
       "    0.6984127163887024],\n",
       "   'loss': [1.1114164590835571,\n",
       "    1.0032227039337158,\n",
       "    0.9880702495574951,\n",
       "    0.9314614534378052,\n",
       "    0.899824857711792,\n",
       "    0.8041921257972717,\n",
       "    0.7969532608985901,\n",
       "    0.7983675003051758,\n",
       "    0.7089870572090149,\n",
       "    0.729351282119751,\n",
       "    0.7301912903785706,\n",
       "    0.6073378324508667,\n",
       "    0.6647077202796936,\n",
       "    0.7217894196510315,\n",
       "    0.6590526103973389,\n",
       "    0.6814014911651611,\n",
       "    0.639419436454773,\n",
       "    0.6956583261489868,\n",
       "    0.5630771517753601,\n",
       "    0.5473679900169373,\n",
       "    0.5659667253494263,\n",
       "    0.5782405734062195,\n",
       "    0.5993603467941284],\n",
       "   'val_accuracy': [0.125,\n",
       "    0.6875,\n",
       "    0.75,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875,\n",
       "    0.9375,\n",
       "    0.875,\n",
       "    0.875],\n",
       "   'val_loss': [1.063812017440796,\n",
       "    0.9269239902496338,\n",
       "    0.8374245762825012,\n",
       "    0.7427287101745605,\n",
       "    0.6536519527435303,\n",
       "    0.5677952170372009,\n",
       "    0.46756601333618164,\n",
       "    0.4015263319015503,\n",
       "    0.4045414626598358,\n",
       "    0.441358745098114,\n",
       "    0.4008023142814636,\n",
       "    0.3918807804584503,\n",
       "    0.27599310874938965,\n",
       "    0.3993013799190521,\n",
       "    0.47560644149780273,\n",
       "    0.3165156841278076,\n",
       "    0.29012811183929443,\n",
       "    0.30390113592147827,\n",
       "    0.32480502128601074,\n",
       "    0.4022974371910095,\n",
       "    0.278516560792923,\n",
       "    0.33390265703201294,\n",
       "    0.3124760687351227]},\n",
       "  {'accuracy': [0.296875,\n",
       "    0.453125,\n",
       "    0.5,\n",
       "    0.671875,\n",
       "    0.5625,\n",
       "    0.65625,\n",
       "    0.71875,\n",
       "    0.765625,\n",
       "    0.6875,\n",
       "    0.75,\n",
       "    0.8125,\n",
       "    0.75,\n",
       "    0.65625,\n",
       "    0.796875,\n",
       "    0.734375,\n",
       "    0.734375,\n",
       "    0.859375,\n",
       "    0.828125,\n",
       "    0.703125,\n",
       "    0.796875,\n",
       "    0.828125,\n",
       "    0.75,\n",
       "    0.875,\n",
       "    0.859375,\n",
       "    0.828125,\n",
       "    0.8125,\n",
       "    0.84375,\n",
       "    0.84375,\n",
       "    0.78125,\n",
       "    0.875,\n",
       "    0.8125,\n",
       "    0.8125,\n",
       "    0.796875,\n",
       "    0.796875,\n",
       "    0.84375,\n",
       "    0.859375,\n",
       "    0.875,\n",
       "    0.84375,\n",
       "    0.859375,\n",
       "    0.796875,\n",
       "    0.875,\n",
       "    0.859375,\n",
       "    0.890625,\n",
       "    0.90625,\n",
       "    0.828125,\n",
       "    0.78125,\n",
       "    0.796875,\n",
       "    0.90625,\n",
       "    0.859375,\n",
       "    0.796875],\n",
       "   'loss': [1.0878595113754272,\n",
       "    1.0370234251022339,\n",
       "    1.013826608657837,\n",
       "    0.9316493272781372,\n",
       "    0.9054971933364868,\n",
       "    0.8030211329460144,\n",
       "    0.7559854388237,\n",
       "    0.679504930973053,\n",
       "    0.7050740122795105,\n",
       "    0.5997169613838196,\n",
       "    0.5838465690612793,\n",
       "    0.5822470784187317,\n",
       "    0.6000794172286987,\n",
       "    0.5672616362571716,\n",
       "    0.571566641330719,\n",
       "    0.6098734140396118,\n",
       "    0.3903942406177521,\n",
       "    0.4326888918876648,\n",
       "    0.5597578287124634,\n",
       "    0.4636344015598297,\n",
       "    0.43277648091316223,\n",
       "    0.5371694564819336,\n",
       "    0.3843584656715393,\n",
       "    0.4274696111679077,\n",
       "    0.44489213824272156,\n",
       "    0.4426925778388977,\n",
       "    0.4299982488155365,\n",
       "    0.40157872438430786,\n",
       "    0.5116184949874878,\n",
       "    0.3990757167339325,\n",
       "    0.4634559154510498,\n",
       "    0.4271410405635834,\n",
       "    0.4753708243370056,\n",
       "    0.5056450963020325,\n",
       "    0.42097699642181396,\n",
       "    0.39466336369514465,\n",
       "    0.3902778625488281,\n",
       "    0.3986639678478241,\n",
       "    0.3341079354286194,\n",
       "    0.39571282267570496,\n",
       "    0.3312223255634308,\n",
       "    0.4388491213321686,\n",
       "    0.304014652967453,\n",
       "    0.32099616527557373,\n",
       "    0.36461740732192993,\n",
       "    0.49061527848243713,\n",
       "    0.4682210683822632,\n",
       "    0.3320333957672119,\n",
       "    0.37352895736694336,\n",
       "    0.4207967519760132],\n",
       "   'val_accuracy': [0.4000000059604645,\n",
       "    0.4000000059604645,\n",
       "    0.5333333611488342,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6666666865348816,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.7333333492279053,\n",
       "    0.6666666865348816,\n",
       "    0.6666666865348816,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.6666666865348816,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.6666666865348816,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.800000011920929,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.8666666746139526,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053,\n",
       "    0.7333333492279053],\n",
       "   'val_loss': [1.062577486038208,\n",
       "    1.0370938777923584,\n",
       "    0.9892936944961548,\n",
       "    0.933731734752655,\n",
       "    0.8974382281303406,\n",
       "    0.8102115392684937,\n",
       "    0.813595175743103,\n",
       "    0.8576279282569885,\n",
       "    0.7444222569465637,\n",
       "    0.8328158259391785,\n",
       "    0.7783380150794983,\n",
       "    0.761588990688324,\n",
       "    0.8836432099342346,\n",
       "    0.8463832139968872,\n",
       "    0.7236509919166565,\n",
       "    0.8200536370277405,\n",
       "    0.7847186326980591,\n",
       "    0.7633923888206482,\n",
       "    0.8019967675209045,\n",
       "    0.717948853969574,\n",
       "    0.6949531435966492,\n",
       "    0.8872117400169373,\n",
       "    0.7587407231330872,\n",
       "    0.7140670418739319,\n",
       "    0.7100857496261597,\n",
       "    0.9540654420852661,\n",
       "    0.6572832465171814,\n",
       "    0.6984551548957825,\n",
       "    0.8961693048477173,\n",
       "    0.7056551575660706,\n",
       "    0.8672106266021729,\n",
       "    0.728908896446228,\n",
       "    0.8493449091911316,\n",
       "    0.7845203280448914,\n",
       "    0.8494224548339844,\n",
       "    0.7063533663749695,\n",
       "    0.6558479070663452,\n",
       "    0.9318094849586487,\n",
       "    0.8640676140785217,\n",
       "    0.6622253656387329,\n",
       "    0.8673628568649292,\n",
       "    0.7587815523147583,\n",
       "    0.6282886862754822,\n",
       "    0.9551345705986023,\n",
       "    0.7084206342697144,\n",
       "    0.5894095301628113,\n",
       "    0.9581862092018127,\n",
       "    0.7937349677085876,\n",
       "    0.7019985318183899,\n",
       "    0.5925674438476562]}],\n",
       " 'confusion_matrices': [array([[2, 1, 2],\n",
       "         [1, 1, 1],\n",
       "         [2, 0, 6]], dtype=int64),\n",
       "  array([[2, 0, 1],\n",
       "         [0, 8, 0],\n",
       "         [0, 0, 5]], dtype=int64),\n",
       "  array([[5, 0, 2],\n",
       "         [0, 4, 0],\n",
       "         [0, 0, 5]], dtype=int64),\n",
       "  array([[1, 0, 1],\n",
       "         [0, 6, 0],\n",
       "         [0, 0, 8]], dtype=int64),\n",
       "  array([[4, 0, 0],\n",
       "         [2, 3, 0],\n",
       "         [0, 0, 6]], dtype=int64)]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make Detection with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "lstm_path = \"lstm_model.h5\"\n",
    "gru_path = \"gru_model.h5\"\n",
    "dnn_pth = \"dnn_model.h5\"\n",
    "\n",
    "#Load model\n",
    "lstm_infer_model = tf.keras.models.load_model(lstm_path)\n",
    "gru_infer_model = tf.keras.models.load_model(gru_path)\n",
    "dnn_infer_model = tf.keras.models.load_model(dnn_pth)\n",
    "\n",
    "infer_model = dnn_infer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global constants\n",
    "CLASSES = [\"Kicking\", \"Punching\", \"Non-violent\"]\n",
    "MAX_SEQ_LEN = 5\n",
    "NUM_FEATURES = 132  # 33 keypoints * (x, y, z, visibility)\n",
    "\n",
    "# Set up MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "# Buffer to store latest MAX_SEQ_LEN frames of keypoints\n",
    "buffer = collections.deque(maxlen=MAX_SEQ_LEN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load models\n",
    "lstm_infer_model = tf.keras.models.load_model(\"lstm_model.h5\")\n",
    "gru_infer_model  = tf.keras.models.load_model(\"gru_model.h5\")\n",
    "dnn_infer_model  = tf.keras.models.load_model(\"dnn_model.h5\")\n",
    "\n",
    "# Select the model to use\n",
    "model = lstm_infer_model  # Change to gru_infer_model or dnn_infer_model as needed\n",
    "\n",
    "# Constants\n",
    "CLASSES = [\"Kicking\", \"Punching\", \"Non-violent\"]\n",
    "MAX_SEQ_LEN = 5\n",
    "NUM_FEATURES = 132\n",
    "\n",
    "# MediaPipe Pose setup\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Initialize a buffer for keypoints\n",
    "buffer = collections.deque(maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "# Start webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH, 960)\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame to consistent shape (optional for clarity)\n",
    "    frame = cv.resize(frame, (960, 720))\n",
    "\n",
    "    # Convert to RGB and get pose\n",
    "    rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    # Extract pose keypoints\n",
    "    if results.pose_landmarks:\n",
    "        keypoints = []\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "    else:\n",
    "        keypoints = [0] * NUM_FEATURES\n",
    "\n",
    "    # Add keypoints to buffer\n",
    "    buffer.append(keypoints)\n",
    "\n",
    "    if len(buffer) == MAX_SEQ_LEN:\n",
    "        seq = np.array(buffer)\n",
    "\n",
    "        if model == dnn_infer_model:\n",
    "            seq_input = seq.reshape(1, -1)  # DNN input shape: (1, 660)\n",
    "        else:\n",
    "            seq_input = np.expand_dims(seq, axis=0)  # LSTM/GRU input shape: (1, 5, 132)\n",
    "\n",
    "        pred = model.predict(seq_input, verbose=0)\n",
    "        class_id = np.argmax(pred)\n",
    "        confidence = float(pred[0][class_id]) * 100\n",
    "        class_name = CLASSES[class_id]\n",
    "        display_text = f\"{class_name} ({confidence:.1f}%)\"\n",
    "    else:\n",
    "        display_text = \"Non-Violent\"\n",
    "\n",
    "    # Show prediction on frame\n",
    "    cv.putText(frame, f'Action: {display_text}', (30, 50),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "    # Draw pose landmarks\n",
    "    if results.pose_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            frame,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "            connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "    # Display the frame\n",
    "    cv.imshow(\"Live Action Detection\", frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "pose.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
